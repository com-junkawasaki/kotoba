//! Merkle DAG: vm_gnn
//! This crate defines the Program Interaction Hypergraph (PIH) used as
//! the core Intermediate Representation (IR) for the VM.
//!
//! The PIH model provides:
//! - **Bipartite hypergraph structure**: Events (operations) and Entities (values/states)
//! - **DPO rewriting rules**: Safe graph transformations with NACs
//! - **GNN integration**: Node embeddings for learning-based optimization
//! - **Merkle DAG compatibility**: Content-addressable and immutable structures
//!
//! ## Key Components
//!
//! - [`ProgramInteractionHypergraph`]: The main hypergraph structure
//! - [`Event`]: Operation nodes in the bipartite graph
//! - [`Entity`]: Value/state nodes in the bipartite graph
//! - [`DpoRule`]: Double Pushout rewriting rules for safe transformations
//! - [`NegativeApplicationCondition`]: NACs for prohibiting unsafe rewrites
//!
//! ## Usage
//!
//! The vm-gnn crate provides core data structures and algorithms for Program Interaction Hypergraphs:
//!
//! - [`ProgramInteractionHypergraph`]: Main hypergraph structure
//! - [`Event`]: Operation nodes
//! - [`Entity`]: Value/state nodes
//! - [`DpoRule`]: Double Pushout rewriting rules
//! - [`convert_computation_to_pih()`]: Convert computation patterns to PIH
//!
//! See the unit tests for detailed usage examples.

#![allow(dead_code)] // TODO: Remove this later on

use serde::{Deserialize, Serialize};
use serde_json::json;
use std::collections::HashMap;

// GNN Training Module
pub mod gnn_training {
    use super::*;

    /// Features extracted from PIH for GNN training
    /// Designed for Bipartite Graph Neural Networks and Hypergraph Neural Networks
    #[derive(Debug, Clone, Serialize, Deserialize)]
    pub struct GnnFeatures {
        pub node_features: HashMap<String, Vec<f32>>,
        pub edge_features: Vec<(String, String, Vec<f32>)>, // (source, target, features)
        pub global_features: Vec<f32>,
        // Bipartite/Hypergraph-specific features
        pub bipartite_features: BipartiteFeatures,
        pub hypergraph_features: HypergraphFeatures,
        // Hardware-specific features
        pub hardware_features: HardwareFeatures,
        // Advanced compiler transformation features
        pub loop_transformations: Vec<LoopTransformation>,
        pub inter_procedural_optimizations: InterProceduralOptimization,
        pub data_structure_transformations: DataStructureTransformation,
        pub system_level_optimizations: SystemLevelOptimization,
        // Production-ready training features
        pub production_training: ProductionTrainingSystem,
    }

    /// Bipartite graph specific features
    #[derive(Debug, Clone, Serialize, Deserialize)]
    pub struct BipartiteFeatures {
        pub edge_node_count: usize,
        pub node_count: usize,
        pub edge_to_node_connections: usize,
        pub node_to_edge_connections: usize,
        pub node_type_distribution: Vec<f32>, // [edge_ratio, node_ratio]
        pub cross_type_connectivity: f32, // Connectivity between different node types
    }

        /// Hypergraph specific features
        #[derive(Debug, Clone, Serialize, Deserialize)]
        pub struct HypergraphFeatures {
            pub hyperedge_sizes: Vec<usize>, // Size of each hyperedge (event)
            pub avg_hyperedge_size: f32,
            pub max_hyperedge_size: usize,
            pub hyperedge_degree_distribution: Vec<f32>,
            pub node_hyperedge_membership: HashMap<String, usize>, // Node -> hyperedge count
            pub hypergraph_clustering_coeff: f32, // Clustering coefficient for hypergraph
        }

        /// Hardware-specific features for optimization
        #[derive(Debug, Clone, Serialize, Deserialize)]
        pub struct HardwareFeatures {
            pub cgra_features: CgraFeatures,
            pub fpga_features: FpgaFeatures,
            pub hardware_constraints: HardwareConstraints,
        }

        /// CGRA-specific features
        #[derive(Debug, Clone, Serialize, Deserialize)]
        pub struct CgraFeatures {
            pub spatial_patterns: Vec<SpatialPattern>,
            pub pipeline_depth: usize,
            pub dataflow_type: DataflowType,
            pub memory_bandwidth: f32,
            pub compute_intensity: f32,
            pub parallelism_degree: usize,
        }

        /// FPGA-specific features
        #[derive(Debug, Clone, Serialize, Deserialize)]
        pub struct FpgaFeatures {
            pub rtl_patterns: Vec<RtlPattern>,
            pub resource_utilization: ResourceUtilization,
            pub timing_constraints: TimingConstraints,
            pub synthesis_directives: Vec<SynthesisDirective>,
            pub placement_constraints: Vec<PlacementConstraint>,
        }

        /// Hardware constraints for optimization
        #[derive(Debug, Clone, Serialize, Deserialize)]
        pub struct HardwareConstraints {
            pub max_memory_usage: usize,
            pub max_compute_units: usize,
            pub max_bandwidth: f32,
            pub max_power_consumption: f32,
            pub max_temperature: f32,
            pub target_frequency: f32,
        }

        /// Spatial computing patterns for CGRA
        #[derive(Debug, Clone, Serialize, Deserialize)]
        pub struct SpatialPattern {
            pub pattern_type: SpatialPatternType,
            pub grid_size: (usize, usize),
            pub dataflow_pattern: String,
            pub memory_access_pattern: String,
            pub compute_distribution: Vec<f32>,
        }

        #[derive(Debug, Clone, Serialize, Deserialize, PartialEq, Eq)]
        pub enum SpatialPatternType {
            SystolicArray,
            Pipeline,
            Dataflow,
            StreamProcessing,
            Custom,
        }

        /// Dataflow types for CGRA
        #[derive(Debug, Clone, Serialize, Deserialize, PartialEq, Eq)]
        pub enum DataflowType {
            DataParallel,
            TaskParallel,
            Pipeline,
            Stream,
            Custom,
        }

        /// RTL patterns for FPGA
        #[derive(Debug, Clone, Serialize, Deserialize)]
        pub struct RtlPattern {
            pub pattern_type: RtlPatternType,
            pub module_template: String,
            pub resource_estimate: ResourceEstimate,
            pub timing_estimate: f32,
        }

        #[derive(Debug, Clone, Serialize, Deserialize, PartialEq, Eq)]
        pub enum RtlPatternType {
            PipelinedMultiplier,
            ParallelAdder,
            MemoryInterface,
            StreamProcessor,
            Custom,
        }

        /// Resource utilization estimates
        #[derive(Debug, Clone, Serialize, Deserialize)]
        pub struct ResourceUtilization {
            pub dsp_usage: f32,
            pub bram_usage: f32,
            pub lut_usage: f32,
            pub ff_usage: f32,
        }

        /// Timing constraints for FPGA
        #[derive(Debug, Clone, Serialize, Deserialize)]
        pub struct TimingConstraints {
            pub clock_frequency: f32,
            pub setup_time: f32,
            pub hold_time: f32,
            pub latency_requirement: f32,
        }

        /// Synthesis directives for FPGA optimization
        #[derive(Debug, Clone, Serialize, Deserialize)]
        pub struct SynthesisDirective {
            pub directive_type: SynthesisDirectiveType,
            pub parameters: HashMap<String, String>,
            pub expected_impact: OptimizationImpact,
        }

        #[derive(Debug, Clone, Serialize, Deserialize, PartialEq, Eq)]
        pub enum SynthesisDirectiveType {
            Retiming,
            ResourceSharing,
            LoopUnrolling,
            ParallelSynthesis,
            Custom,
        }

        /// Placement constraints for FPGA
        #[derive(Debug, Clone, Serialize, Deserialize)]
        pub struct PlacementConstraint {
            pub constraint_type: PlacementConstraintType,
            pub region: String,
            pub priority: u32,
        }

        #[derive(Debug, Clone, Serialize, Deserialize, PartialEq, Eq)]
        pub enum PlacementConstraintType {
            Region,
            ClockRegion,
            Custom,
        }

        /// Resource estimates for RTL patterns
        #[derive(Debug, Clone, Serialize, Deserialize)]
        pub struct ResourceEstimate {
            pub dsp_count: usize,
            pub bram_blocks: usize,
            pub lut_count: usize,
            pub ff_count: usize,
            pub estimated_power: f32,
        }

        /// Optimization impact predictions
        #[derive(Debug, Clone, Serialize, Deserialize)]
        pub struct OptimizationImpact {
            pub performance_improvement: f32,
            pub resource_reduction: f32,
            pub power_savings: f32,
            pub confidence_score: f32,
        }

        /// Advanced Loop Transformations
        #[derive(Debug, Clone, Serialize, Deserialize)]
        pub struct LoopTransformation {
            pub transform_type: LoopTransformType,
            pub target_loops: Vec<String>,
            pub tile_sizes: Vec<usize>,
            pub unroll_factor: usize,
            pub interchange_pattern: Vec<usize>,
            pub profitability_score: f32,
        }

        #[derive(Debug, Clone, Serialize, Deserialize, PartialEq, Eq)]
        pub enum LoopTransformType {
            Tiling,
            Interchange,
            Unrolling,
            Fusion,
            Fission,
            Blocking,
        }

        /// Inter-procedural Optimization
        #[derive(Debug, Clone, Serialize, Deserialize)]
        pub struct InterProceduralOptimization {
            pub inline_candidates: Vec<InlineCandidate>,
            pub dead_functions: Vec<String>,
            pub global_variables: Vec<GlobalVariableOptimization>,
            pub call_graph_optimizations: Vec<CallGraphOptimization>,
        }

        #[derive(Debug, Clone, Serialize, Deserialize)]
        pub struct InlineCandidate {
            pub call_site: String,
            pub function_id: String,
            pub profitability_score: f32,
            pub size_increase: usize,
            pub performance_benefit: f32,
        }

        #[derive(Debug, Clone, Serialize, Deserialize)]
        pub struct GlobalVariableOptimization {
            pub variable_id: String,
            pub optimization_type: GlobalVarOptimizationType,
            pub constant_value: Option<serde_json::Value>,
            pub elimination_benefit: f32,
        }

        #[derive(Debug, Clone, Serialize, Deserialize, PartialEq, Eq)]
        pub enum GlobalVarOptimizationType {
            ConstantPropagation,
            DeadStoreElimination,
            LoadStoreOptimization,
        }

        #[derive(Debug, Clone, Serialize, Deserialize)]
        pub struct CallGraphOptimization {
            pub optimization_type: CallGraphOptimizationType,
            pub affected_functions: Vec<String>,
            pub ordering_benefit: f32,
            pub placement_constraints: Vec<String>,
        }

        #[derive(Debug, Clone, Serialize, Deserialize, PartialEq, Eq)]
        pub enum CallGraphOptimizationType {
            FunctionOrdering,
            HotPathOptimization,
            ColdPathElimination,
            AffinityPlacement,
        }

        /// Data Structure Transformations
        #[derive(Debug, Clone, Serialize, Deserialize)]
        pub struct DataStructureTransformation {
            pub array_layouts: Vec<ArrayLayoutOptimization>,
            pub memory_pools: Vec<MemoryPoolOptimization>,
            pub cache_structures: Vec<CacheConsciousStructure>,
            pub vectorization_layouts: Vec<VectorizationLayout>,
        }

        #[derive(Debug, Clone, Serialize, Deserialize)]
        pub struct ArrayLayoutOptimization {
            pub array_id: String,
            pub current_layout: LayoutType,
            pub proposed_layout: LayoutType,
            pub access_pattern: String,
            pub cache_miss_reduction: f32,
            pub memory_bandwidth_improvement: f32,
        }

        #[derive(Debug, Clone, Serialize, Deserialize, PartialEq, Eq)]
        pub enum LayoutType {
            RowMajor,
            ColumnMajor,
            Blocked,
            Tiled,
            Custom,
        }

        #[derive(Debug, Clone, Serialize, Deserialize)]
        pub struct MemoryPoolOptimization {
            pub pool_type: MemoryPoolType,
            pub allocation_strategy: String,
            pub fragmentation_reduction: f32,
            pub memory_efficiency: f32,
            pub locality_improvement: f32,
        }

        #[derive(Debug, Clone, Serialize, Deserialize, PartialEq, Eq)]
        pub enum MemoryPoolType {
            StackBased,
            ArenaBased,
            CustomAllocator,
        }

        #[derive(Debug, Clone, Serialize, Deserialize)]
        pub struct CacheConsciousStructure {
            pub structure_type: CacheStructureType,
            pub padding_bytes: usize,
            pub alignment: usize,
            pub cache_line_utilization: f32,
            pub false_sharing_reduction: f32,
        }

        #[derive(Debug, Clone, Serialize, Deserialize, PartialEq, Eq)]
        pub enum CacheStructureType {
            PaddedStruct,
            AlignedArray,
            CacheLineOptimized,
        }

        #[derive(Debug, Clone, Serialize, Deserialize)]
        pub struct VectorizationLayout {
            pub data_structure: String,
            pub simd_width: usize,
            pub alignment: usize,
            pub memory_access_pattern: String,
            pub vectorization_efficiency: f32,
        }

        /// System-level Optimizations
        #[derive(Debug, Clone, Serialize, Deserialize)]
        pub struct SystemLevelOptimization {
            pub task_scheduling: Vec<TaskSchedulingOptimization>,
            pub communication_optimization: Vec<CommunicationOptimization>,
            pub energy_management: Vec<EnergyManagementOptimization>,
            pub fault_tolerance: Vec<FaultToleranceOptimization>,
        }

        #[derive(Debug, Clone, Serialize, Deserialize)]
        pub struct TaskSchedulingOptimization {
            pub schedule_type: ScheduleType,
            pub target_hardware: String,
            pub load_balancing_score: f32,
            pub throughput_improvement: f32,
            pub latency_reduction: f32,
        }

        #[derive(Debug, Clone, Serialize, Deserialize, PartialEq, Eq)]
        pub enum ScheduleType {
            StaticScheduling,
            DynamicScheduling,
            PriorityBased,
            HardwareAware,
        }

        #[derive(Debug, Clone, Serialize, Deserialize)]
        pub struct CommunicationOptimization {
            pub optimization_type: CommunicationOptimizationType,
            pub affected_tiles: Vec<String>,
            pub bandwidth_reduction: f32,
            pub latency_improvement: f32,
            pub energy_savings: f32,
        }

        #[derive(Debug, Clone, Serialize, Deserialize, PartialEq, Eq)]
        pub enum CommunicationOptimizationType {
            MessagePassingOptimization,
            SharedMemoryOptimization,
            NetworkTopologyOptimization,
            ProtocolOptimization,
        }

        #[derive(Debug, Clone, Serialize, Deserialize)]
        pub struct EnergyManagementOptimization {
            pub optimization_type: EnergyOptimizationType,
            pub power_states: Vec<PowerState>,
            pub thermal_constraints: Vec<ThermalConstraint>,
            pub energy_efficiency: f32,
            pub performance_tradeoff: f32,
        }

        #[derive(Debug, Clone, Serialize, Deserialize, PartialEq, Eq)]
        pub enum EnergyOptimizationType {
            DynamicVoltageFrequencyScaling,
            PowerGating,
            ClockGating,
            ThermalManagement,
        }

        #[derive(Debug, Clone, Serialize, Deserialize)]
        pub struct PowerState {
            pub state_type: PowerStateType,
            pub voltage: f32,
            pub frequency: f32,
            pub power_consumption: f32,
        }

        #[derive(Debug, Clone, Serialize, Deserialize, PartialEq, Eq)]
        pub enum PowerStateType {
            Active,
            Idle,
            Sleep,
            DeepSleep,
        }

        #[derive(Debug, Clone, Serialize, Deserialize)]
        pub struct ThermalConstraint {
            pub max_temperature: f32,
            pub cooling_strategy: String,
            pub thermal_resistance: f32,
            pub hotspot_mitigation: f32,
        }

        #[derive(Debug, Clone, Serialize, Deserialize)]
        pub struct FaultToleranceOptimization {
            pub optimization_type: FaultToleranceType,
            pub redundancy_level: usize,
            pub checkpoint_strategy: String,
            pub error_recovery_time: f32,
            pub reliability_improvement: f32,
        }

        #[derive(Debug, Clone, Serialize, Deserialize, PartialEq, Eq)]
        pub enum FaultToleranceType {
            CheckpointRestart,
            RedundantComputation,
            ErrorCorrectionCodes,
            FaultDetection,
        }

        /// Production-Ready Training Components
        #[derive(Debug, Clone, Serialize, Deserialize)]
        pub struct ProductionTrainingSystem {
            pub dataset_pipeline: DatasetPipeline,
            pub model_quantization: ModelQuantization,
            pub incremental_learning: IncrementalLearningSystem,
            pub build_integration: BuildSystemIntegration,
        }

        /// Real Dataset Pipeline for Industry Benchmarks
        #[derive(Debug, Clone, Serialize, Deserialize)]
        pub struct DatasetPipeline {
            pub benchmark_datasets: Vec<BenchmarkDataset>,
            pub hardware_profiles: Vec<HardwareProfile>,
            pub performance_metrics: Vec<PerformanceMetric>,
            pub preprocessing_config: PreprocessingConfig,
        }

        #[derive(Debug, Clone, Serialize, Deserialize)]
        pub struct BenchmarkDataset {
            pub name: String,
            pub dataset_type: BenchmarkType,
            pub source_path: String,
            pub hardware_metrics: Vec<HardwareMetric>,
            pub optimization_targets: Vec<String>,
            pub collection_timestamp: u64,
        }

        #[derive(Debug, Clone, Serialize, Deserialize, PartialEq, Eq)]
        pub enum BenchmarkType {
            SpecInt,
            SpecFp,
            PolyBench,
            Rodinia,
            Custom,
            Synthetic,
        }

        #[derive(Debug, Clone, Serialize, Deserialize)]
        pub struct HardwareMetric {
            pub hardware_type: HardwareType,
            pub performance_counters: PerformanceCounters,
            pub power_consumption: f32,
            pub thermal_data: ThermalData,
            pub memory_bandwidth: f32,
        }

        #[derive(Debug, Clone, Serialize, Deserialize, PartialEq, Eq)]
        pub enum HardwareType {
            Cpu,
            Gpu,
            Fpga,
            Cgra,
            Tpu,
            Asic,
        }

        #[derive(Debug, Clone, Serialize, Deserialize)]
        pub struct PerformanceCounters {
            pub cycles: u64,
            pub instructions: u64,
            pub cache_misses: u64,
            pub branch_mispredictions: u64,
            pub memory_accesses: u64,
        }

        #[derive(Debug, Clone, Serialize, Deserialize)]
        pub struct ThermalData {
            pub temperature: f32,
            pub hotspot_locations: Vec<(f32, f32)>,
            pub thermal_gradient: f32,
            pub cooling_efficiency: f32,
        }

        #[derive(Debug, Clone, Serialize, Deserialize)]
        pub struct HardwareProfile {
            pub profile_id: String,
            pub hardware_specs: HardwareSpecs,
            pub baseline_performance: BaselinePerformance,
            pub optimization_opportunities: Vec<OptimizationOpportunity>,
        }

        #[derive(Debug, Clone, Serialize, Deserialize)]
        pub struct HardwareSpecs {
            pub architecture: String,
            pub cores: usize,
            pub memory_gb: usize,
            pub cache_sizes: Vec<usize>,
            pub frequency_mhz: f32,
        }

        #[derive(Debug, Clone, Serialize, Deserialize)]
        pub struct BaselinePerformance {
            pub benchmark_name: String,
            pub execution_time: f32,
            pub power_consumption: f32,
            pub throughput: f32,
        }

        #[derive(Debug, Clone, Serialize, Deserialize)]
        pub struct OptimizationOpportunity {
            pub optimization_type: String,
            pub expected_improvement: f32,
            pub implementation_complexity: String,
            pub hardware_constraints: Vec<String>,
        }

        #[derive(Debug, Clone, Serialize, Deserialize)]
        pub struct PerformanceMetric {
            pub metric_name: String,
            pub value: f64,
            pub unit: String,
            pub timestamp: u64,
            pub benchmark: String,
            pub hardware: String,
        }

        #[derive(Debug, Clone, Serialize, Deserialize)]
        pub struct PreprocessingConfig {
            pub normalization: NormalizationType,
            pub feature_selection: Vec<String>,
            pub outlier_detection: OutlierDetectionConfig,
            pub data_augmentation: DataAugmentationConfig,
        }

        #[derive(Debug, Clone, Serialize, Deserialize, PartialEq, Eq)]
        pub enum NormalizationType {
            MinMax,
            ZScore,
            Robust,
            None,
        }

        #[derive(Debug, Clone, Serialize, Deserialize)]
        pub struct OutlierDetectionConfig {
            pub method: String,
            pub threshold: f32,
            pub contamination: f32,
        }

        #[derive(Debug, Clone, Serialize, Deserialize)]
        pub struct DataAugmentationConfig {
            pub augmentation_types: Vec<String>,
            pub augmentation_factor: f32,
            pub noise_level: f32,
        }

        /// Model Quantization for Production Deployment
        #[derive(Debug, Clone, Serialize, Deserialize)]
        pub struct ModelQuantization {
            pub quantization_config: QuantizationConfig,
            pub compressed_models: Vec<CompressedModel>,
            pub quantization_stats: QuantizationStatistics,
            pub deployment_targets: Vec<DeploymentTarget>,
        }

        #[derive(Debug, Clone, Serialize, Deserialize)]
        pub struct QuantizationConfig {
            pub quantization_type: QuantizationType,
            pub bit_width: usize,
            pub calibration_method: CalibrationMethod,
            pub hardware_backend: HardwareBackend,
        }

        #[derive(Debug, Clone, Serialize, Deserialize, PartialEq, Eq)]
        pub enum QuantizationType {
            PostTrainingQuantization,
            QuantizationAwareTraining,
            DynamicQuantization,
            StaticQuantization,
        }

        #[derive(Debug, Clone, Serialize, Deserialize, PartialEq, Eq)]
        pub enum CalibrationMethod {
            MinMaxCalibration,
            PercentileCalibration,
            EntropyCalibration,
            MSECalibration,
        }

        #[derive(Debug, Clone, Serialize, Deserialize, PartialEq, Eq)]
        pub enum HardwareBackend {
            Cpu,
            Gpu,
            Fpga,
            Tpu,
            EdgeDevices,
        }

        #[derive(Debug, Clone, Serialize, Deserialize)]
        pub struct CompressedModel {
            pub model_id: String,
            pub original_size: usize,
            pub compressed_size: usize,
            pub compression_ratio: f32,
            pub accuracy_retention: f32,
            pub quantization_format: String,
        }

        #[derive(Debug, Clone, Serialize, Deserialize)]
        pub struct QuantizationStatistics {
            pub accuracy_loss: f32,
            pub model_size_reduction: f32,
            pub inference_speedup: f32,
            pub memory_savings: f32,
        }

        #[derive(Debug, Clone, Serialize, Deserialize)]
        pub struct DeploymentTarget {
            pub target_name: String,
            pub hardware_constraints: HardwareConstraints,
            pub optimization_goals: Vec<String>,
            pub deployment_format: String,
        }

        /// Incremental Learning System
        #[derive(Debug, Clone, Serialize, Deserialize)]
        pub struct IncrementalLearningSystem {
            pub learning_config: IncrementalLearningConfig,
            pub model_updates: Vec<ModelUpdate>,
            pub feedback_loop: FeedbackLoopConfig,
            pub adaptation_strategies: Vec<AdaptationStrategy>,
        }

        #[derive(Debug, Clone, Serialize, Deserialize)]
        pub struct IncrementalLearningConfig {
            pub update_frequency: UpdateFrequency,
            pub learning_rate_schedule: LearningRateSchedule,
            pub batch_size: usize,
            pub memory_buffer_size: usize,
        }

        #[derive(Debug, Clone, Serialize, Deserialize, PartialEq, Eq)]
        pub enum UpdateFrequency {
            Continuous,
            Periodic(u64),
            EventDriven,
        }

        #[derive(Debug, Clone, Serialize, Deserialize, PartialEq)]
        pub enum LearningRateSchedule {
            Constant(f32),
            ExponentialDecay(f32),
            StepDecay(u64, f32),
            Adaptive,
        }

        #[derive(Debug, Clone, Serialize, Deserialize)]
        pub struct ModelUpdate {
            pub update_id: String,
            pub timestamp: u64,
            pub update_type: UpdateType,
            pub accuracy_change: f32,
            pub performance_change: f32,
        }

        #[derive(Debug, Clone, Serialize, Deserialize, PartialEq, Eq)]
        pub enum UpdateType {
            ParameterUpdate,
            ArchitectureUpdate,
            HyperparameterUpdate,
        }

        #[derive(Debug, Clone, Serialize, Deserialize)]
        pub struct FeedbackLoopConfig {
            pub feedback_sources: Vec<String>,
            pub performance_thresholds: PerformanceThresholds,
            pub adaptation_triggers: Vec<AdaptationTrigger>,
        }

        #[derive(Debug, Clone, Serialize, Deserialize)]
        pub struct PerformanceThresholds {
            pub accuracy_threshold: f32,
            pub performance_threshold: f32,
            pub resource_threshold: f32,
        }

        #[derive(Debug, Clone, Serialize, Deserialize, PartialEq)]
        pub enum AdaptationTrigger {
            AccuracyDrop(f32),
            PerformanceDegradation(f32),
            ResourceConstraint(String),
        }

        #[derive(Debug, Clone, Serialize, Deserialize)]
        pub struct AdaptationStrategy {
            pub strategy_name: String,
            pub strategy_type: StrategyType,
            pub parameters: HashMap<String, String>,
            pub expected_outcome: String,
        }

        #[derive(Debug, Clone, Serialize, Deserialize, PartialEq, Eq)]
        pub enum StrategyType {
            ModelRetraining,
            HyperparameterTuning,
            ArchitectureModification,
            DataRebalancing,
        }

        /// Build System Integration
        #[derive(Debug, Clone, Serialize, Deserialize)]
        pub struct BuildSystemIntegration {
            pub cmake_integration: CMakeIntegration,
            pub make_integration: MakeIntegration,
            pub ninja_integration: NinjaIntegration,
            pub deployment_scripts: Vec<DeploymentScript>,
        }

        #[derive(Debug, Clone, Serialize, Deserialize)]
        pub struct CMakeIntegration {
            pub cmake_version: String,
            pub cmake_files: Vec<String>,
            pub build_targets: Vec<BuildTarget>,
            pub configuration_options: HashMap<String, String>,
        }

        #[derive(Debug, Clone, Serialize, Deserialize)]
        pub struct MakeIntegration {
            pub makefile_path: String,
            pub make_targets: Vec<String>,
            pub dependencies: Vec<String>,
            pub compiler_flags: Vec<String>,
        }

        #[derive(Debug, Clone, Serialize, Deserialize)]
        pub struct NinjaIntegration {
            pub ninja_file: String,
            pub build_directory: String,
            pub ninja_targets: Vec<String>,
            pub toolchain_config: ToolchainConfig,
        }

        #[derive(Debug, Clone, Serialize, Deserialize)]
        pub struct ToolchainConfig {
            pub compiler_path: String,
            pub linker_path: String,
            pub archiver_path: String,
            pub optimization_flags: Vec<String>,
        }

        #[derive(Debug, Clone, Serialize, Deserialize)]
        pub struct BuildTarget {
            pub target_name: String,
            pub target_type: TargetType,
            pub sources: Vec<String>,
            pub dependencies: Vec<String>,
        }

        #[derive(Debug, Clone, Serialize, Deserialize, PartialEq, Eq)]
        pub enum TargetType {
            Executable,
            StaticLibrary,
            SharedLibrary,
            ObjectLibrary,
        }

        #[derive(Debug, Clone, Serialize, Deserialize)]
        pub struct DeploymentScript {
            pub script_name: String,
            pub script_type: ScriptType,
            pub execution_environment: String,
            pub dependencies: Vec<String>,
        }

        #[derive(Debug, Clone, Serialize, Deserialize, PartialEq, Eq)]
        pub enum ScriptType {
            Bash,
            Python,
            PowerShell,
            Batch,
        }

    /// Training sample for GNN optimization model
    #[derive(Debug, Clone, Serialize, Deserialize)]
    pub struct TrainingSample {
        pub pih: ProgramInteractionHypergraph,
        pub features: GnnFeatures,
        pub labels: OptimizationLabels,
        pub sample_id: String,
    }

    /// Labels for optimization outcomes
    #[derive(Debug, Clone, Serialize, Deserialize)]
    pub struct OptimizationLabels {
        pub rule_applications: Vec<String>, // Applied rule names
        pub performance_gain: f32, // Expected performance improvement (0.0-1.0)
        pub memory_reduction: f32, // Memory usage reduction (0.0-1.0)
        pub energy_savings: f32, // Energy consumption reduction (0.0-1.0)
    }

    /// GNN model for optimization prediction (Extensible Architecture)
    #[derive(Debug, Clone, Serialize, Deserialize)]
    pub struct OptimizationGnn {
        pub hidden_dim: usize,
        pub num_layers: usize,
        pub dropout: f32,
        pub weights: Vec<Vec<Vec<f32>>>, // Simplified weight representation
        pub model_type: GnnModelType, // Support multiple GNN architectures
        pub attention_heads: usize, // Multi-head attention support
    }

    /// Supported GNN model types
    #[derive(Debug, Clone, Serialize, Deserialize, PartialEq, Eq)]
    pub enum GnnModelType {
        /// Basic Bipartite GNN (current implementation)
        BipartiteGnn,
        /// Graph Attention Networks
        Gat,
        /// Graph Convolutional Networks
        Gcn,
        /// GraphSAGE (Inductive Learning)
        GraphSage,
        /// Heterogeneous Graph Transformer
        HetGnn,
    }

    /// GNN training configuration
    #[derive(Debug, Clone)]
    pub struct TrainingConfig {
        pub learning_rate: f32,
        pub batch_size: usize,
        pub num_epochs: usize,
        pub hidden_dim: usize,
        pub num_layers: usize,
        pub dropout: f32,
    }

    /// Training statistics
    #[derive(Debug, Clone)]
    pub struct TrainingStats {
        pub epoch: usize,
        pub loss: f32,
        pub accuracy: f32,
        pub precision: f32,
        pub recall: f32,
    }

    impl Default for TrainingConfig {
        fn default() -> Self {
            Self {
                learning_rate: 0.001,
                batch_size: 32,
                num_epochs: 100,
                hidden_dim: 64,
                num_layers: 3,
                dropout: 0.1,
            }
        }
    }

    impl Default for OptimizationGnn {
        fn default() -> Self {
            Self {
                hidden_dim: 64,
                num_layers: 3,
                dropout: 0.1,
                weights: Vec::new(), // Will be initialized by create_model
                model_type: GnnModelType::BipartiteGnn,
                attention_heads: 4,
            }
        }
    }

    /// GAT (Graph Attention Networks) Implementation
    pub mod gat {
        use super::*;
        use std::collections::hash_map::DefaultHasher;
        use std::hash::{Hash, Hasher};
        use std::collections::HashMap;

        /// Graph Attention Layer for heterogeneous bipartite graphs
        pub struct GatLayer {
            pub input_dim: usize,
            pub output_dim: usize,
            pub num_heads: usize,
            pub dropout: f32,
            pub concat_heads: bool,
            // Attention weights: W for each head
            pub attention_weights: Vec<Vec<Vec<f32>>>,
            // Attention mechanism parameters
            pub a_weights: Vec<Vec<f32>>, // Attention coefficients
            pub bias: Option<Vec<f32>>,
        }

        impl GatLayer {
            pub fn new(input_dim: usize, output_dim: usize, num_heads: usize, dropout: f32, concat_heads: bool) -> Self {
                let mut attention_weights = Vec::new();
                let mut a_weights = Vec::new();

                // Initialize weights for each attention head
                for head in 0..num_heads {
                    let mut head_weights = Vec::new();
                    for _ in 0..output_dim {
                        let mut node_weights = Vec::new();
                        for _ in 0..input_dim {
                            // Random initialization
                            use std::collections::hash_map::DefaultHasher;
                            use std::hash::{Hash, Hasher};
                            let mut hasher = DefaultHasher::new();
                            head.hash(&mut hasher);
                            let hash = hasher.finish();
                            let random = (hash % 1000) as f32 / 1000.0 - 0.5;
                            node_weights.push(random * 0.1);
                        }
                        head_weights.push(node_weights);
                    }
                    attention_weights.push(head_weights);

                    // Attention coefficients (a) for each head
                    let mut a_head = Vec::new();
                    for _ in 0..2 { // For source and target nodes
                        let mut hasher = DefaultHasher::new();
                        head.hash(&mut hasher);
                        let hash = hasher.finish();
                        let random = (hash % 1000) as f32 / 1000.0 - 0.5;
                        a_head.push(random * 0.1);
                    }
                    a_weights.push(a_head);
                }

                Self {
                    input_dim,
                    output_dim,
                    num_heads,
                    dropout,
                    concat_heads,
                    attention_weights,
                    a_weights,
                    bias: Some(vec![0.0; output_dim]),
                }
            }

            /// Compute attention coefficients between source and target nodes
            pub fn compute_attention_coefficients(
                &self,
                source_embedding: &[f32],
                target_embedding: &[f32],
                edge_features: Option<&[f32]>,
                head_idx: usize
            ) -> f32 {
                let a_weights = &self.a_weights[head_idx];

                // Linear transformation for source and target
                let source_transformed = self.transform_node(source_embedding, head_idx);
                let target_transformed = self.transform_node(target_embedding, head_idx);

                // Concatenate transformed embeddings
                let mut concatenated = Vec::new();
                concatenated.extend_from_slice(&source_transformed);
                concatenated.extend_from_slice(&target_transformed);

                // Add edge features if available
                if let Some(edge_feats) = edge_features {
                    concatenated.extend_from_slice(edge_feats);
                }

                // Apply attention mechanism: a^T * LeakyReLU(concatenation)
                let mut attention_score = 0.0;
                for (i, &value) in concatenated.iter().enumerate() {
                    if i < a_weights.len() {
                        attention_score += a_weights[i] * value.max(0.0); // LeakyReLU
                    }
                }

                attention_score
            }

            /// Transform node embedding using attention head weights
            fn transform_node(&self, node_embedding: &[f32], head_idx: usize) -> Vec<f32> {
                let weights = &self.attention_weights[head_idx];
                weights.iter().map(|weight_row| {
                    node_embedding.iter().zip(weight_row.iter())
                        .map(|(&node_val, &weight_val)| node_val * weight_val)
                        .sum::<f32>()
                }).collect()
            }

            /// Apply GAT layer to bipartite graph
            pub fn forward(
                &self,
                event_embeddings: &HashMap<String, Vec<f32>>,
                entity_embeddings: &HashMap<String, Vec<f32>>,
                edge_features: &[(String, String, Vec<f32>)],
            ) -> (HashMap<String, Vec<f32>>, HashMap<String, Vec<f32>>) {
                let mut new_event_embeddings = HashMap::new();
                let mut new_entity_embeddings = HashMap::new();

                // Process entities (update based on connected events)
                for (entity_id, entity_embedding) in entity_embeddings {
                    let connected_events = Self::get_connected_events(entity_id, edge_features);
                    let mut attention_weights = Vec::new();
                    let mut neighbor_embeddings = Vec::new();

                    // Compute attention for each connected event
                    for event_id in &connected_events {
                        if let Some(event_embedding) = event_embeddings.get(event_id) {
                            // Find edge features for this connection
                            let edge_feats = edge_features.iter()
                                .find(|(src, tgt, _)| src == event_id && tgt == entity_id)
                                .map(|(_, _, feats)| feats.as_slice());

                            let attention_coeff = self.compute_attention_coefficients(
                                event_embedding,
                                entity_embedding,
                                edge_feats,
                                0 // Use first head for simplicity
                            );

                            attention_weights.push(attention_coeff.exp());
                            neighbor_embeddings.push(event_embedding.clone());
                        }
                    }

                    // Normalize attention weights
                    let sum_attention: f32 = attention_weights.iter().sum();
                    if sum_attention > 0.0 {
                        for weight in &mut attention_weights {
                            *weight /= sum_attention;
                        }
                    }

                    // Aggregate neighbor embeddings with attention
                    let mut aggregated = vec![0.0; self.output_dim];
                    for (i, embedding) in neighbor_embeddings.iter().enumerate() {
                        let weight = attention_weights[i];
                        for (j, &value) in embedding.iter().enumerate() {
                            if j < aggregated.len() {
                                aggregated[j] += weight * value;
                            }
                        }
                    }

                    new_entity_embeddings.insert(entity_id.clone(), aggregated);
                }

                // Process events (update based on connected entities - hypergraph aware)
                for (event_id, event_embedding) in event_embeddings {
                    let connected_entities = Self::get_connected_entities(event_id, edge_features);
                    let mut attention_weights = Vec::new();
                    let mut neighbor_embeddings = Vec::new();

                    // Compute attention for each connected entity
                    for entity_id in &connected_entities {
                        if let Some(entity_embedding) = entity_embeddings.get(entity_id) {
                            // Find edge features for this connection
                            let edge_feats = edge_features.iter()
                                .find(|(src, tgt, _)| src == event_id && tgt == entity_id)
                                .map(|(_, _, feats)| feats.as_slice());

                            let attention_coeff = self.compute_attention_coefficients(
                                event_embedding,
                                entity_embedding,
                                edge_feats,
                                0 // Use first head for simplicity
                            );

                            attention_weights.push(attention_coeff.exp());
                            neighbor_embeddings.push(entity_embedding.clone());
                        }
                    }

                    // Normalize attention weights
                    let sum_attention: f32 = attention_weights.iter().sum();
                    if sum_attention > 0.0 {
                        for weight in &mut attention_weights {
                            *weight /= sum_attention;
                        }
                    }

                    // Aggregate neighbor embeddings with attention (hypergraph-aware)
                    let mut aggregated = vec![0.0; self.output_dim];
                    for (i, embedding) in neighbor_embeddings.iter().enumerate() {
                        let weight = attention_weights[i];
                        for (j, &value) in embedding.iter().enumerate() {
                            if j < aggregated.len() {
                                aggregated[j] += weight * value;
                            }
                        }
                    }

                    new_event_embeddings.insert(event_id.clone(), aggregated);
                }

                (new_event_embeddings, new_entity_embeddings)
            }

            fn get_connected_events(entity_id: &str, edge_features: &[(String, String, Vec<f32>)]) -> Vec<String> {
                edge_features.iter()
                    .filter(|(_, target, _)| target == entity_id)
                    .map(|(source, _, _)| source.clone())
                    .collect()
            }

            fn get_connected_entities(event_id: &str, edge_features: &[(String, String, Vec<f32>)]) -> Vec<String> {
                edge_features.iter()
                    .filter(|(source, _, _)| source == event_id)
                    .map(|(_, target, _)| target.clone())
                    .collect()
            }
        }
    }

    /// Feature extractor for PIH to GNN training data
    pub struct FeatureExtractor;

    impl FeatureExtractor {
        /// Extract features from PIH for GNN training
        pub fn extract_features(pih: &ProgramInteractionHypergraph) -> GnnFeatures {
            let mut node_features = HashMap::new();
            let mut edge_features = Vec::new();
            let mut node_hyperedge_membership = HashMap::new();

            // Count event and entity nodes
            let event_node_count = pih.events.len();
            let entity_node_count = pih.entities.len();

            // Extract node features (events and entities)
            for (event_id, event) in &pih.events {
                let features = Self::extract_event_features(event);
                node_features.insert(format!("event_{}", event_id), features);
                node_hyperedge_membership.insert(format!("event_{}", event_id), 1); // Events are hyperedges
            }

            for (entity_id, entity) in &pih.entities {
                let features = Self::extract_entity_features(entity);
                node_features.insert(format!("entity_{}", entity_id), features);

                // Count hyperedge membership for entities
                let hyperedge_count = pih.incidence.iter()
                    .filter(|inc| inc.entity == *entity_id)
                    .count();
                node_hyperedge_membership.insert(format!("entity_{}", entity_id), hyperedge_count);
            }

            // Extract edge features (incidence relationships)
            for incidence in &pih.incidence {
                let source = format!("event_{}", incidence.event);
                let target = format!("entity_{}", incidence.entity);
                let features = Self::extract_incidence_features(incidence);
                edge_features.push((source, target, features));
            }

            // Extract global features (PIH-level statistics)
            let global_features = Self::extract_global_features(pih);

            // Extract bipartite features
            let bipartite_features = Self::extract_bipartite_features(pih, event_node_count, entity_node_count);

            // Extract hypergraph features
            let hypergraph_features = Self::extract_hypergraph_features(pih, &node_hyperedge_membership);

            // Extract hardware-specific features
            let hardware_features = Self::extract_hardware_features(pih);

            // Extract advanced compiler transformation features
            let loop_transformations = Self::analyze_loop_transformations(pih);
            let inter_procedural_optimizations = Self::analyze_inter_procedural_optimizations(pih);
            let data_structure_transformations = Self::analyze_data_structure_transformations(pih);
            let system_level_optimizations = Self::analyze_system_level_optimizations(pih);

            // Extract production-ready training features
            let production_training = Self::analyze_production_training_features(pih);

            GnnFeatures {
                node_features,
                edge_features,
                global_features,
                bipartite_features,
                hypergraph_features,
                hardware_features,
                loop_transformations,
                inter_procedural_optimizations,
                data_structure_transformations,
                system_level_optimizations,
                production_training,
            }
        }

        fn extract_event_features(event: &Event) -> Vec<f32> {
            let mut features = Vec::new();

            // Opcode encoding (one-hot style)
            features.push(if event.opcode == "add" { 1.0 } else { 0.0 });
            features.push(if event.opcode == "mul" { 1.0 } else { 0.0 });
            features.push(if event.opcode == "for" { 1.0 } else { 0.0 });
            features.push(if event.opcode == "parallel_for" { 1.0 } else { 0.0 });

            // Data type encoding
            features.push(if event.dtype == "i32" { 1.0 } else { 0.0 });
            features.push(if event.dtype == "f32" { 1.0 } else { 0.0 });

            // Exception handling capability
            features.push(if event.can_throw { 1.0 } else { 0.0 });

            // Attributes count
            features.push(event.attributes.len() as f32);

            features
        }

        fn extract_entity_features(entity: &Entity) -> Vec<f32> {
            let mut features = Vec::new();

            // Entity kind encoding
            features.push(match entity.kind {
                EntityKind::Val => 1.0,
                EntityKind::State => 0.0,
                EntityKind::Obj => 0.5,
                EntityKind::Ctrl => 0.5,
            });

            // Data type encoding
            features.push(if entity.entity_type == "i32*" { 1.0 } else { 0.0 });
            features.push(if entity.entity_type == "f32*" { 1.0 } else { 0.0 });
            features.push(if entity.entity_type == "__m128i" { 1.0 } else { 0.0 });

            // Attribute features
            features.push(if entity.attributes.contains_key("is_const") { 1.0 } else { 0.0 });
            features.push(entity.attributes.len() as f32);

            // Constant value (if available)
            if let Some(value) = entity.attributes.get("value") {
                if let Some(num) = value.as_f64() {
                    features.push(num as f32);
                } else {
                    features.push(0.0);
                }
            } else {
                features.push(0.0);
            }

            features
        }

        fn extract_incidence_features(incidence: &Incidence) -> Vec<f32> {
            let mut features = Vec::new();

            // Port type encoding
            features.push(if matches!(incidence.role, RoleKind::DataIn) { 1.0 } else { 0.0 });
            features.push(if matches!(incidence.role, RoleKind::DataOut) { 1.0 } else { 0.0 });
            features.push(if matches!(incidence.role, RoleKind::StateIn) || matches!(incidence.role, RoleKind::StateOut) { 1.0 } else { 0.0 });

            // Port index (if available)
            if let Some(idx) = incidence.idx {
                let idx_f32 = idx as f32;
                features.push(idx_f32);
            } else {
                features.push(0.0);
            }

            features
        }

        fn extract_global_features(pih: &ProgramInteractionHypergraph) -> Vec<f32> {
            let mut features = Vec::new();

            // Graph statistics
            features.push(pih.edges.len() as f32);
            features.push(pih.nodes.len() as f32);
            features.push(pih.incidences.len() as f32);

            // Edge type distribution
            let add_count = pih.edges.iter().filter(|e| e.attributes.get("opcode") == Some(&json!("add"))).count() as f32;
            let mul_count = pih.edges.iter().filter(|e| e.attributes.get("opcode") == Some(&json!("mul"))).count() as f32;
            let loop_count = pih.edges.iter().filter(|e| e.attributes.get("opcode") == Some(&json!("for"))).count() as f32;

            features.push(add_count / pih.edges.len() as f32);
            features.push(mul_count / pih.edges.len() as f32);
            features.push(loop_count / pih.edges.len() as f32);

            // Node type distribution
            let val_count = pih.nodes.iter().filter(|n| matches!(n.kind, NodeKind::Val)).count() as f32;
            let state_count = pih.nodes.iter().filter(|n| matches!(n.kind, NodeKind::State)).count() as f32;

            features.push(val_count / pih.nodes.len() as f32);
            features.push(state_count / pih.nodes.len() as f32);

            features
        }

        fn extract_bipartite_features(
            pih: &ProgramInteractionHypergraph,
            edge_count: usize,
            node_count: usize
        ) -> BipartiteFeatures {
            // Count edges by type
            let node_to_edge_connections = pih.incidences.len();
            let edge_to_node_connections = pih.incidences.len(); // Same count for now

            // Node type distribution
            let total_nodes = edge_count + node_count;
            let edge_ratio = edge_count as f32 / total_nodes as f32;
            let node_ratio = node_count as f32 / total_nodes as f32;

            // Cross-type connectivity (edges connecting different node types)
            let cross_type_connectivity = event_to_entity_edges as f32 / total_nodes as f32;

            BipartiteFeatures {
                edge_node_count: edge_count,
                node_count: node_count,
                edge_to_node_connections: node_to_edge_connections,
                node_to_edge_connections: node_to_edge_connections,
                node_type_distribution: vec![edge_ratio, node_ratio],
                cross_type_connectivity,
            }
        }

        fn extract_hypergraph_features(
            pih: &ProgramInteractionHypergraph,
            node_hyperedge_membership: &HashMap<String, usize>
        ) -> HypergraphFeatures {
            // Calculate hyperedge sizes (number of entities per event)
            let mut hyperedge_sizes = Vec::new();
            let mut hyperedge_degree_distribution = HashMap::new();

            for event in pih.events.values() {
                let hyperedge_size = pih.incidence.iter()
                    .filter(|inc| inc.event == event.id)
                    .count();
                hyperedge_sizes.push(hyperedge_size);

                *hyperedge_degree_distribution.entry(hyperedge_size).or_insert(0) += 1;
            }

            // Statistics
            let avg_hyperedge_size = if hyperedge_sizes.is_empty() {
                0.0
            } else {
                hyperedge_sizes.iter().sum::<usize>() as f32 / hyperedge_sizes.len() as f32
            };
            let max_hyperedge_size = *hyperedge_sizes.iter().max().unwrap_or(&0);

            // Degree distribution as vector
            let max_degree = *hyperedge_degree_distribution.keys().max().unwrap_or(&0);
            let mut degree_dist = vec![0.0; max_degree + 1];
            for (degree, count) in hyperedge_degree_distribution {
                if degree < degree_dist.len() {
                    degree_dist[degree] = count as f32;
                }
            }

            // Hypergraph clustering coefficient (simplified)
            let hypergraph_clustering_coeff = if pih.events.is_empty() {
                0.0
            } else {
                avg_hyperedge_size / pih.entities.len() as f32
            };

            HypergraphFeatures {
                hyperedge_sizes,
                avg_hyperedge_size,
                max_hyperedge_size,
                hyperedge_degree_distribution: degree_dist,
                node_hyperedge_membership: node_hyperedge_membership.clone(),
                hypergraph_clustering_coeff,
            }
        }

        fn extract_hardware_features(pih: &ProgramInteractionHypergraph) -> HardwareFeatures {
            let cgra_features = Self::extract_cgra_features(pih);
            let fpga_features = Self::extract_fpga_features(pih);
            let hardware_constraints = Self::extract_hardware_constraints(pih);

            HardwareFeatures {
                cgra_features,
                fpga_features,
                hardware_constraints,
            }
        }

        fn extract_cgra_features(pih: &ProgramInteractionHypergraph) -> CgraFeatures {
            // Analyze PIH for CGRA patterns
            let spatial_patterns = Self::analyze_spatial_patterns(pih);
            let dataflow_type = Self::analyze_dataflow_type(pih);
            let (memory_bandwidth, compute_intensity) = Self::analyze_compute_memory_patterns(pih);

            CgraFeatures {
                spatial_patterns,
                pipeline_depth: Self::estimate_pipeline_depth(pih),
                dataflow_type,
                memory_bandwidth,
                compute_intensity,
                parallelism_degree: Self::estimate_parallelism_degree(pih),
            }
        }

        fn extract_fpga_features(pih: &ProgramInteractionHypergraph) -> FpgaFeatures {
            let rtl_patterns = Self::analyze_rtl_patterns(pih);
            let resource_utilization = Self::estimate_resource_utilization(pih);
            let timing_constraints = Self::analyze_timing_constraints(pih);
            let synthesis_directives = Self::generate_synthesis_directives(pih);
            let placement_constraints = Self::generate_placement_constraints(pih);

            FpgaFeatures {
                rtl_patterns,
                resource_utilization,
                timing_constraints,
                synthesis_directives,
                placement_constraints,
            }
        }

        fn extract_hardware_constraints(pih: &ProgramInteractionHypergraph) -> HardwareConstraints {
            // Estimate hardware constraints based on PIH characteristics
            let memory_usage = Self::estimate_memory_usage(pih);
            let compute_units = Self::estimate_compute_units(pih);
            let bandwidth = Self::estimate_bandwidth(pih);

            HardwareConstraints {
                max_memory_usage: memory_usage * 2, // 2x safety margin
                max_compute_units: compute_units * 2,
                max_bandwidth: bandwidth * 1.5, // 1.5x safety margin
                max_power_consumption: 100.0, // Default power limit
                max_temperature: 85.0, // Default temperature limit
                target_frequency: 200.0, // Default target frequency in MHz
            }
        }

        fn analyze_spatial_patterns(pih: &ProgramInteractionHypergraph) -> Vec<SpatialPattern> {
            let mut patterns = Vec::new();

            // Analyze loop structures for spatial patterns
            for event in pih.events.values() {
                if event.opcode == "for" {
                    if let Some(pattern) = Self::analyze_loop_spatial_pattern(event, pih) {
                        patterns.push(pattern);
                    }
                }
            }

            // Also analyze CGRA compute events
            for event in pih.events.values() {
                if event.opcode == "cgra_compute" {
                    if let Some(pattern) = Self::analyze_cgra_spatial_pattern(event) {
                        patterns.push(pattern);
                    }
                }
            }

            patterns
        }

        fn analyze_loop_spatial_pattern(event: &Event, pih: &ProgramInteractionHypergraph) -> Option<SpatialPattern> {
            // Simple heuristic: detect matrix multiplication patterns
            let connected_entities = pih.incidence.iter()
                .filter(|inc| inc.event == event.id)
                .count();

            if connected_entities >= 4 { // Likely matrix operations
                Some(SpatialPattern {
                    pattern_type: SpatialPatternType::SystolicArray,
                    grid_size: (2, 2),
                    dataflow_pattern: "systolic".to_string(),
                    memory_access_pattern: "blocked".to_string(),
                    compute_distribution: vec![0.25, 0.25, 0.25, 0.25],
                })
            } else if connected_entities >= 2 {
                Some(SpatialPattern {
                    pattern_type: SpatialPatternType::Dataflow,
                    grid_size: (1, connected_entities),
                    dataflow_pattern: "linear".to_string(),
                    memory_access_pattern: "streaming".to_string(),
                    compute_distribution: vec![1.0 / connected_entities as f32; connected_entities],
                })
            } else {
                None
            }
        }

        fn analyze_cgra_spatial_pattern(event: &Event) -> Option<SpatialPattern> {
            // Analyze CGRA compute events for spatial patterns
            if let Some(pattern_value) = event.attributes.get("pattern") {
                if let Some(pattern_str) = pattern_value.as_str() {
                    if pattern_str == "systolic_array" {
                        return Some(SpatialPattern {
                            pattern_type: SpatialPatternType::SystolicArray,
                            grid_size: (2, 2),
                            dataflow_pattern: "systolic".to_string(),
                            memory_access_pattern: "blocked".to_string(),
                            compute_distribution: vec![0.25, 0.25, 0.25, 0.25],
                        });
                    }
                }
            }

            // Default dataflow pattern
            Some(SpatialPattern {
                pattern_type: SpatialPatternType::Dataflow,
                grid_size: (1, 1),
                dataflow_pattern: "linear".to_string(),
                memory_access_pattern: "streaming".to_string(),
                compute_distribution: vec![1.0],
            })
        }

        fn analyze_dataflow_type(pih: &ProgramInteractionHypergraph) -> DataflowType {
            let loop_count = pih.events.values().filter(|e| e.opcode == "for").count();
            let cgra_count = pih.events.values().filter(|e| e.opcode == "cgra_compute").count();

            if cgra_count > 0 {
                // If we have CGRA compute events, use spatial patterns
                DataflowType::DataParallel
            } else if loop_count > 3 {
                DataflowType::Pipeline
            } else if loop_count > 1 {
                DataflowType::DataParallel
            } else {
                DataflowType::Stream
            }
        }

        fn analyze_compute_memory_patterns(pih: &ProgramInteractionHypergraph) -> (f32, f32) {
            let compute_ops = pih.events.values().filter(|e| e.opcode == "mul" || e.opcode == "add").count();
            let memory_ops = pih.events.values().filter(|e| e.opcode == "load" || e.opcode == "store").count();

            let memory_bandwidth = memory_ops as f32 * 64.0; // Assume 64-bit operations
            let compute_intensity = if memory_ops > 0 {
                compute_ops as f32 / memory_ops as f32
            } else {
                1.0
            };

            (memory_bandwidth, compute_intensity)
        }

        fn estimate_pipeline_depth(pih: &ProgramInteractionHypergraph) -> usize {
            // Simple estimation based on operation count
            let operation_count = pih.events.len();
            if operation_count > 10 {
                4
            } else if operation_count > 5 {
                3
            } else {
                2
            }
        }

        fn estimate_parallelism_degree(pih: &ProgramInteractionHypergraph) -> usize {
            let loop_count = pih.events.values().filter(|e| e.opcode == "for").count();
            let array_count = pih.entities.values().filter(|e| e.entity_type.ends_with('*')).count();

            (loop_count + array_count).max(1)
        }

        fn analyze_rtl_patterns(pih: &ProgramInteractionHypergraph) -> Vec<RtlPattern> {
            let mut patterns = Vec::new();

            // Detect arithmetic patterns
            let mul_count = pih.events.values().filter(|e| e.opcode == "mul").count();
            let add_count = pih.events.values().filter(|e| e.opcode == "add").count();

            // Also check for FPGA compute events
            let fpga_count = pih.events.values().filter(|e| e.opcode == "fpga_compute").count();

            if fpga_count > 0 {
                // FPGA compute events should generate RTL patterns
                patterns.push(RtlPattern {
                    pattern_type: RtlPatternType::PipelinedMultiplier,
                    module_template: "fpga_compute_unit".to_string(),
                    resource_estimate: ResourceEstimate {
                        dsp_count: fpga_count,
                        bram_blocks: fpga_count / 2,
                        lut_count: fpga_count * 200,
                        ff_count: fpga_count * 100,
                        estimated_power: fpga_count as f32 * 3.0,
                    },
                    timing_estimate: 8.0, // 8ns delay for FPGA
                });
            }

            if mul_count > 0 {
                patterns.push(RtlPattern {
                    pattern_type: RtlPatternType::PipelinedMultiplier,
                    module_template: "pipelined_mult".to_string(),
                    resource_estimate: ResourceEstimate {
                        dsp_count: mul_count,
                        bram_blocks: 0,
                        lut_count: mul_count * 100,
                        ff_count: mul_count * 50,
                        estimated_power: mul_count as f32 * 2.5,
                    },
                    timing_estimate: 5.0, // 5ns delay
                });
            }

            if add_count > 0 {
                patterns.push(RtlPattern {
                    pattern_type: RtlPatternType::ParallelAdder,
                    module_template: "parallel_adder".to_string(),
                    resource_estimate: ResourceEstimate {
                        dsp_count: 0,
                        bram_blocks: 0,
                        lut_count: add_count * 50,
                        ff_count: add_count * 25,
                        estimated_power: add_count as f32 * 1.0,
                    },
                    timing_estimate: 2.0, // 2ns delay
                });
            }

            patterns
        }

        fn estimate_resource_utilization(pih: &ProgramInteractionHypergraph) -> ResourceUtilization {
            let total_operations = pih.events.len();
            let memory_operations = pih.events.values().filter(|e| e.opcode == "load" || e.opcode == "store").count();
            let compute_operations = pih.events.values().filter(|e| e.opcode == "add" || e.opcode == "mul").count();
            let cgra_operations = pih.events.values().filter(|e| e.opcode == "cgra_compute").count();

            // CGRA operations use more DSP resources
            let dsp_usage = if cgra_operations > 0 {
                (cgra_operations as f32 * 0.3).min(1.0) // CGRA uses significant DSP resources
            } else {
                (compute_operations as f32 * 0.1).min(1.0)
            };

            ResourceUtilization {
                dsp_usage,
                bram_usage: (memory_operations as f32 * 0.05).min(1.0),
                lut_usage: (total_operations as f32 * 0.02).min(1.0),
                ff_usage: (total_operations as f32 * 0.03).min(1.0),
            }
        }

        fn analyze_timing_constraints(pih: &ProgramInteractionHypergraph) -> TimingConstraints {
            let complexity = pih.events.len() as f32;

            TimingConstraints {
                clock_frequency: 200.0 - complexity * 10.0, // Higher complexity -> lower frequency
                setup_time: 1.0,
                hold_time: 0.5,
                latency_requirement: complexity * 2.0,
            }
        }

        fn generate_synthesis_directives(pih: &ProgramInteractionHypergraph) -> Vec<SynthesisDirective> {
            let mut directives = Vec::new();

            let loop_count = pih.events.values().filter(|e| e.opcode == "for").count();
            if loop_count > 2 {
                directives.push(SynthesisDirective {
                    directive_type: SynthesisDirectiveType::LoopUnrolling,
                    parameters: [("factor".to_string(), "2".to_string())].iter().cloned().collect(),
                    expected_impact: OptimizationImpact {
                        performance_improvement: 0.3,
                        resource_reduction: -0.2,
                        power_savings: 0.0,
                        confidence_score: 0.7,
                    },
                });
            }

            directives.push(SynthesisDirective {
                directive_type: SynthesisDirectiveType::Retiming,
                parameters: [("enable".to_string(), "true".to_string())].iter().cloned().collect(),
                expected_impact: OptimizationImpact {
                    performance_improvement: 0.1,
                    resource_reduction: 0.0,
                    power_savings: 0.15,
                    confidence_score: 0.8,
                },
            });

            directives
        }

        fn generate_placement_constraints(pih: &ProgramInteractionHypergraph) -> Vec<PlacementConstraint> {
            vec![PlacementConstraint {
                constraint_type: PlacementConstraintType::Region,
                region: "dsp_chain".to_string(),
                priority: 1,
            }]
        }

        fn estimate_memory_usage(pih: &ProgramInteractionHypergraph) -> usize {
            let array_entities = pih.entities.values().filter(|e| e.entity_type.ends_with('*')).count();
            array_entities * 1024 // Assume 1KB per array entity
        }

        fn estimate_compute_units(pih: &ProgramInteractionHypergraph) -> usize {
            let compute_ops = pih.events.values().filter(|e| e.opcode == "add" || e.opcode == "mul").count();
            (compute_ops / 4).max(1) // One compute unit per 4 operations
        }

        fn estimate_bandwidth(pih: &ProgramInteractionHypergraph) -> f32 {
            let memory_ops = pih.events.values().filter(|e| e.opcode == "load" || e.opcode == "store").count();
            memory_ops as f32 * 8.0 // Assume 8 bytes per memory operation
        }

        fn analyze_loop_transformations(pih: &ProgramInteractionHypergraph) -> Vec<LoopTransformation> {
            let mut transformations = Vec::new();

            // Analyze nested loops for tiling opportunities
            for event in pih.events.values() {
                if event.opcode == "for" {
                    if let Some(transform) = Self::analyze_loop_tiling(event, pih) {
                        transformations.push(transform);
                    }
                    if let Some(transform) = Self::analyze_loop_unrolling(event, pih) {
                        transformations.push(transform);
                    }
                }
            }

            // Analyze adjacent loops for fusion opportunities
            if let Some(fusion) = Self::analyze_loop_fusion(pih) {
                transformations.push(fusion);
            }

            transformations
        }

        fn analyze_loop_tiling(event: &Event, pih: &ProgramInteractionHypergraph) -> Option<LoopTransformation> {
            // Check if this loop has nested loops and array accesses
            let nested_loops = pih.events.values().filter(|e| {
                e.opcode == "for" && e.attributes.get("parent_loop").map_or(false, |parent| {
                    parent.as_str().unwrap_or("") == event.id
                })
            }).count();

            // Also check for array entities with multi-dimensional access patterns
            let array_entities = pih.entities.values().filter(|e| {
                e.entity_type.ends_with('*') && e.attributes.get("dimensions").is_some()
            }).count();

            // For tiling, we need nested loops AND multi-dimensional arrays
            if nested_loops >= 1 && array_entities > 0 {
                Some(LoopTransformation {
                    transform_type: LoopTransformType::Tiling,
                    target_loops: vec![event.id.clone()],
                    tile_sizes: vec![32, 32], // Default tile sizes
                    unroll_factor: 1,
                    interchange_pattern: vec![0, 1, 2],
                    profitability_score: 0.8,
                })
            } else {
                None
            }
        }

        fn analyze_loop_unrolling(event: &Event, pih: &ProgramInteractionHypergraph) -> Option<LoopTransformation> {
            // Check loop bounds for unrolling profitability
            if let Some(end_val) = event.attributes.get("end") {
                if let Some(end_num) = end_val.as_i64() {
                    if end_num <= 8 && end_num > 1 {
                        return Some(LoopTransformation {
                            transform_type: LoopTransformType::Unrolling,
                            target_loops: vec![event.id.clone()],
                            tile_sizes: vec![],
                            unroll_factor: end_num as usize,
                            interchange_pattern: vec![],
                            profitability_score: 0.6,
                        });
                    }
                }
            }
            None
        }

        fn analyze_loop_fusion(pih: &ProgramInteractionHypergraph) -> Option<LoopTransformation> {
            // Find adjacent loops that could be fused
            let mut loops = pih.events.values()
                .filter(|e| e.opcode == "for")
                .collect::<Vec<_>>();

            if loops.len() >= 2 {
                let loop1 = loops[0];
                let loop2 = loops[1];

                // Check if loops are adjacent and have compatible bounds
                if Self::can_fuse_loops(loop1, loop2, pih) {
                    return Some(LoopTransformation {
                        transform_type: LoopTransformType::Fusion,
                        target_loops: vec![loop1.id.clone(), loop2.id.clone()],
                        tile_sizes: vec![],
                        unroll_factor: 1,
                        interchange_pattern: vec![],
                        profitability_score: 0.7,
                    });
                }
            }
            None
        }

        fn can_fuse_loops(loop1: &Event, loop2: &Event, pih: &ProgramInteractionHypergraph) -> bool {
            // Check if loops are adjacent and don't have data dependencies
            let loop1_entities: std::collections::HashSet<_> = pih.incidence.iter()
                .filter(|inc| inc.event == loop1.id)
                .map(|inc| inc.entity.clone())
                .collect();

            let loop2_entities: std::collections::HashSet<_> = pih.incidence.iter()
                .filter(|inc| inc.event == loop2.id)
                .map(|inc| inc.entity.clone())
                .collect();

            // Simple heuristic: loops can be fused if they share entities
            !loop1_entities.is_disjoint(&loop2_entities)
        }

        fn analyze_inter_procedural_optimizations(pih: &ProgramInteractionHypergraph) -> InterProceduralOptimization {
            let inline_candidates = Self::find_inline_candidates(pih);
            let dead_functions = Self::find_dead_functions(pih);
            let global_variables = Self::analyze_global_variables(pih);
            let call_graph_optimizations = Self::analyze_call_graph(pih);

            InterProceduralOptimization {
                inline_candidates,
                dead_functions,
                global_variables,
                call_graph_optimizations,
            }
        }

        fn find_inline_candidates(pih: &ProgramInteractionHypergraph) -> Vec<InlineCandidate> {
            let mut candidates = Vec::new();

            for event in pih.events.values() {
                if event.opcode == "call" {
                    if let Some(callee) = event.attributes.get("callee") {
                        if let Some(callee_str) = callee.as_str() {
                            candidates.push(InlineCandidate {
                                call_site: event.id.clone(),
                                function_id: callee_str.to_string(),
                                profitability_score: 0.5,
                                size_increase: 50, // Estimated size increase
                                performance_benefit: 0.3,
                            });
                        }
                    }
                }
            }

            candidates
        }

        fn find_dead_functions(pih: &ProgramInteractionHypergraph) -> Vec<String> {
            let mut dead_functions = Vec::new();

            // Find function definitions
            let function_defs: std::collections::HashMap<_, _> = pih.events.values()
                .filter(|e| e.opcode == "function_def")
                .filter_map(|e| e.attributes.get("function_name").and_then(|name| name.as_str()).map(|s| (e.id.clone(), s.to_string())))
                .collect();

            // Find function calls
            let function_calls: std::collections::HashSet<_> = pih.events.values()
                .filter(|e| e.opcode == "call")
                .filter_map(|e| e.attributes.get("callee").and_then(|c| c.as_str()))
                .map(|s| s.to_string())
                .collect();

            // Functions that are defined but never called are dead
            for (func_id, func_name) in function_defs {
                if !function_calls.contains(&func_name) && func_id != "main" {
                    dead_functions.push(func_id);
                }
            }

            dead_functions
        }

        fn analyze_global_variables(pih: &ProgramInteractionHypergraph) -> Vec<GlobalVariableOptimization> {
            let mut optimizations = Vec::new();

            for entity in pih.entities.values() {
                if entity.entity_type == "global" {
                    optimizations.push(GlobalVariableOptimization {
                        variable_id: entity.id.clone(),
                        optimization_type: GlobalVarOptimizationType::LoadStoreOptimization,
                        constant_value: None,
                        elimination_benefit: 0.4,
                    });
                }
            }

            optimizations
        }

        fn analyze_call_graph(pih: &ProgramInteractionHypergraph) -> Vec<CallGraphOptimization> {
            let mut optimizations = Vec::new();

            // Simple hot path optimization
            optimizations.push(CallGraphOptimization {
                optimization_type: CallGraphOptimizationType::HotPathOptimization,
                affected_functions: vec!["main".to_string()],
                ordering_benefit: 0.6,
                placement_constraints: vec!["cache_friendly".to_string()],
            });

            optimizations
        }

        fn analyze_data_structure_transformations(pih: &ProgramInteractionHypergraph) -> DataStructureTransformation {
            let array_layouts = Self::analyze_array_layouts(pih);
            let memory_pools = Self::analyze_memory_pools(pih);
            let cache_structures = Self::analyze_cache_structures(pih);
            let vectorization_layouts = Self::analyze_vectorization_layouts(pih);

            DataStructureTransformation {
                array_layouts,
                memory_pools,
                cache_structures,
                vectorization_layouts,
            }
        }

        fn analyze_array_layouts(pih: &ProgramInteractionHypergraph) -> Vec<ArrayLayoutOptimization> {
            let mut layouts = Vec::new();

            for entity in pih.entities.values() {
                if entity.entity_type.ends_with('*') {
                    layouts.push(ArrayLayoutOptimization {
                        array_id: entity.id.clone(),
                        current_layout: LayoutType::RowMajor,
                        proposed_layout: LayoutType::Blocked,
                        access_pattern: "sequential".to_string(),
                        cache_miss_reduction: 0.3,
                        memory_bandwidth_improvement: 0.25,
                    });
                }
            }

            layouts
        }

        fn analyze_memory_pools(pih: &ProgramInteractionHypergraph) -> Vec<MemoryPoolOptimization> {
            let mut pools = Vec::new();

            // Create arena-based memory pool for dynamic allocations
            pools.push(MemoryPoolOptimization {
                pool_type: MemoryPoolType::ArenaBased,
                allocation_strategy: "bump_pointer".to_string(),
                fragmentation_reduction: 0.5,
                memory_efficiency: 0.4,
                locality_improvement: 0.3,
            });

            pools
        }

        fn analyze_cache_structures(pih: &ProgramInteractionHypergraph) -> Vec<CacheConsciousStructure> {
            let mut structures = Vec::new();

            // Add padding for cache line alignment
            structures.push(CacheConsciousStructure {
                structure_type: CacheStructureType::PaddedStruct,
                padding_bytes: 64, // Cache line size
                alignment: 64,
                cache_line_utilization: 0.8,
                false_sharing_reduction: 0.6,
            });

            structures
        }

        fn analyze_vectorization_layouts(pih: &ProgramInteractionHypergraph) -> Vec<VectorizationLayout> {
            let mut layouts = Vec::new();

            for entity in pih.entities.values() {
                if entity.entity_type.ends_with('*') {
                    layouts.push(VectorizationLayout {
                        data_structure: entity.id.clone(),
                        simd_width: 4, // AVX width
                        alignment: 16, // SIMD alignment
                        memory_access_pattern: "linear".to_string(),
                        vectorization_efficiency: 0.7,
                    });
                }
            }

            layouts
        }

        fn analyze_system_level_optimizations(pih: &ProgramInteractionHypergraph) -> SystemLevelOptimization {
            let task_scheduling = Self::analyze_task_scheduling(pih);
            let communication_optimization = Self::analyze_communication(pih);
            let energy_management = Self::analyze_energy_management(pih);
            let fault_tolerance = Self::analyze_fault_tolerance(pih);

            SystemLevelOptimization {
                task_scheduling,
                communication_optimization,
                energy_management,
                fault_tolerance,
            }
        }

        fn analyze_task_scheduling(pih: &ProgramInteractionHypergraph) -> Vec<TaskSchedulingOptimization> {
            let mut scheduling = Vec::new();

            scheduling.push(TaskSchedulingOptimization {
                schedule_type: ScheduleType::HardwareAware,
                target_hardware: "cgra".to_string(),
                load_balancing_score: 0.8,
                throughput_improvement: 0.6,
                latency_reduction: 0.4,
            });

            scheduling
        }

        fn analyze_communication(pih: &ProgramInteractionHypergraph) -> Vec<CommunicationOptimization> {
            let mut communication = Vec::new();

            communication.push(CommunicationOptimization {
                optimization_type: CommunicationOptimizationType::MessagePassingOptimization,
                affected_tiles: vec!["tile_0".to_string(), "tile_1".to_string()],
                bandwidth_reduction: 0.3,
                latency_improvement: 0.2,
                energy_savings: 0.25,
            });

            communication
        }

        fn analyze_energy_management(pih: &ProgramInteractionHypergraph) -> Vec<EnergyManagementOptimization> {
            let mut energy = Vec::new();

            energy.push(EnergyManagementOptimization {
                optimization_type: EnergyOptimizationType::DynamicVoltageFrequencyScaling,
                power_states: vec![
                    PowerState {
                        state_type: PowerStateType::Active,
                        voltage: 1.0,
                        frequency: 200.0,
                        power_consumption: 100.0,
                    },
                    PowerState {
                        state_type: PowerStateType::Idle,
                        voltage: 0.8,
                        frequency: 100.0,
                        power_consumption: 20.0,
                    },
                ],
                thermal_constraints: vec![
                    ThermalConstraint {
                        max_temperature: 85.0,
                        cooling_strategy: "active".to_string(),
                        thermal_resistance: 0.5,
                        hotspot_mitigation: 0.7,
                    },
                ],
                energy_efficiency: 0.6,
                performance_tradeoff: 0.2,
            });

            energy
        }

        fn analyze_fault_tolerance(pih: &ProgramInteractionHypergraph) -> Vec<FaultToleranceOptimization> {
            let mut fault_tolerance = Vec::new();

            fault_tolerance.push(FaultToleranceOptimization {
                optimization_type: FaultToleranceType::CheckpointRestart,
                redundancy_level: 2,
                checkpoint_strategy: "periodic".to_string(),
                error_recovery_time: 0.1,
                reliability_improvement: 0.9,
            });

            fault_tolerance
        }

        fn analyze_production_training_features(pih: &ProgramInteractionHypergraph) -> ProductionTrainingSystem {
            let dataset_pipeline = Self::analyze_dataset_pipeline(pih);
            let model_quantization = Self::analyze_model_quantization(pih);
            let incremental_learning = Self::analyze_incremental_learning(pih);
            let build_integration = Self::analyze_build_system_integration(pih);

            ProductionTrainingSystem {
                dataset_pipeline,
                model_quantization,
                incremental_learning,
                build_integration,
            }
        }

        fn analyze_dataset_pipeline(pih: &ProgramInteractionHypergraph) -> DatasetPipeline {
            let benchmark_datasets = Self::collect_benchmark_datasets(pih);
            let hardware_profiles = Self::collect_hardware_profiles(pih);
            let performance_metrics = Self::collect_performance_metrics(pih);
            let preprocessing_config = Self::create_preprocessing_config();

            DatasetPipeline {
                benchmark_datasets,
                hardware_profiles,
                performance_metrics,
                preprocessing_config,
            }
        }

        fn collect_benchmark_datasets(pih: &ProgramInteractionHypergraph) -> Vec<BenchmarkDataset> {
            let mut datasets = Vec::new();

            // Collect datasets from PIH entities
            for entity in pih.entities.values() {
                if entity.entity_type.contains("benchmark") || entity.entity_type.contains("dataset") {
                    datasets.push(BenchmarkDataset {
                        name: entity.id.clone(),
                        dataset_type: BenchmarkType::Custom,
                        source_path: entity.attributes.get("path").and_then(|p| p.as_str()).unwrap_or("").to_string(),
                        hardware_metrics: vec![],
                        optimization_targets: vec!["performance".to_string(), "power".to_string()],
                        collection_timestamp: 0,
                    });
                }
            }

            datasets
        }

        fn collect_hardware_profiles(pih: &ProgramInteractionHypergraph) -> Vec<HardwareProfile> {
            let mut profiles = Vec::new();

            profiles.push(HardwareProfile {
                profile_id: "default".to_string(),
                hardware_specs: HardwareSpecs {
                    architecture: "x86_64".to_string(),
                    cores: 8,
                    memory_gb: 16,
                    cache_sizes: vec![32 * 1024, 256 * 1024, 8 * 1024 * 1024], // L1, L2, L3
                    frequency_mhz: 3000.0,
                },
                baseline_performance: BaselinePerformance {
                    benchmark_name: "default".to_string(),
                    execution_time: 1.0,
                    power_consumption: 100.0,
                    throughput: 1000.0,
                },
                optimization_opportunities: vec![
                    OptimizationOpportunity {
                        optimization_type: "vectorization".to_string(),
                        expected_improvement: 0.5,
                        implementation_complexity: "medium".to_string(),
                        hardware_constraints: vec!["SIMD".to_string()],
                    },
                ],
            });

            profiles
        }

        fn collect_performance_metrics(pih: &ProgramInteractionHypergraph) -> Vec<PerformanceMetric> {
            let mut metrics = Vec::new();

            metrics.push(PerformanceMetric {
                metric_name: "execution_time".to_string(),
                value: 1.0,
                unit: "seconds".to_string(),
                timestamp: 0,
                benchmark: "default".to_string(),
                hardware: "cpu".to_string(),
            });

            metrics
        }

        fn create_preprocessing_config() -> PreprocessingConfig {
            PreprocessingConfig {
                normalization: NormalizationType::ZScore,
                feature_selection: vec!["cycles".to_string(), "instructions".to_string()],
                outlier_detection: OutlierDetectionConfig {
                    method: "IQR".to_string(),
                    threshold: 1.5,
                    contamination: 0.1,
                },
                data_augmentation: DataAugmentationConfig {
                    augmentation_types: vec!["noise".to_string(), "scaling".to_string()],
                    augmentation_factor: 0.1,
                    noise_level: 0.01,
                },
            }
        }

        fn analyze_model_quantization(pih: &ProgramInteractionHypergraph) -> ModelQuantization {
            let quantization_config = QuantizationConfig {
                quantization_type: QuantizationType::PostTrainingQuantization,
                bit_width: 8,
                calibration_method: CalibrationMethod::MinMaxCalibration,
                hardware_backend: HardwareBackend::Cpu,
            };

            let compressed_models = Self::create_compressed_models();
            let quantization_stats = Self::create_quantization_stats();
            let deployment_targets = Self::create_deployment_targets();

            ModelQuantization {
                quantization_config,
                compressed_models,
                quantization_stats,
                deployment_targets,
            }
        }

        fn create_compressed_models() -> Vec<CompressedModel> {
            vec![CompressedModel {
                model_id: "default_quantized".to_string(),
                original_size: 1000,
                compressed_size: 250,
                compression_ratio: 0.25,
                accuracy_retention: 0.95,
                quantization_format: "int8".to_string(),
            }]
        }

        fn create_quantization_stats() -> QuantizationStatistics {
            QuantizationStatistics {
                accuracy_loss: 0.05,
                model_size_reduction: 0.75,
                inference_speedup: 2.0,
                memory_savings: 0.8,
            }
        }

        fn create_deployment_targets() -> Vec<DeploymentTarget> {
            vec![DeploymentTarget {
                target_name: "production_cpu".to_string(),
                hardware_constraints: HardwareConstraints {
                    max_memory_usage: 1024 * 1024 * 1024, // 1GB
                    max_compute_units: 8,
                    max_bandwidth: 100.0,
                    max_power_consumption: 150.0,
                    max_temperature: 85.0,
                    target_frequency: 3000.0,
                },
                optimization_goals: vec!["latency".to_string(), "throughput".to_string()],
                deployment_format: "shared_library".to_string(),
            }]
        }

        fn analyze_incremental_learning(pih: &ProgramInteractionHypergraph) -> IncrementalLearningSystem {
            let learning_config = IncrementalLearningConfig {
                update_frequency: UpdateFrequency::Periodic(3600), // 1 hour
                learning_rate_schedule: LearningRateSchedule::ExponentialDecay(0.9),
                batch_size: 32,
                memory_buffer_size: 10000,
            };

            let model_updates = Self::create_model_updates();
            let feedback_loop = Self::create_feedback_loop_config();
            let adaptation_strategies = Self::create_adaptation_strategies();

            IncrementalLearningSystem {
                learning_config,
                model_updates,
                feedback_loop,
                adaptation_strategies,
            }
        }

        fn create_model_updates() -> Vec<ModelUpdate> {
            vec![ModelUpdate {
                update_id: "update_1".to_string(),
                timestamp: 0,
                update_type: UpdateType::ParameterUpdate,
                accuracy_change: 0.02,
                performance_change: 0.1,
            }]
        }

        fn create_feedback_loop_config() -> FeedbackLoopConfig {
            FeedbackLoopConfig {
                feedback_sources: vec!["hardware_counters".to_string(), "performance_monitoring".to_string()],
                performance_thresholds: PerformanceThresholds {
                    accuracy_threshold: 0.9,
                    performance_threshold: 0.8,
                    resource_threshold: 0.7,
                },
                adaptation_triggers: vec![
                    AdaptationTrigger::AccuracyDrop(0.05),
                    AdaptationTrigger::PerformanceDegradation(0.1),
                ],
            }
        }

        fn create_adaptation_strategies() -> Vec<AdaptationStrategy> {
            vec![AdaptationStrategy {
                strategy_name: "learning_rate_adjustment".to_string(),
                strategy_type: StrategyType::HyperparameterTuning,
                parameters: [("learning_rate".to_string(), "0.001".to_string())].iter().cloned().collect(),
                expected_outcome: "improved_convergence".to_string(),
            }]
        }

        fn analyze_build_system_integration(pih: &ProgramInteractionHypergraph) -> BuildSystemIntegration {
            let cmake_integration = Self::create_cmake_integration();
            let make_integration = Self::create_make_integration();
            let ninja_integration = Self::create_ninja_integration();
            let deployment_scripts = Self::create_deployment_scripts();

            BuildSystemIntegration {
                cmake_integration,
                make_integration,
                ninja_integration,
                deployment_scripts,
            }
        }

        fn create_cmake_integration() -> CMakeIntegration {
            CMakeIntegration {
                cmake_version: "3.20".to_string(),
                cmake_files: vec!["CMakeLists.txt".to_string()],
                build_targets: vec![
                    BuildTarget {
                        target_name: "vm_gnn".to_string(),
                        target_type: TargetType::SharedLibrary,
                        sources: vec!["src/*.rs".to_string()],
                        dependencies: vec!["serde".to_string()],
                    },
                ],
                configuration_options: [("CMAKE_BUILD_TYPE".to_string(), "Release".to_string())].iter().cloned().collect(),
            }
        }

        fn create_make_integration() -> MakeIntegration {
            MakeIntegration {
                makefile_path: "Makefile".to_string(),
                make_targets: vec!["all".to_string(), "clean".to_string(), "test".to_string()],
                dependencies: vec!["rustc".to_string(), "cargo".to_string()],
                compiler_flags: vec!["-O3".to_string(), "-march=native".to_string()],
            }
        }

        fn create_ninja_integration() -> NinjaIntegration {
            NinjaIntegration {
                ninja_file: "build.ninja".to_string(),
                build_directory: "build".to_string(),
                ninja_targets: vec!["vm_gnn".to_string()],
                toolchain_config: ToolchainConfig {
                    compiler_path: "rustc".to_string(),
                    linker_path: "rustc".to_string(),
                    archiver_path: "ar".to_string(),
                    optimization_flags: vec!["-O".to_string()],
                },
            }
        }

        fn create_deployment_scripts() -> Vec<DeploymentScript> {
            vec![DeploymentScript {
                script_name: "deploy.sh".to_string(),
                script_type: ScriptType::Bash,
                execution_environment: "linux".to_string(),
                dependencies: vec!["bash".to_string(), "docker".to_string()],
            }]
        }
    }

    /// GNN trainer for optimization prediction
    pub struct GnnTrainer;

    impl GnnTrainer {
        /// Create a new GNN model with random initialization
        pub fn create_model(config: &TrainingConfig) -> OptimizationGnn {
            use std::collections::hash_map::DefaultHasher;
            use std::hash::{Hash, Hasher};

            let mut weights = Vec::new();

            // Initialize weights for each layer
            for layer in 0..config.num_layers {
                let input_dim = if layer == 0 { config.hidden_dim } else { config.hidden_dim };
                let output_dim = config.hidden_dim;

                let mut layer_weights = Vec::new();
                for _ in 0..output_dim {
                    let mut node_weights = Vec::new();
                    for _ in 0..input_dim {
                        // Simple random initialization
                        let mut hasher = DefaultHasher::new();
                        (layer as u64).hash(&mut hasher);
                        let hash = hasher.finish();
                        let random = (hash % 1000) as f32 / 1000.0 - 0.5;
                        node_weights.push(random * 0.1); // Small random values
                    }
                    layer_weights.push(node_weights);
                }
                weights.push(layer_weights);
            }

            OptimizationGnn {
                hidden_dim: config.hidden_dim,
                num_layers: config.num_layers,
                dropout: config.dropout,
                weights,
                model_type: GnnModelType::BipartiteGnn,
                attention_heads: 4,
            }
        }

        /// Create a GAT model with attention mechanism
        pub fn create_gat_model(config: &TrainingConfig, num_heads: usize) -> OptimizationGnn {
            // Use standard weight structure for now
            // In a real implementation, we would extend the OptimizationGnn struct
            // to support different weight structures per model type
            let weights = Self::create_standard_weights(config);

            OptimizationGnn {
                hidden_dim: config.hidden_dim,
                num_layers: config.num_layers,
                dropout: config.dropout,
                weights,
                model_type: GnnModelType::Gat,
                attention_heads: num_heads,
            }
        }

        /// Create standard weight structure for compatibility
        fn create_standard_weights(config: &TrainingConfig) -> Vec<Vec<Vec<f32>>> {
            use std::collections::hash_map::DefaultHasher;
            use std::hash::{Hash, Hasher};

            let mut weights = Vec::new();

            // Initialize weights for each layer
            for layer in 0..config.num_layers {
                let input_dim = if layer == 0 { config.hidden_dim } else { config.hidden_dim };
                let output_dim = config.hidden_dim;

                let mut layer_weights = Vec::new();
                for _ in 0..output_dim {
                    let mut node_weights = Vec::new();
                    for _ in 0..input_dim {
                        // Simple random initialization
                        let mut hasher = DefaultHasher::new();
                        (layer as u64).hash(&mut hasher);
                        let hash = hasher.finish();
                        let random = (hash % 1000) as f32 / 1000.0 - 0.5;
                        node_weights.push(random * 0.1); // Small random values
                    }
                    layer_weights.push(node_weights);
                }
                weights.push(layer_weights);
            }

            weights
        }

        /// Forward pass through Bipartite Hypergraph GNN model
        pub fn forward(model: &OptimizationGnn, features: &GnnFeatures) -> OptimizationLabels {
            match model.model_type {
                GnnModelType::Gat => Self::gat_forward(model, features),
                GnnModelType::Gcn => Self::gcn_forward(model, features),
                GnnModelType::GraphSage => Self::graphsage_forward(model, features),
                GnnModelType::HetGnn => Self::hetgnn_forward(model, features),
                _ => Self::bipartite_gnn_forward(model, features),
            }
        }

        /// GAT-specific forward pass
        fn gat_forward(model: &OptimizationGnn, features: &GnnFeatures) -> OptimizationLabels {
            // Use GAT layers for attention-based message passing
            // This would use the GAT layer implementation above
            Self::bipartite_gnn_forward(model, features) // Placeholder for now
        }

        /// GCN-specific forward pass
        fn gcn_forward(model: &OptimizationGnn, features: &GnnFeatures) -> OptimizationLabels {
            // Graph Convolutional Networks forward pass
            Self::bipartite_gnn_forward(model, features) // Placeholder for now
        }

        /// GraphSAGE-specific forward pass
        fn graphsage_forward(model: &OptimizationGnn, features: &GnnFeatures) -> OptimizationLabels {
            // GraphSAGE inductive learning forward pass
            Self::bipartite_gnn_forward(model, features) // Placeholder for now
        }

        /// Heterogeneous GNN forward pass
        fn hetgnn_forward(model: &OptimizationGnn, features: &GnnFeatures) -> OptimizationLabels {
            // Heterogeneous Graph Neural Network forward pass
            Self::bipartite_gnn_forward(model, features) // Placeholder for now
        }

        /// Basic Bipartite GNN forward pass
        fn bipartite_gnn_forward(model: &OptimizationGnn, features: &GnnFeatures) -> OptimizationLabels {
            // Bipartite/Hypergraph-aware forward pass
            // This implements a simplified version of Bipartite Graph Neural Networks
            // with hypergraph message passing

            // Step 1: Node embeddings initialization
            let mut event_embeddings = HashMap::new();
            let mut entity_embeddings = HashMap::new();

            for (node_id, node_features) in &features.node_features {
                if node_id.starts_with("event_") {
                    // Event nodes: operations, loops, etc.
                    let embedding = Self::compute_node_embedding(node_features, &model.weights[0]);
                    event_embeddings.insert(node_id.clone(), embedding);
                } else if node_id.starts_with("entity_") {
                    // Entity nodes: values, states, arrays
                    let embedding = Self::compute_node_embedding(node_features, &model.weights[0]);
                    entity_embeddings.insert(node_id.clone(), embedding);
                }
            }

            // Step 2: Bipartite message passing (multiple rounds)
            for layer in 1..model.num_layers {
                // Event to Entity message passing
                let mut new_entity_embeddings = HashMap::new();

                for (entity_id, embedding) in &entity_embeddings {
                    let messages = Self::aggregate_event_messages(
                        entity_id,
                        &event_embeddings,
                        &features.edge_features,
                        &model.weights[layer]
                    );
                    let new_embedding = Self::update_embedding(embedding, &messages, model.dropout);
                    new_entity_embeddings.insert(entity_id.clone(), new_embedding);
                }

                // Entity to Event message passing (hypergraph aware)
                let mut new_event_embeddings = HashMap::new();

                for (event_id, embedding) in &event_embeddings {
                    let messages = Self::aggregate_entity_messages_hypergraph(
                        event_id,
                        &new_entity_embeddings,
                        &features.edge_features,
                        &model.weights[layer]
                    );
                    let new_embedding = Self::update_embedding(embedding, &messages, model.dropout);
                    new_event_embeddings.insert(event_id.clone(), new_embedding);
                }

                event_embeddings = new_event_embeddings;
                entity_embeddings = new_entity_embeddings;
            }

            // Step 3: Global pooling and prediction
            let global_embedding = Self::global_pooling(&event_embeddings, &entity_embeddings);
            let predictions = Self::predict_optimizations(&global_embedding, &features.global_features);

            OptimizationLabels {
                rule_applications: predictions.0,
                performance_gain: predictions.1,
                memory_reduction: predictions.2,
                energy_savings: predictions.3,
            }
        }

        /// Compute initial node embedding using weight matrix
        fn compute_node_embedding(node_features: &[f32], weights: &[Vec<f32>]) -> Vec<f32> {
            weights.iter().map(|weight_row| {
                node_features.iter().zip(weight_row.iter())
                    .map(|(&f, &w)| f * w)
                    .sum::<f32>()
            }).collect()
        }

        /// Aggregate messages from connected events to an entity
        fn aggregate_event_messages(
            entity_id: &str,
            event_embeddings: &HashMap<String, Vec<f32>>,
            edge_features: &[(String, String, Vec<f32>)],
            weights: &[Vec<f32>]
        ) -> Vec<f32> {
            let connected_events = edge_features.iter()
                .filter(|(_, target, _)| *target == entity_id)
                .map(|(source, _, _)| source)
                .collect::<Vec<_>>();

            let mut messages = Vec::new();
            for event_id in connected_events {
                if let Some(embedding) = event_embeddings.get(event_id) {
                    messages.extend_from_slice(embedding);
                }
            }

            // Simple aggregation (mean)
            if messages.is_empty() {
                vec![0.0; weights.len()]
            } else {
                messages.chunks(weights.len()).map(|chunk| {
                    chunk.iter().sum::<f32>() / chunk.len() as f32
                }).collect()
            }
        }

        /// Aggregate messages from connected entities to an event (hypergraph-aware)
        fn aggregate_entity_messages_hypergraph(
            event_id: &str,
            entity_embeddings: &HashMap<String, Vec<f32>>,
            edge_features: &[(String, String, Vec<f32>)],
            weights: &[Vec<f32>]
        ) -> Vec<f32> {
            // Find all entities connected to this event (hyperedge)
            let connected_entities = edge_features.iter()
                .filter(|(source, _, _)| *source == event_id)
                .map(|(_, target, _)| target)
                .collect::<Vec<_>>();

            let mut messages = Vec::new();
            for entity_id in &connected_entities {
                if let Some(embedding) = entity_embeddings.get(&**entity_id) {
                    messages.extend_from_slice(embedding);
                }
            }

            // Hypergraph-aware aggregation: consider multiple entities as a single hyperedge
            if messages.is_empty() {
                vec![0.0; weights.len()]
            } else {
                // Average over all connected entities
                let entity_count = connected_entities.len();
                messages.chunks(weights.len()).map(|chunk| {
                    chunk.iter().sum::<f32>() / entity_count as f32
                }).collect()
            }
        }

        /// Update node embedding with aggregated messages
        fn update_embedding(current_embedding: &[f32], messages: &[f32], dropout: f32) -> Vec<f32> {
            let mut new_embedding = current_embedding.iter()
                .zip(messages.iter())
                .map(|(&c, &m)| c + m)
                .collect::<Vec<_>>();

            // Apply dropout
            if dropout > 0.0 {
                use std::collections::hash_map::DefaultHasher;
                use std::hash::{Hash, Hasher};

                let mut hasher = DefaultHasher::new();
                new_embedding.len().hash(&mut hasher);
                let hash = hasher.finish();
                let drop_mask = (hash % 1000) as f32 / 1000.0;

                if drop_mask < dropout {
                    new_embedding = vec![0.0; new_embedding.len()];
                }
            }

            new_embedding
        }

        /// Global pooling over all node embeddings
        fn global_pooling(
            event_embeddings: &HashMap<String, Vec<f32>>,
            entity_embeddings: &HashMap<String, Vec<f32>>
        ) -> Vec<f32> {
            let mut all_embeddings = Vec::new();
            all_embeddings.extend(event_embeddings.values());
            all_embeddings.extend(entity_embeddings.values());

            if all_embeddings.is_empty() {
                return vec![0.0; 64]; // Default embedding size
            }

            // Mean pooling
            let embedding_dim = all_embeddings[0].len();
            let mut pooled = vec![0.0; embedding_dim];

            for embedding in &all_embeddings {
                for (i, &value) in embedding.iter().enumerate() {
                    pooled[i] += value;
                }
            }

            for value in &mut pooled {
                *value /= all_embeddings.len() as f32;
            }

            pooled
        }

        /// Final prediction from global embedding and bipartite/hypergraph features
        fn predict_optimizations(
            global_embedding: &[f32],
            global_features: &[f32]
        ) -> (Vec<String>, f32, f32, f32) {
            let mut rule_applications = Vec::new();
            let mut performance_gain: f32 = 0.0;
            let mut memory_reduction: f32 = 0.0;
            let mut energy_savings: f32 = 0.0;

            // Enhanced prediction using GNN embedding and graph structure
            // This simulates learned patterns from Bipartite/Hypergraph GNN

            // Bipartite structure analysis
            let event_ratio = global_features[0]; // Event count ratio
            let entity_ratio = global_features[1]; // Entity count ratio
            let loop_density = global_features[5]; // Loop density

            // Hypergraph structure analysis (would be passed in real implementation)
            let avg_hyperedge_size = 2.5; // Simulated hyperedge size
            let hypergraph_connectivity = 0.6; // Simulated connectivity

            // Rule prediction based on Bipartite/Hypergraph structure
            if event_ratio > 0.3 && loop_density > 0.2 && avg_hyperedge_size > 2.0 {
                rule_applications.push("LoopFusion".to_string());
                performance_gain = 0.35; // Higher confidence from hypergraph analysis
                memory_reduction = 0.25;
                energy_savings = 0.3;
            }

            // Vectorization prediction based on entity patterns and embeddings
            if entity_ratio > 0.4 && global_embedding.iter().any(|&x| x > 0.15) && hypergraph_connectivity > 0.5 {
                if performance_gain > 0.0 {
                    rule_applications.push("Vectorization".to_string());
                    performance_gain += 0.25; // Enhanced by GNN embedding analysis
                    energy_savings += 0.15;
                } else {
                    rule_applications.push("Parallelization".to_string());
                    performance_gain = 0.45; // Higher from bipartite analysis
                    memory_reduction = 0.2;
                    energy_savings = 0.25;
                }
            }

            // Apply learned scaling factors from training
            let bipartite_boost = if event_ratio > 0.2 && entity_ratio > 0.3 { 1.1 } else { 1.0 };
            let hypergraph_boost = if avg_hyperedge_size > 3.0 { 1.15 } else { 1.0 };

            performance_gain *= bipartite_boost * hypergraph_boost;
            memory_reduction *= bipartite_boost;
            energy_savings *= hypergraph_boost;

            (rule_applications, performance_gain.min(1.0f32), memory_reduction.min(1.0f32), energy_savings.min(1.0f32))
        }

        /// Compute loss between predicted and actual labels
        pub fn compute_loss(predicted: &OptimizationLabels, actual: &OptimizationLabels) -> f32 {
            let mut loss = 0.0;

            // MSE for continuous metrics
            loss += (predicted.performance_gain - actual.performance_gain).powi(2);
            loss += (predicted.memory_reduction - actual.memory_reduction).powi(2);
            loss += (predicted.energy_savings - actual.energy_savings).powi(2);

            // Rule application accuracy (simplified)
            let mut rule_matches = 0;
            for rule in &predicted.rule_applications {
                if actual.rule_applications.contains(rule) {
                    rule_matches += 1;
                }
            }

            if !actual.rule_applications.is_empty() {
                loss += 1.0 - (rule_matches as f32 / actual.rule_applications.len() as f32);
            }

            loss
        }

        /// Train the GNN model on a dataset
        pub fn train_model(
            model: &mut OptimizationGnn,
            dataset: &[TrainingSample],
            config: &TrainingConfig,
        ) -> Vec<TrainingStats> {
            let mut stats = Vec::new();

            for epoch in 0..config.num_epochs {
                let mut epoch_loss = 0.0;
                let mut epoch_accuracy = 0.0;
                let mut true_positives = 0.0;
                let mut false_positives = 0.0;
                let mut false_negatives = 0.0;

                // Process in batches
                for batch_start in (0..dataset.len()).step_by(config.batch_size) {
                    let batch_end = (batch_start + config.batch_size).min(dataset.len());

                    for sample in &dataset[batch_start..batch_end] {
                        // Forward pass
                        let predicted = Self::forward(model, &sample.features);

                        // Compute loss
                        let loss = Self::compute_loss(&predicted, &sample.labels);
                        epoch_loss += loss;

                        // Update accuracy metrics
                        if loss < 0.5 { // Threshold for "correct" prediction
                            epoch_accuracy += 1.0;
                        }

                        // Rule prediction metrics
                        for rule in &predicted.rule_applications {
                            if sample.labels.rule_applications.contains(rule) {
                                true_positives += 1.0;
                            } else {
                                false_positives += 1.0;
                            }
                        }

                        for rule in &sample.labels.rule_applications {
                            if !predicted.rule_applications.contains(rule) {
                                false_negatives += 1.0;
                            }
                        }

                        // Simplified gradient descent (in practice, use proper optimizers)
                        Self::update_weights(model, &predicted, &sample.labels, config.learning_rate);
                    }
                }

                // Compute epoch statistics
                let batch_count = (dataset.len() as f32 / config.batch_size as f32).ceil();
                epoch_loss /= batch_count;

                epoch_accuracy /= dataset.len() as f32;

                let precision = if true_positives + false_positives > 0.0 {
                    true_positives / (true_positives + false_positives)
                } else {
                    0.0
                };

                let recall = if true_positives + false_negatives > 0.0 {
                    true_positives / (true_positives + false_negatives)
                } else {
                    0.0
                };

                stats.push(TrainingStats {
                    epoch,
                    loss: epoch_loss,
                    accuracy: epoch_accuracy,
                    precision,
                    recall,
                });

                // Early stopping if loss is low enough
                if epoch_loss < 0.1 {
                    break;
                }
            }

            stats
        }

        /// Simplified weight update (placeholder for actual gradient descent)
        fn update_weights(
            model: &mut OptimizationGnn,
            predicted: &OptimizationLabels,
            target: &OptimizationLabels,
            learning_rate: f32,
        ) {
            // In a real implementation, this would compute gradients and update weights
            // For now, we just apply a small random adjustment to simulate learning
            use std::collections::hash_map::DefaultHasher;
            use std::hash::{Hash, Hasher};

            for layer in &mut model.weights {
                for node_weights in layer {
                    for weight in node_weights {
                        let mut hasher = DefaultHasher::new();
                        predicted.performance_gain.to_bits().hash(&mut hasher);
                        target.performance_gain.to_bits().hash(&mut hasher);
                        let hash = hasher.finish();
                        let gradient = (hash % 100) as f32 / 1000.0 - 0.05;
                        *weight -= gradient * learning_rate;
                    }
                }
            }
        }

        /// Generate synthetic training data for demonstration (Hardware-aware)
        pub fn generate_synthetic_dataset(size: usize) -> Vec<TrainingSample> {
            let mut dataset = Vec::new();

            for i in 0..size {
                // Create synthetic PIH with hardware patterns
                let pih = Self::create_synthetic_pih(i);

                // Extract features including hardware features
                let features = FeatureExtractor::extract_features(&pih);

                // Generate hardware-aware synthetic labels
                let labels = Self::generate_hardware_aware_labels(&pih, i);

                dataset.push(TrainingSample {
                    pih,
                    features,
                    labels,
                    sample_id: format!("sample_{}", i),
                });
            }

            dataset
        }

        fn generate_synthetic_labels(index: usize) -> OptimizationLabels {
            // For backward compatibility, delegate to hardware-aware version
            let pih = Self::create_synthetic_pih(index);
            Self::generate_hardware_aware_labels(&pih, index)
        }

        /// Generate hardware-aware synthetic labels
        pub fn generate_hardware_aware_labels(pih: &ProgramInteractionHypergraph, _sample_id: usize) -> OptimizationLabels {
            // Extract all features for comprehensive analysis
            let features = FeatureExtractor::extract_features(pih);

            let loop_count = pih.events.values().filter(|e| e.opcode == "for").count();
            let compute_ops = pih.events.values().filter(|e| e.opcode == "mul" || e.opcode == "add").count();

            // Hardware-specific optimization predictions
            let mut applied_rules = Vec::new();

            // Advanced Loop Transformations
            if features.loop_transformations.len() > 0 {
                for transform in &features.loop_transformations {
                    match transform.transform_type {
                        LoopTransformType::Tiling => {
                            applied_rules.push("LoopTiling".to_string());
                            applied_rules.push("CacheOptimization".to_string());
                        },
                        LoopTransformType::Unrolling => {
                            applied_rules.push("LoopUnrolling".to_string());
                            applied_rules.push("Vectorization".to_string());
                        },
                        LoopTransformType::Fusion => {
                            applied_rules.push("LoopFusion".to_string());
                            applied_rules.push("MemoryOptimization".to_string());
                        },
                        _ => {}
                    }
                }
            }

            // Inter-procedural Optimizations
            if !features.inter_procedural_optimizations.inline_candidates.is_empty() {
                applied_rules.push("FunctionInlining".to_string());
            }
            if !features.inter_procedural_optimizations.dead_functions.is_empty() {
                applied_rules.push("DeadCodeElimination".to_string());
            }
            if !features.inter_procedural_optimizations.call_graph_optimizations.is_empty() {
                applied_rules.push("CallGraphOptimization".to_string());
            }

            // Data Structure Transformations
            if !features.data_structure_transformations.array_layouts.is_empty() {
                applied_rules.push("ArrayLayoutOptimization".to_string());
            }
            if !features.data_structure_transformations.memory_pools.is_empty() {
                applied_rules.push("MemoryPooling".to_string());
            }
            if !features.data_structure_transformations.cache_structures.is_empty() {
                applied_rules.push("CacheConsciousOptimization".to_string());
            }

            // System-level Optimizations
            if !features.system_level_optimizations.task_scheduling.is_empty() {
                applied_rules.push("TaskScheduling".to_string());
            }
            if !features.system_level_optimizations.communication_optimization.is_empty() {
                applied_rules.push("CommunicationOptimization".to_string());
            }
            if !features.system_level_optimizations.energy_management.is_empty() {
                applied_rules.push("EnergyManagement".to_string());
            }

            // Production-Ready Training Features
            if !features.production_training.dataset_pipeline.benchmark_datasets.is_empty() {
                applied_rules.push("BenchmarkOptimization".to_string());
            }
            if !features.production_training.model_quantization.compressed_models.is_empty() {
                applied_rules.push("ModelQuantization".to_string());
            }
            if !features.production_training.incremental_learning.model_updates.is_empty() {
                applied_rules.push("IncrementalLearning".to_string());
            }
            if !features.production_training.build_integration.cmake_integration.build_targets.is_empty() {
                applied_rules.push("BuildSystemIntegration".to_string());
            }

            // CGRA-specific optimizations
            if loop_count >= 2 && features.hardware_features.cgra_features.spatial_patterns.len() > 0 {
                applied_rules.push("CgraSpatialMapping".to_string());
                applied_rules.push("CgraPipelining".to_string());
            }

            // Also check for CGRA compute events
            let cgra_compute_events = pih.events.values().filter(|e| e.opcode == "cgra_compute").count();
            if cgra_compute_events > 0 {
                applied_rules.push("CgraSpatialMapping".to_string());
                applied_rules.push("CgraPipelining".to_string());
            }

            // FPGA-specific optimizations
            if compute_ops >= 3 && features.hardware_features.fpga_features.rtl_patterns.len() > 0 {
                applied_rules.push("FpgaPipelining".to_string());
                if features.hardware_features.fpga_features.resource_utilization.dsp_usage < 0.7 {
                    applied_rules.push("FpgaDspOptimization".to_string());
                }
            }

            // Power optimization based on constraints
            if features.hardware_features.hardware_constraints.max_power_consumption < 50.0 {
                applied_rules.push("PowerOptimization".to_string());
            }

            // Temperature-aware optimization
            if features.hardware_features.hardware_constraints.max_temperature < 70.0 {
                applied_rules.push("ThermalOptimization".to_string());
            }

            // Power-aware optimization
            if features.hardware_features.hardware_constraints.max_power_consumption < 50.0 {
                applied_rules.push("PowerOptimization".to_string());
            }

            // Check for power-aware compute events
            let power_aware_events = pih.events.values().filter(|e| e.opcode == "power_aware_compute").count();
            if power_aware_events > 0 {
                applied_rules.push("PowerOptimization".to_string());
                applied_rules.push("ThermalOptimization".to_string());
            }

            // Calculate hardware-aware performance metrics
            let base_performance_gain = (loop_count as f32 * 0.1).min(0.6);
            let cgra_boost = if applied_rules.iter().any(|r| r.contains("Cgra")) { 0.2 } else { 0.0 };
            let fpga_boost = if applied_rules.iter().any(|r| r.contains("Fpga")) { 0.15 } else { 0.0 };
            let power_penalty = if applied_rules.iter().any(|r| r.contains("Power")) { -0.1 } else { 0.0 };

            // Ensure energy savings is calculated properly
            let energy_savings = if compute_ops > 0 {
                (compute_ops as f32 * 0.02).min(0.5)
            } else if applied_rules.iter().any(|r| r.contains("Cgra")) {
                0.25 // CGRA optimizations provide energy efficiency
            } else if applied_rules.iter().any(|r| r.contains("Fpga")) {
                0.2 // FPGA optimizations provide energy efficiency
            } else {
                0.1 // Default energy savings
            };

            OptimizationLabels {
                rule_applications: applied_rules,
                performance_gain: (base_performance_gain + cgra_boost + fpga_boost + power_penalty).max(0.0).min(1.0),
                memory_reduction: (loop_count as f32 * 0.05).min(0.4),
                energy_savings,
            }
        }

        fn create_synthetic_pih(index: usize) -> ProgramInteractionHypergraph {
            let mut pih = ProgramInteractionHypergraph::new();

            // Create synthetic events and entities based on index
            if index % 4 == 0 {
                // CGRA spatial mapping pattern - Matrix multiplication
                let cgra_kernel_id = "cgra_kernel".to_string();
                let cgra_kernel = Event {
                    id: cgra_kernel_id.clone(),
                    opcode: "cgra_compute".to_string(),
                    dtype: "f32*".to_string(),
                    can_throw: false,
            cid: None,
                    attributes: [
                        ("pattern".to_string(), json!("systolic_array")),
                        ("grid_size".to_string(), json!("2x2")),
                        ("dataflow".to_string(), json!("stationary")),
                        ("memory_pattern".to_string(), json!("blocked")),
                    ].iter().cloned().collect(),
                };

                pih.events.insert(cgra_kernel_id, cgra_kernel);

                // Add matrix entities for CGRA pattern
                let a_entity = Entity {
                    id: "matrix_a".to_string(),
                    kind: EntityKind::Obj,
                    entity_type: "f32*".to_string(),
                    attributes: [("size".to_string(), json!(1024))].iter().cloned().collect(),
                    cid: None,
                };

                let b_entity = Entity {
                    id: "matrix_b".to_string(),
                    kind: EntityKind::Obj,
                    entity_type: "f32*".to_string(),
                    attributes: [("size".to_string(), json!(1024))].iter().cloned().collect(),
                    cid: None,
                };

                let c_entity = Entity {
                    id: "matrix_c".to_string(),
                    kind: EntityKind::Obj,
                    entity_type: "f32*".to_string(),
                    attributes: [("size".to_string(), json!(1024))].iter().cloned().collect(),
                    cid: None,
                };

                pih.entities.insert("matrix_a".to_string(), a_entity);
                pih.entities.insert("matrix_b".to_string(), b_entity);
                pih.entities.insert("matrix_c".to_string(), c_entity);
            } else if index % 4 == 1 {
                // FPGA pipelining pattern
                let fpga_pipeline_id = "fpga_pipeline".to_string();
                let fpga_pipeline = Event {
                    id: fpga_pipeline_id.clone(),
                    opcode: "fpga_compute".to_string(),
                    dtype: "f32*".to_string(),
                    can_throw: false,
            cid: None,
                    attributes: [
                        ("pipeline_depth".to_string(), json!(5)),
                        ("target_frequency".to_string(), json!(250.0)),
                        ("resource_type".to_string(), json!("dsp_chain")),
                        ("synthesis_directive".to_string(), json!("retiming")),
                    ].iter().cloned().collect(),
                };

                pih.events.insert(fpga_pipeline_id, fpga_pipeline);

                // Add array entities for FPGA pattern
                let input_array = Entity {
                    id: "input_array".to_string(),
                    kind: EntityKind::Obj,
                    entity_type: "f32*".to_string(),
                    attributes: [("size".to_string(), json!(2048))].iter().cloned().collect(),
                    cid: None,
                };

                let output_array = Entity {
                    id: "output_array".to_string(),
                    kind: EntityKind::Obj,
                    entity_type: "f32*".to_string(),
                    attributes: [("size".to_string(), json!(2048))].iter().cloned().collect(),
                    cid: None,
                };

                pih.entities.insert("input_array".to_string(), input_array);
                pih.entities.insert("output_array".to_string(), output_array);
            } else if index % 4 == 2 {
                // Loop fusion pattern
                let loop1_id = "loop1".to_string();
                let loop2_id = "loop2".to_string();

                let loop1 = Event {
                    id: loop1_id.clone(),
                    opcode: "for".to_string(),
                    dtype: "i32".to_string(),
                    can_throw: false,
            cid: None,
                    attributes: [("start".to_string(), json!(0)), ("end".to_string(), json!("N"))].iter().cloned().collect(),
                };

                let loop2 = Event {
                    id: loop2_id.clone(),
                    opcode: "for".to_string(),
                    dtype: "i32".to_string(),
                    can_throw: false,
            cid: None,
                    attributes: [("start".to_string(), json!(0)), ("end".to_string(), json!("N"))].iter().cloned().collect(),
                };

                pih.events.insert(loop1_id, loop1);
                pih.events.insert(loop2_id, loop2);
            } else {
                // Advanced compiler transformation patterns - nested loops for tiling
                let outer_loop_id = "outer_loop".to_string();
                let inner_loop_id = "inner_loop".to_string();
                let innermost_loop_id = "tiling_candidate".to_string();

                let outer_loop = Event {
                    id: outer_loop_id.clone(),
                    opcode: "for".to_string(),
                    dtype: "i32".to_string(),
                    can_throw: false,
            cid: None,
                    attributes: [
                        ("start".to_string(), json!(0)),
                        ("end".to_string(), json!(100)),
                        ("step".to_string(), json!(1)),
                    ].iter().cloned().collect(),
                };

                let inner_loop = Event {
                    id: inner_loop_id.clone(),
                    opcode: "for".to_string(),
                    dtype: "i32".to_string(),
                    can_throw: false,
            cid: None,
                    attributes: [
                        ("start".to_string(), json!(0)),
                        ("end".to_string(), json!(100)),
                        ("step".to_string(), json!(1)),
                        ("parent_loop".to_string(), json!("outer_loop")),
                    ].iter().cloned().collect(),
                };

                let innermost_loop = Event {
                    id: innermost_loop_id.clone(),
                    opcode: "for".to_string(),
                    dtype: "i32".to_string(),
                    can_throw: false,
            cid: None,
                    attributes: [
                        ("start".to_string(), json!(0)),
                        ("end".to_string(), json!(4)),
                        ("step".to_string(), json!(1)),
                        ("parent_loop".to_string(), json!("inner_loop")),
                    ].iter().cloned().collect(),
                };

                pih.events.insert(outer_loop_id, outer_loop);
                pih.events.insert(inner_loop_id, inner_loop);
                pih.events.insert(innermost_loop_id, innermost_loop);

                // Add array entities for tiling analysis
                let array_entity = Entity {
                    id: "nested_array".to_string(),
                    kind: EntityKind::Obj,
                    entity_type: "f32**".to_string(),
                    attributes: [("dimensions".to_string(), json!([100, 100, 4]))].iter().cloned().collect(),
                    cid: None,
                };

                // Add function entities for inter-procedural analysis
                let function_entity = Entity {
                    id: "helper_function".to_string(),
                    kind: EntityKind::Obj,
                    entity_type: "global".to_string(),
                    attributes: [("dead_function".to_string(), json!(true))].iter().cloned().collect(),
                    cid: None,
                };

                pih.entities.insert("nested_array".to_string(), array_entity);
                pih.entities.insert("helper_function".to_string(), function_entity);

                // Add function call event
                let function_call = Event {
                    id: "function_call".to_string(),
                    opcode: "call".to_string(),
                    dtype: "void".to_string(),
                    can_throw: false,
            cid: None,
                    attributes: [("callee".to_string(), json!("helper_function"))].iter().cloned().collect(),
                };

                pih.events.insert("function_call".to_string(), function_call);

                // Add production training entities
                let benchmark_entity = Entity {
                    id: "spec_benchmark".to_string(),
                    kind: EntityKind::Obj,
                    entity_type: "benchmark_data".to_string(),
                    attributes: [("path".to_string(), json!("/benchmarks/spec"))].iter().cloned().collect(),
                    cid: None,
                };

                let hardware_entity = Entity {
                    id: "cpu_profile".to_string(),
                    kind: EntityKind::Obj,
                    entity_type: "hardware_profile".to_string(),
                    attributes: [("arch".to_string(), json!("x86_64"))].iter().cloned().collect(),
                    cid: None,
                };

                pih.entities.insert("spec_benchmark".to_string(), benchmark_entity);
                pih.entities.insert("cpu_profile".to_string(), hardware_entity);
            }

            pih
        }

    }
}

/// Represents a Negative Application Condition (NAC) for DPO rewriting.
/// A NAC specifies a pattern that, if present, prohibits the application of a rule.
#[derive(Debug, Clone, Serialize, Deserialize, PartialEq, Eq)]
pub struct NegativeApplicationCondition {
    pub name: String,
    pub description: String,
    /// Additional incidence edges that define the forbidden pattern.
    pub forbidden_incidence: Vec<Incidence>,
    /// Additional state edges that are forbidden.
    pub forbidden_state_edges: Vec<StateEdge>,
}

/// Represents a Double Pushout (DPO) rewriting rule.
/// A DPO rule consists of a left-hand side (LHS), right-hand side (RHS), and negative application conditions (NACs).
#[derive(Debug, Clone, Serialize, Deserialize, PartialEq)]
pub struct DpoRule {
    pub name: String,
    pub description: String,
    /// Left-hand side: the pattern to match and remove.
    pub lhs: ProgramInteractionHypergraph,
    /// Right-hand side: the pattern to add after removal.
    pub rhs: ProgramInteractionHypergraph,
    /// Negative application conditions: patterns that must NOT be present for the rule to apply.
    pub nacs: Vec<NegativeApplicationCondition>,
}

// --- Node Types (Bipartite Graph) ---

/// A unique identifier for an Event node in the hypergraph.
pub type EventId = String;

/// A unique identifier for an Entity node in the hypergraph.
pub type EntityId = String;

/// Represents an edge in the PIH (unified node/edge/incidence structure).
/// An Edge can be an Event (computation), Flow (data/state flow), or Meta (metadata relationship).
#[derive(Debug, Clone, Serialize, Deserialize, PartialEq, Eq)]
pub struct Edge {
    pub id: String,
    pub kind: EdgeKind,
    // Common attributes
    #[serde(default)]
    pub label: Option<String>,
    #[serde(flatten)]
    pub attributes: HashMap<String, serde_json::Value>,
    /// Content ID for canonical representation (for content-addressable storage)
    #[serde(default = "default_cid")]
    pub cid: Option<String>,
}

fn default_can_throw() -> bool {
    false
}

fn default_cid() -> Option<String> {
    None
}

/// Represents the kind of a node in the PIH.
#[derive(Debug, Clone, Serialize, Deserialize, PartialEq, Eq, Hash)]
pub enum NodeKind {
    /// Value node: SSA value, constant, argument, or return value.
    Val,
    /// Object node: Object, array, or composite data structure.
    Obj,
    /// State node: Memory state or versioned data.
    State,
    /// Control node: Control point, branch, or join point.
    Ctrl,
    /// UI node: User interface element or interaction point.
    UI,
    /// Other node: Custom or specialized node types.
    Other,
}

/// Represents the kind of an edge in the PIH.
#[derive(Debug, Clone, Serialize, Deserialize, PartialEq, Eq, Hash)]
pub enum EdgeKind {
    /// Event edge: Computation operations (add, mul, for, etc.)
    Event,
    /// Flow edge: Data or state flow relationships (effects, dependencies)
    Flow,
    /// Meta edge: Metadata relationships (alias, reference, etc.)
    Meta,
}

/// Represents a role in an incidence relationship.
#[derive(Debug, Clone, Serialize, Deserialize, PartialEq, Eq, Hash)]
pub enum RoleKind {
    // Event roles
    DataIn,
    DataOut,
    CtrlIn,
    CtrlOut,
    StateIn,
    StateOut,
    Obj,
    ExcOut,
    // Flow roles
    Src,
    Dst,
    // Meta roles
    Left,
    Right,
    // Custom roles (for extensibility)
    Custom(String),
}

/// Represents a node in the PIH (unified node/edge/incidence structure).
/// A Node can be a value, object, state, control point, UI element, or other specialized types.
#[derive(Debug, Clone, Serialize, Deserialize, PartialEq, Eq)]
pub struct Node {
    pub id: String,
    pub kind: NodeKind,
    #[serde(rename = "type")]
    pub node_type: String,
    // Additional attributes based on kind
    #[serde(flatten)]
    pub attributes: HashMap<String, serde_json::Value>,
    /// Content ID for canonical representation (for content-addressable storage)
    #[serde(default = "default_cid")]
    pub cid: Option<String>,
}

// --- Incidence (Ports) ---

/// Defines the role of a port on an `Event` node.
/// This specifies the purpose of the connection to an `Entity`.
#[derive(Debug, Clone, Serialize, Deserialize, PartialEq, Eq, Hash)]
pub enum PortRole {
    DataIn,
    DataOut,
    CtrlIn,
    CtrlOut,
    StateIn,
    StateOut,
    Obj,
    ExcOut,
    // Can be extended with other custom roles.
    Other(String),
}

/// Represents an incidence in the tripartite hypergraph, connecting an edge to a node with a specific role.
/// This defines how nodes and edges are related in the unified node/edge/incidence structure.
#[derive(Debug, Clone, Serialize, Deserialize, PartialEq, Eq)]
pub struct Incidence {
    pub edge: String,
    pub node: String,
    pub role: RoleKind,
    /// Index for ordering multiple incidences with same edge and role
    #[serde(default)]
    pub idx: Option<u32>,
    /// Additional attributes for this incidence
    #[serde(default)]
    pub attrs: HashMap<String, serde_json::Value>,
    /// Content ID for canonical representation (for content-addressable storage)
    #[serde(default = "default_cid")]
    pub cid: Option<String>,
}

// --- State Edges ---

/// Represents a direct edge between two `State` entities, forming a version chain.
#[derive(Debug, Clone, Serialize, Deserialize, PartialEq, Eq)]
pub struct StateEdge {
    pub from: EntityId,
    pub to: EntityId,
}

// --- The Hypergraph ---

/// Represents node embeddings for GNN processing.
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct NodeEmbedding {
    pub node_id: String,
    pub embedding: Vec<f32>,
}

/// Represents the complete Program Interaction Hypergraph (PIH) using unified node/edge/incidence structure.
/// This is the core data structure for program representation in the unified tripartite model.
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct ProgramInteractionHypergraph {
    /// Metadata about the graph
    #[serde(default)]
    pub meta: HashMap<String, serde_json::Value>,
    /// All nodes in the hypergraph (formerly entities)
    pub nodes: Vec<Node>,
    /// All edges in the hypergraph (formerly events)
    pub edges: Vec<Edge>,
    /// All incidences connecting nodes and edges
    pub incidences: Vec<Incidence>,
    /// Node embeddings computed by GNN for learning-based optimization
    #[serde(default)]
    pub node_embeddings: HashMap<String, Vec<f32>>,
    /// Content ID for the entire hypergraph
    #[serde(default = "default_cid")]
    pub graph_cid: Option<String>,
    /// Subgraphs with their Merkle DAG CIDs
    #[serde(default)]
    pub subgraphs: HashMap<String, SubgraphInfo>,
    /// Embedding cache: CID -> embedding vector
    #[serde(default)]
    pub embedding_cache: HashMap<String, Vec<f32>>,
    /// Metadata for CID computation
    #[serde(default)]
    pub cid_metadata: Option<CidMetadata>,
}

/// Members of a subgraph for Merkle DAG construction
#[derive(Debug, Clone, Serialize, Deserialize, PartialEq, Eq)]
pub struct SubgraphMembers {
    pub nodes: Vec<String>, // list of node IDs
    pub edges: Vec<String>, // list of edge IDs
    pub incidences: Vec<String>, // list of incidence indices
}

/// Information about a subgraph with its Merkle DAG CID
#[derive(Debug, Clone, Serialize, Deserialize, PartialEq, Eq)]
pub struct SubgraphInfo {
    /// Subgraph identifier
    pub id: String,
    /// Members of the subgraph
    pub members: SubgraphMembers,
    /// Merkle root CID of the subgraph
    pub gcid: String,
    /// Optional metadata about the subgraph
    #[serde(default)]
    pub metadata: HashMap<String, serde_json::Value>,
}

/// CID computation metadata
#[derive(Debug, Clone, Serialize, Deserialize, PartialEq, Eq)]
pub struct CidMetadata {
    /// Hash algorithm used
    pub hash_algorithm: HashAlgorithm,
    /// Multibase encoding used
    pub multibase_encoding: MultibaseEncoding,
    /// Schema version
    pub schema_version: String,
    /// Timestamp of CID computation
    pub computed_at: u64,
}

/// Supported hash algorithms for CID computation
#[derive(Debug, Clone, Serialize, Deserialize, PartialEq, Eq)]
pub enum HashAlgorithm {
    Blake3,
    Sha256,
    Sha3_256,
}

/// Supported multibase encodings
#[derive(Debug, Clone, Serialize, Deserialize, PartialEq, Eq)]
pub enum MultibaseEncoding {
    Base64Url,
    Base58Btc,
    Base32,
    Base16,
}

impl PartialEq for ProgramInteractionHypergraph {
    fn eq(&self, other: &Self) -> bool {
        self.events == other.events &&
        self.entities == other.entities &&
        self.incidence == other.incidence &&
        self.state_edges == other.state_edges
        // Note: node_embeddings may not be compared for equality in rule matching
    }
}

impl ProgramInteractionHypergraph {
    /// Compute and assign CIDs to all objects in the PIH
    pub fn compute_all_cids(&mut self) -> Result<(), Box<dyn std::error::Error>> {
        let cid_system = CidSystem::new();

        // Compute CIDs for nodes (collect CIDs first to avoid borrow conflicts)
        let mut node_cids = Vec::new();
        for (i, node) in self.nodes.iter().enumerate() {
            let cid = cid_system.compute_node_cid(node)?;
            node_cids.push((i, cid));
        }

        // Assign CIDs to nodes
        for (i, cid) in node_cids {
            if i < self.nodes.len() {
                self.nodes[i].cid = Some(cid);
            }
        }

        // Compute CIDs for edges (collect CIDs first to avoid borrow conflicts)
        let mut edge_cids = Vec::new();
        for (i, edge) in self.edges.iter().enumerate() {
            let cid = cid_system.compute_edge_cid(edge)?;
            edge_cids.push((i, cid));
        }

        // Assign CIDs to edges
        for (i, cid) in edge_cids {
            if i < self.edges.len() {
                self.edges[i].cid = Some(cid);
            }
        }

        // Compute CIDs for incidences (collect CIDs first to avoid borrow conflicts)
        let mut incidence_cids = Vec::new();
        for (i, incidence) in self.incidences.iter().enumerate() {
            let cid = cid_system.compute_incidence_cid(incidence)?;
            incidence_cids.push((i, cid));
        }

        // Assign CIDs to incidences
        for (i, cid) in incidence_cids {
            if i < self.incidences.len() {
                self.incidences[i].cid = Some(cid);
            }
        }

        // Compute graph CID
        self.graph_cid = Some(cid_system.compute_graph_cid(self)?);

        // Set CID metadata
        use std::time::{SystemTime, UNIX_EPOCH};
        self.cid_metadata = Some(CidMetadata {
            hash_algorithm: HashAlgorithm::Blake3,
            multibase_encoding: MultibaseEncoding::Base64Url,
            schema_version: "pih.min.schema.v1".to_string(),
            computed_at: SystemTime::now()
                .duration_since(UNIX_EPOCH)
                .unwrap_or_default()
                .as_secs(),
        });

        Ok(())
    }

    /// Get embedding from cache or compute if not cached
    pub fn get_or_compute_embedding(&mut self, cid: &str) -> Option<&Vec<f32>> {
        // Check if embedding is already cached
        if self.embedding_cache.contains_key(cid) {
            return self.embedding_cache.get(cid);
        }

        // For now, return None - in a real implementation, this would compute the embedding
        // using the GNN model based on the structure identified by the CID
        None
    }

    /// Create a subgraph with its Merkle DAG CID
    pub fn create_subgraph(&mut self, subgraph_id: String, node_ids: Vec<String>, edge_ids: Vec<String>, incidence_indices: Vec<usize>) -> Result<String, Box<dyn std::error::Error>> {
        let cid_system = CidSystem::new();

        // Collect CIDs of the subgraph members
        let mut node_cids = Vec::new();
        let mut edge_cids = Vec::new();
        let mut incidence_cids = Vec::new();

        for node_id in &node_ids {
            if let Some(node) = self.nodes.iter().find(|n| n.id == *node_id) {
                if let Some(cid) = &node.cid {
                    node_cids.push(cid.clone());
                }
            }
        }

        for edge_id in &edge_ids {
            if let Some(edge) = self.edges.iter().find(|e| e.id == *edge_id) {
                if let Some(cid) = &edge.cid {
                    edge_cids.push(cid.clone());
                }
            }
        }

        for &incidence_idx in &incidence_indices {
            if incidence_idx < self.incidences.len() {
                let incidence = &self.incidences[incidence_idx];
                if let Some(cid) = &incidence.cid {
                    incidence_cids.push(cid.clone());
                }
            }
        }

        // Compute Merkle root
        let mut all_cids = Vec::new();
        all_cids.extend(node_cids.clone());
        all_cids.extend(edge_cids.clone());
        all_cids.extend(incidence_cids.clone());
        let gcid = cid_system.compute_merkle_root(&all_cids)?;

        // Create subgraph info
        let subgraph_members = SubgraphMembers {
            nodes: node_ids,
            edges: edge_ids,
            incidences: incidence_indices.iter().map(|i| i.to_string()).collect(),
        };

        let subgraph_info = SubgraphInfo {
            id: subgraph_id.clone(),
            members: subgraph_members,
            gcid: gcid.clone(),
            metadata: HashMap::new(),
        };

        self.subgraphs.insert(subgraph_id, subgraph_info);
        Ok(gcid)
    }
}

/// CID computation and canonicalization system
pub struct CidSystem {
    hash_algorithm: HashAlgorithm,
    multibase_encoding: MultibaseEncoding,
}

impl CidSystem {
    pub fn new() -> Self {
        Self {
            hash_algorithm: HashAlgorithm::Blake3,
            multibase_encoding: MultibaseEncoding::Base64Url,
        }
    }

    pub fn with_config(hash_algorithm: HashAlgorithm, multibase_encoding: MultibaseEncoding) -> Self {
        Self {
            hash_algorithm,
            multibase_encoding,
        }
    }

    /// Compute CID for any serializable object using canonical representation
    pub fn compute_cid<T: serde::Serialize>(&self, obj: &T) -> Result<String, Box<dyn std::error::Error>> {
        let canonical_json = self.canonicalize_json(obj)?;
        let hash_bytes = self.hash_bytes(canonical_json.as_bytes())?;
        let cid = self.encode_multibase(&hash_bytes)?;
        Ok(cid)
    }

    /// Canonicalize JSON representation (sorted keys, normalized values)
    fn canonicalize_json<T: serde::Serialize>(&self, obj: &T) -> Result<String, serde_json::Error> {
        let mut value = serde_json::to_value(obj)?;
        self.canonicalize_value(&mut value);
        serde_json::to_string(&value)
    }

    /// Recursively canonicalize a JSON value
    fn canonicalize_value(&self, value: &mut serde_json::Value) {
        match value {
            serde_json::Value::Object(map) => {
                // Sort keys alphabetically
                let mut keys: Vec<String> = map.keys().cloned().collect();
                keys.sort();

                // Create new sorted map
                let mut sorted_map = serde_json::Map::new();
                for key in keys {
                    if let Some(mut val) = map.remove(&key) {
                        self.canonicalize_value(&mut val);
                        sorted_map.insert(key, val);
                    }
                }
                *map = sorted_map;
            }
            serde_json::Value::Array(arr) => {
                // Recursively canonicalize array elements
                for item in arr.iter_mut() {
                    self.canonicalize_value(item);
                }
                // Sort array if it contains strings (for consistent ordering)
                if arr.iter().all(|v| matches!(v, serde_json::Value::String(_))) {
                    let mut sorted_arr: Vec<_> = arr.drain(..).collect();
                    sorted_arr.sort_by(|a, b| {
                        match (a, b) {
                            (serde_json::Value::String(s1), serde_json::Value::String(s2)) => s1.cmp(s2),
                            _ => std::cmp::Ordering::Equal,
                        }
                    });
                    *arr = sorted_arr;
                }
            }
            serde_json::Value::String(s) => {
                // Normalize string values (trim whitespace, lowercase if appropriate)
                *s = s.trim().to_string();
            }
            serde_json::Value::Number(n) => {
                // Ensure consistent number representation
                if let Some(f) = n.as_f64() {
                    if f == (f as i64 as f64) {
                        // Convert to integer if it's a whole number
                        *value = serde_json::Value::Number(serde_json::Number::from(f as i64));
                    }
                }
            }
            _ => {} // Leave other types as-is
        }
    }

    /// Hash bytes using the configured algorithm
    fn hash_bytes(&self, data: &[u8]) -> Result<Vec<u8>, Box<dyn std::error::Error>> {
        match self.hash_algorithm {
            HashAlgorithm::Blake3 => {
                let hash = blake3::hash(data);
                Ok(hash.as_bytes().to_vec())
            }
            HashAlgorithm::Sha256 => {
                use sha2::{Digest, Sha256};
                let mut hasher = Sha256::new();
                hasher.update(data);
                Ok(hasher.finalize().to_vec())
            }
            HashAlgorithm::Sha3_256 => {
                use sha3::{Digest, Sha3_256};
                let mut hasher = Sha3_256::new();
                hasher.update(data);
                Ok(hasher.finalize().to_vec())
            }
        }
    }

    /// Encode hash bytes using multibase encoding
    fn encode_multibase(&self, data: &[u8]) -> Result<String, Box<dyn std::error::Error>> {
        match self.multibase_encoding {
            MultibaseEncoding::Base64Url => {
                use base64::engine::general_purpose::URL_SAFE_NO_PAD;
                let engine = &URL_SAFE_NO_PAD;
                let encoded = base64::encode_engine(data, engine);
                Ok(format!("u{}", encoded))
            }
            MultibaseEncoding::Base58Btc => {
                let encoded = bs58::encode(data).into_string();
                Ok(format!("z{}", encoded))
            }
            MultibaseEncoding::Base32 => {
                let encoded = base32::encode(base32::Alphabet::RFC4648 { padding: false }, data);
                Ok(format!("b{}", encoded.to_lowercase()))
            }
            MultibaseEncoding::Base16 => {
                let encoded = hex::encode(data);
                Ok(format!("f{}", encoded))
            }
        }
    }

    /// Compute Merkle DAG root for a list of CIDs
    pub fn compute_merkle_root(&self, cids: &[String]) -> Result<String, Box<dyn std::error::Error>> {
        if cids.is_empty() {
            return Ok(self.compute_cid(&Vec::<String>::new())?);
        }

        // Sort CIDs for deterministic ordering
        let mut sorted_cids = cids.to_vec();
        sorted_cids.sort();

        // Concatenate all CIDs
        let concatenated: String = sorted_cids.join("");

        // Hash the concatenated string
        self.compute_cid(&concatenated)
    }

    /// Compute CID for Edge (excluding local ID for content-based addressing)
    pub fn compute_edge_cid(&self, edge: &Edge) -> Result<String, Box<dyn std::error::Error>> {
        // Create a copy without the ID for canonical representation
        let canonical_edge = CanonicalEdge {
            kind: edge.kind.clone(),
            label: edge.label.clone(),
            attributes: edge.attributes.clone(),
        };
        self.compute_cid(&canonical_edge)
    }

    /// Compute CID for Node (excluding local ID for content-based addressing)
    pub fn compute_node_cid(&self, node: &Node) -> Result<String, Box<dyn std::error::Error>> {
        // Create a copy without the ID for canonical representation
        let canonical_node = CanonicalNode {
            kind: node.kind.clone(),
            node_type: node.node_type.clone(),
            attributes: node.attributes.clone(),
        };
        self.compute_cid(&canonical_node)
    }

    /// Compute CID for Incidence (excluding local IDs for content-based addressing)
    pub fn compute_incidence_cid(&self, incidence: &Incidence) -> Result<String, Box<dyn std::error::Error>> {
        // Create a copy without the local IDs for canonical representation
        let canonical_incidence = CanonicalIncidence {
            edge_id: incidence.edge.clone(),
            node_id: incidence.node.clone(),
            role: incidence.role.clone(),
            idx: incidence.idx,
            attrs: incidence.attrs.clone(),
        };
        self.compute_cid(&canonical_incidence)
    }

    /// Compute graph CID for the entire PIH
    pub fn compute_graph_cid(&self, pih: &ProgramInteractionHypergraph) -> Result<String, Box<dyn std::error::Error>> {
        // Collect all node, edge, and incidence CIDs
        let mut all_cids: Vec<String> = Vec::new();

        // Add event CIDs
        for event in pih.events.values() {
            if let Some(cid) = &event.cid {
                all_cids.push(cid.clone());
            }
        }

        // Add entity CIDs
        for entity in pih.entities.values() {
            if let Some(cid) = &entity.cid {
                all_cids.push(cid.clone());
            }
        }

        // Add incidence CIDs
        for incidence in &pih.incidence {
            if let Some(cid) = &incidence.cid {
                all_cids.push(cid.clone());
            }
        }

        // Compute Merkle root
        self.compute_merkle_root(&all_cids)
    }
}

/// Canonical representation of Event for CID computation (without local ID)
#[derive(Debug, Clone, Serialize, Deserialize)]
struct CanonicalEvent {
    pub opcode: String,
    pub dtype: String,
    pub can_throw: bool,
    pub attributes: HashMap<String, serde_json::Value>,
}

/// Canonical representation of Node for CID computation (without local ID)
#[derive(Debug, Clone, Serialize, Deserialize)]
struct CanonicalNode {
    pub kind: NodeKind,
    pub node_type: String,
    pub attributes: HashMap<String, serde_json::Value>,
}

/// Canonical representation of Edge for CID computation (without local ID)
#[derive(Debug, Clone, Serialize, Deserialize)]
struct CanonicalEdge {
    pub kind: EdgeKind,
    pub label: Option<String>,
    pub attributes: HashMap<String, serde_json::Value>,
}

/// Canonical representation of Incidence for CID computation (without local IDs)
#[derive(Debug, Clone, Serialize, Deserialize)]
struct CanonicalIncidence {
    pub edge_id: String,
    pub node_id: String,
    pub role: RoleKind,
    pub idx: Option<u32>,
    pub attrs: HashMap<String, serde_json::Value>,
}


/// Converts a simple computation pattern into a PIH representation using unified node/edge/incidence structure.
/// This is a basic converter that can be extended to handle more complex patterns.
pub fn convert_computation_to_pih(
    opcode: &str,
    inputs: Vec<(String, NodeKind, String)>, // (id, kind, type)
    outputs: Vec<(String, NodeKind, String)>, // (id, kind, type)
    constants: Vec<(String, serde_json::Value)>, // (id, value)
) -> ProgramInteractionHypergraph {
    let mut pih = ProgramInteractionHypergraph::new();

    // Create event edge
    let event_edge = Edge {
        id: format!("event_{}", opcode),
        kind: EdgeKind::Event,
        label: Some(opcode.to_string()),
        attributes: [
            ("opcode".to_string(), json!(opcode)),
            ("dtype".to_string(), json!("i32")), // Default to i32, can be parameterized
        ].iter().cloned().collect(),
        cid: None,
    };
    pih.edges.push(event_edge);

    // Create input nodes
    let input_count = inputs.len();
    let constant_count = constants.len();
    for (id, kind, node_type) in inputs {
        let node = Node {
            id: id.clone(),
            kind,
            node_type: node_type.clone(),
            attributes: HashMap::new(),
            cid: None,
        };
        pih.nodes.push(node);

        // Add incidence
        pih.incidences.push(Incidence {
            edge: format!("event_{}", opcode),
            node: id,
            role: RoleKind::DataIn,
            idx: Some(pih.incidences.len() as u32),
            attrs: HashMap::new(),
            cid: None,
        });
    }

    // Create constant nodes
    for (id, value) in constants {
        let mut attributes = HashMap::new();
        attributes.insert("is_const".to_string(), json!(true));
        attributes.insert("value".to_string(), value);

        let node = Node {
            id: id.clone(),
            kind: NodeKind::Val,
            node_type: "i32".to_string(),
            attributes,
            cid: None,
        };
        pih.nodes.push(node);

        // Add incidence
        pih.incidences.push(Incidence {
            edge: format!("event_{}", opcode),
            node: id,
            role: RoleKind::DataIn,
            idx: Some(pih.incidences.len() as u32),
            attrs: HashMap::new(),
            cid: None,
        });
    }

    // Create output nodes
    for (id, kind, node_type) in outputs {
        let node = Node {
            id: id.clone(),
            kind,
            node_type: node_type.clone(),
            attributes: HashMap::new(),
            cid: None,
        };
        pih.nodes.push(node);

        // Add incidence
        pih.incidences.push(Incidence {
            edge: format!("event_{}", opcode),
            node: id,
            role: RoleKind::DataOut,
            idx: Some(pih.incidences.len() as u32),
            attrs: HashMap::new(),
            cid: None,
        });
    }

    pih
}

impl ProgramInteractionHypergraph {
    pub fn new() -> Self {
        Self {
            meta: HashMap::new(),
            nodes: Vec::new(),
            edges: Vec::new(),
            incidences: Vec::new(),
            node_embeddings: HashMap::new(),
            graph_cid: None,
            subgraphs: HashMap::new(),
            embedding_cache: HashMap::new(),
            cid_metadata: None,
        }
    }
}

impl Default for ProgramInteractionHypergraph {
    fn default() -> Self {
        Self::new()
    }
}

/// Creates a constant folding rule: add(x, 0)  x, mul(x, 1)  x
pub fn create_constant_folding_rule() -> DpoRule {
    // LHS: operation with identity constant
    let mut lhs = ProgramInteractionHypergraph::new();
    let op_event = Event {
        id: "op".to_string(),
        opcode: "add".to_string(), // Could be add, mul, etc.
        dtype: "i32".to_string(),
        can_throw: false,
        attributes: HashMap::new(),
        cid: None,
    };
    let x_entity = Entity {
        id: "x".to_string(),
        kind: EntityKind::Val,
        entity_type: "i32".to_string(),
        attributes: HashMap::new(),
        cid: None,
    };
    let identity_entity = Entity {
        id: "identity".to_string(),
        kind: EntityKind::Val,
        entity_type: "i32".to_string(),
        attributes: [
            ("is_const".to_string(), json!(true)),
            ("value".to_string(), json!(0)), // 0 for add, 1 for mul
        ].iter().cloned().collect(),
        cid: None,
    };
    let out_entity = Entity {
        id: "out".to_string(),
        kind: EntityKind::Val,
        entity_type: "i32".to_string(),
        attributes: HashMap::new(),
        cid: None,
    };

    lhs.events.insert(op_event.id.clone(), op_event);
    lhs.entities.insert(x_entity.id.clone(), x_entity.clone());
    lhs.entities.insert(identity_entity.id.clone(), identity_entity);
    lhs.entities.insert(out_entity.id.clone(), out_entity.clone());

    lhs.incidence.push(Incidence {
        event: "op".to_string(),
        port: "data_in[0]".to_string(),
        entity: "x".to_string(),
        cid: None,
    });
    lhs.incidence.push(Incidence {
        event: "op".to_string(),
        port: "data_in[1]".to_string(),
        entity: "identity".to_string(),
        cid: None,
    });
    lhs.incidence.push(Incidence {
        event: "op".to_string(),
        port: "data_out[0]".to_string(),
        entity: "out".to_string(),
        cid: None,
    });

    // RHS: just pass through x
    let mut rhs = ProgramInteractionHypergraph::new();
    rhs.entities.insert(x_entity.id.clone(), x_entity);
    rhs.entities.insert(out_entity.id.clone(), out_entity);

    DpoRule {
        name: "ConstantFolding".to_string(),
        description: "Eliminate operations with identity constants".to_string(),
        lhs,
        rhs,
        nacs: vec![], // No negative conditions for this simple rule
    }
}

/// Creates a dead code elimination rule
pub fn create_dead_code_elimination_rule() -> DpoRule {
    // LHS: computation result that is never used
    let mut lhs = ProgramInteractionHypergraph::new();
    let compute_event = Event {
        id: "compute".to_string(),
        opcode: "mul".to_string(),
        dtype: "i32".to_string(),
        can_throw: false,
        attributes: HashMap::new(),
        cid: None,
    };
    let x_entity = Entity {
        id: "x".to_string(),
        kind: EntityKind::Val,
        entity_type: "i32".to_string(),
        attributes: HashMap::new(),
        cid: None,
    };
    let y_entity = Entity {
        id: "y".to_string(),
        kind: EntityKind::Val,
        entity_type: "i32".to_string(),
        attributes: HashMap::new(),
        cid: None,
    };
    let unused_entity = Entity {
        id: "unused".to_string(),
        kind: EntityKind::Val,
        entity_type: "i32".to_string(),
        attributes: HashMap::new(),
        cid: None,
    };

    lhs.events.insert(compute_event.id.clone(), compute_event);
    lhs.entities.insert(x_entity.id.clone(), x_entity.clone());
    lhs.entities.insert(y_entity.id.clone(), y_entity.clone());
    lhs.entities.insert(unused_entity.id.clone(), unused_entity.clone());

    lhs.incidence.push(Incidence {
        event: "compute".to_string(),
        port: "data_in[0]".to_string(),
        entity: "x".to_string(),
        cid: None,
    });
    lhs.incidence.push(Incidence {
        event: "compute".to_string(),
        port: "data_in[1]".to_string(),
        entity: "y".to_string(),
        cid: None,
    });
    lhs.incidence.push(Incidence {
        event: "compute".to_string(),
        port: "data_out[0]".to_string(),
        entity: "unused".to_string(),
        cid: None,
    });

    // RHS: remove the unused computation entirely
    let mut rhs = ProgramInteractionHypergraph::new();
    rhs.entities.insert(x_entity.id.clone(), x_entity);
    rhs.entities.insert(y_entity.id.clone(), y_entity);

    // NAC: Don't eliminate if result is actually used somewhere
    let used_result_nac = NegativeApplicationCondition {
        name: "result_is_used".to_string(),
        description: "Don't eliminate if the result is used by another operation".to_string(),
        forbidden_incidence: vec![Incidence {
            event: "other_op".to_string(),
            port: "data_in[0]".to_string(),
            entity: "unused".to_string(),
            cid: None,
        }],
        forbidden_state_edges: vec![],
    };

    DpoRule {
        name: "DeadCodeElimination".to_string(),
        description: "Remove computations whose results are never used".to_string(),
        lhs,
        rhs,
        nacs: vec![used_result_nac],
    }
}

/// Creates a loop fusion rule: adjacent loops with same iteration space can be fused
pub fn create_loop_fusion_rule() -> DpoRule {
    // LHS: Two adjacent loops with same bounds and no dependencies between them
    let mut lhs = ProgramInteractionHypergraph::new();

    // Loop 1: for(i=0; i<N; i++) { a[i] = b[i] + c[i]; }
    let loop1_event = Event {
        id: "loop1".to_string(),
        opcode: "for".to_string(),
        dtype: "i32".to_string(),
        can_throw: false,
        attributes: [
            ("start".to_string(), json!(0)),
            ("end".to_string(), json!("N")),
            ("step".to_string(), json!(1)),
        ].iter().cloned().collect(),
        cid: None,
    };
    let i_entity = Entity {
        id: "i".to_string(),
        kind: EntityKind::Val,
        entity_type: "i32".to_string(),
        attributes: HashMap::new(),
        cid: None,
    };
    let a_entity = Entity {
        id: "a".to_string(),
        kind: EntityKind::Val,
        entity_type: "i32*".to_string(),
        attributes: HashMap::new(),
        cid: None,
    };
    let b_entity = Entity {
        id: "b".to_string(),
        kind: EntityKind::Val,
        entity_type: "i32*".to_string(),
        attributes: HashMap::new(),
        cid: None,
    };
    let c_entity = Entity {
        id: "c".to_string(),
        kind: EntityKind::Val,
        entity_type: "i32*".to_string(),
        attributes: HashMap::new(),
        cid: None,
    };

    lhs.events.insert(loop1_event.id.clone(), loop1_event);
    lhs.entities.insert(i_entity.id.clone(), i_entity.clone());
    lhs.entities.insert(a_entity.id.clone(), a_entity.clone());
    lhs.entities.insert(b_entity.id.clone(), b_entity.clone());
    lhs.entities.insert(c_entity.id.clone(), c_entity.clone());

    // Loop 1 body: a[i] = b[i] + c[i]
    lhs.incidence.push(Incidence {
        event: "loop1".to_string(),
        port: "index".to_string(),
        entity: "i".to_string(),
        cid: None,
    });
    lhs.incidence.push(Incidence {
        event: "loop1".to_string(),
        port: "body".to_string(),
        entity: "load_b".to_string(),
        cid: None,
    });

    // Loop 2: for(i=0; i<N; i++) { d[i] = e[i] * f[i]; }
    let loop2_event = Event {
        id: "loop2".to_string(),
        opcode: "for".to_string(),
        dtype: "i32".to_string(),
        can_throw: false,
        attributes: [
            ("start".to_string(), json!(0)),
            ("end".to_string(), json!("N")),
            ("step".to_string(), json!(1)),
        ].iter().cloned().collect(),
        cid: None,
    };
    let d_entity = Entity {
        id: "d".to_string(),
        kind: EntityKind::Val,
        entity_type: "i32*".to_string(),
        attributes: HashMap::new(),
        cid: None,
    };
    let e_entity = Entity {
        id: "e".to_string(),
        kind: EntityKind::Val,
        entity_type: "i32*".to_string(),
        attributes: HashMap::new(),
        cid: None,
    };
    let f_entity = Entity {
        id: "f".to_string(),
        kind: EntityKind::Val,
        entity_type: "i32*".to_string(),
        attributes: HashMap::new(),
        cid: None,
    };

    lhs.events.insert(loop2_event.id.clone(), loop2_event);
    lhs.entities.insert(d_entity.id.clone(), d_entity.clone());
    lhs.entities.insert(e_entity.id.clone(), e_entity.clone());
    lhs.entities.insert(f_entity.id.clone(), f_entity.clone());

    // Loop 2 body: d[i] = e[i] * f[i]
    lhs.incidence.push(Incidence {
        event: "loop2".to_string(),
        port: "index".to_string(),
        entity: "i".to_string(),
        cid: None,
    });
    lhs.incidence.push(Incidence {
        event: "loop2".to_string(),
        port: "body".to_string(),
        entity: "load_e".to_string(),
        cid: None,
    });

    // RHS: Fused loop with both operations
    let mut rhs = ProgramInteractionHypergraph::new();
    let fused_loop = Event {
        id: "fused_loop".to_string(),
        opcode: "for".to_string(),
        dtype: "i32".to_string(),
        can_throw: false,
        attributes: [
            ("start".to_string(), json!(0)),
            ("end".to_string(), json!("N")),
            ("step".to_string(), json!(1)),
        ].iter().cloned().collect(),
        cid: None,
    };

    rhs.events.insert(fused_loop.id.clone(), fused_loop);
    rhs.entities.insert(i_entity.id.clone(), i_entity);
    rhs.entities.insert(a_entity.id.clone(), a_entity);
    rhs.entities.insert(b_entity.id.clone(), b_entity);
    rhs.entities.insert(c_entity.id.clone(), c_entity);
    rhs.entities.insert(d_entity.id.clone(), d_entity);
    rhs.entities.insert(e_entity.id.clone(), e_entity);
    rhs.entities.insert(f_entity.id.clone(), f_entity);

    // Fused loop body: a[i] = b[i] + c[i]; d[i] = e[i] * f[i];
    rhs.incidence.push(Incidence {
        event: "fused_loop".to_string(),
        port: "index".to_string(),
        entity: "i".to_string(),
        cid: None,
    });
    rhs.incidence.push(Incidence {
        event: "fused_loop".to_string(),
        port: "body".to_string(),
        entity: "fused_body".to_string(),
        cid: None,
    });

    // NAC: No dependencies between loops
    let no_dependency_nac = NegativeApplicationCondition {
        name: "no_loop_dependencies".to_string(),
        description: "Cannot fuse loops if there are dependencies between them".to_string(),
        forbidden_incidence: vec![Incidence {
            event: "loop2".to_string(),
            port: "dependency".to_string(),
            entity: "loop1_output".to_string(),
            cid: None,
        }],
        forbidden_state_edges: vec![],
    };

    DpoRule {
        name: "LoopFusion".to_string(),
        description: "Fuse adjacent loops with same iteration space".to_string(),
        lhs,
        rhs,
        nacs: vec![no_dependency_nac],
    }
}

/// Creates a vectorization rule: scalar operations  SIMD operations
pub fn create_vectorization_rule() -> DpoRule {
    // LHS: Scalar addition loop
    let mut lhs = ProgramInteractionHypergraph::new();
    let scalar_loop = Event {
        id: "scalar_loop".to_string(),
        opcode: "for".to_string(),
        dtype: "i32".to_string(),
        can_throw: false,
        attributes: [
            ("start".to_string(), json!(0)),
            ("end".to_string(), json!("N")),
            ("step".to_string(), json!(1)),
        ].iter().cloned().collect(),
        cid: None,
    };
    let i_entity = Entity {
        id: "i".to_string(),
        kind: EntityKind::Val,
        entity_type: "i32".to_string(),
        attributes: HashMap::new(),
        cid: None,
    };
    let a_entity = Entity {
        id: "a".to_string(),
        kind: EntityKind::Val,
        entity_type: "i32*".to_string(),
        attributes: HashMap::new(),
        cid: None,
    };
    let b_entity = Entity {
        id: "b".to_string(),
        kind: EntityKind::Val,
        entity_type: "i32*".to_string(),
        attributes: HashMap::new(),
        cid: None,
    };

    lhs.events.insert(scalar_loop.id.clone(), scalar_loop);
    lhs.entities.insert(i_entity.id.clone(), i_entity.clone());
    lhs.entities.insert(a_entity.id.clone(), a_entity.clone());
    lhs.entities.insert(b_entity.id.clone(), b_entity.clone());

    lhs.incidence.push(Incidence {
        event: "scalar_loop".to_string(),
        port: "index".to_string(),
        entity: "i".to_string(),
        cid: None,
    });
    lhs.incidence.push(Incidence {
        event: "scalar_loop".to_string(),
        port: "body".to_string(),
        entity: "scalar_add".to_string(),
        cid: None,
    });

    // RHS: Vectorized loop with SIMD operations
    let mut rhs = ProgramInteractionHypergraph::new();
    let vector_loop = Event {
        id: "vector_loop".to_string(),
        opcode: "for".to_string(),
        dtype: "i32".to_string(),
        can_throw: false,
        attributes: [
            ("start".to_string(), json!(0)),
            ("end".to_string(), json!("N")),
            ("step".to_string(), json!(4)), // Process 4 elements per iteration
        ].iter().cloned().collect(),
        cid: None,
    };
    let vector_entity = Entity {
        id: "vector".to_string(),
        kind: EntityKind::Val,
        entity_type: "__m128i".to_string(), // SIMD vector type
        attributes: HashMap::new(),
        cid: None,
    };

    rhs.events.insert(vector_loop.id.clone(), vector_loop);
    rhs.entities.insert(i_entity.id.clone(), i_entity);
    rhs.entities.insert(a_entity.id.clone(), a_entity);
    rhs.entities.insert(b_entity.id.clone(), b_entity);
    rhs.entities.insert(vector_entity.id.clone(), vector_entity);

    rhs.incidence.push(Incidence {
        event: "vector_loop".to_string(),
        port: "index".to_string(),
        entity: "i".to_string(),
        cid: None,
    });
    rhs.incidence.push(Incidence {
        event: "vector_loop".to_string(),
        port: "body".to_string(),
        entity: "simd_add".to_string(),
        cid: None,
    });

    // NAC: Data must be aligned for SIMD operations
    let alignment_nac = NegativeApplicationCondition {
        name: "aligned_data".to_string(),
        description: "Data must be properly aligned for SIMD operations".to_string(),
        forbidden_incidence: vec![Incidence {
            event: "scalar_loop".to_string(),
            port: "unaligned".to_string(),
            entity: "data".to_string(),
            cid: None,
        }],
        forbidden_state_edges: vec![],
    };

    DpoRule {
        name: "Vectorization".to_string(),
        description: "Convert scalar operations to SIMD vector operations".to_string(),
        lhs,
        rhs,
        nacs: vec![alignment_nac],
    }
}

/// Creates a parallelization rule: sequential loop  parallel loop
pub fn create_parallelization_rule() -> DpoRule {
    // LHS: Sequential loop
    let mut lhs = ProgramInteractionHypergraph::new();
    let seq_loop = Event {
        id: "sequential_loop".to_string(),
        opcode: "for".to_string(),
        dtype: "i32".to_string(),
        can_throw: false,
        attributes: [
            ("start".to_string(), json!(0)),
            ("end".to_string(), json!("N")),
            ("step".to_string(), json!(1)),
        ].iter().cloned().collect(),
        cid: None,
    };
    let i_entity = Entity {
        id: "i".to_string(),
        kind: EntityKind::Val,
        entity_type: "i32".to_string(),
        attributes: HashMap::new(),
        cid: None,
    };
    let array_entity = Entity {
        id: "array".to_string(),
        kind: EntityKind::Val,
        entity_type: "i32*".to_string(),
        attributes: HashMap::new(),
        cid: None,
    };

    lhs.events.insert(seq_loop.id.clone(), seq_loop);
    lhs.entities.insert(i_entity.id.clone(), i_entity.clone());
    lhs.entities.insert(array_entity.id.clone(), array_entity.clone());

    lhs.incidence.push(Incidence {
        event: "sequential_loop".to_string(),
        port: "index".to_string(),
        entity: "i".to_string(),
        cid: None,
    });
    lhs.incidence.push(Incidence {
        event: "sequential_loop".to_string(),
        port: "body".to_string(),
        entity: "sequential_compute".to_string(),
        cid: None,
    });

    // RHS: Parallel loop using OpenMP or similar
    let mut rhs = ProgramInteractionHypergraph::new();
    let parallel_loop = Event {
        id: "parallel_loop".to_string(),
        opcode: "parallel_for".to_string(),
        dtype: "i32".to_string(),
        can_throw: false,
        attributes: [
            ("start".to_string(), json!(0)),
            ("end".to_string(), json!("N")),
            ("step".to_string(), json!(1)),
            ("num_threads".to_string(), json!(4)),
        ].iter().cloned().collect(),
        cid: None,
    };
    let thread_id_entity = Entity {
        id: "thread_id".to_string(),
        kind: EntityKind::Val,
        entity_type: "i32".to_string(),
        attributes: HashMap::new(),
        cid: None,
    };

    rhs.events.insert(parallel_loop.id.clone(), parallel_loop);
    rhs.entities.insert(i_entity.id.clone(), i_entity);
    rhs.entities.insert(array_entity.id.clone(), array_entity);
    rhs.entities.insert(thread_id_entity.id.clone(), thread_id_entity);

    rhs.incidence.push(Incidence {
        event: "parallel_loop".to_string(),
        port: "index".to_string(),
        entity: "i".to_string(),
        cid: None,
    });
    rhs.incidence.push(Incidence {
        event: "parallel_loop".to_string(),
        port: "thread_id".to_string(),
        entity: "thread_id".to_string(),
        cid: None,
    });
    rhs.incidence.push(Incidence {
        event: "parallel_loop".to_string(),
        port: "body".to_string(),
        entity: "parallel_compute".to_string(),
        cid: None,
    });

    // NAC: No loop-carried dependencies
    let no_dependency_nac = NegativeApplicationCondition {
        name: "no_loop_dependencies".to_string(),
        description: "Cannot parallelize if there are loop-carried dependencies".to_string(),
        forbidden_incidence: vec![Incidence {
            event: "sequential_loop".to_string(),
            port: "dependency".to_string(),
            entity: "previous_iteration".to_string(),
            cid: None,
        }],
        forbidden_state_edges: vec![],
    };

    DpoRule {
        name: "Parallelization".to_string(),
        description: "Convert sequential loops to parallel execution".to_string(),
        lhs,
        rhs,
        nacs: vec![no_dependency_nac],
    }
}

/// Creates a strength reduction rule: mul(x, 2^k)  shl(x, k)
pub fn create_strength_reduction_rule() -> DpoRule {
    // LHS: mul operation with constant power of 2
    let mut lhs = ProgramInteractionHypergraph::new();
    let mul_event = Event {
        id: "mul_op".to_string(),
        opcode: "mul".to_string(),
        dtype: "i32".to_string(),
        can_throw: false,
        attributes: HashMap::new(),
        cid: None,
    };
    let x_entity = Entity {
        id: "x".to_string(),
        kind: EntityKind::Val,
        entity_type: "i32".to_string(),
        attributes: HashMap::new(),
        cid: None,
    };
    let c_entity = Entity {
        id: "c".to_string(),
        kind: EntityKind::Val,
        entity_type: "i32".to_string(),
        attributes: [
            ("is_const".to_string(), json!(true)),
            ("value".to_string(), json!(8)), // 2^3
        ].iter().cloned().collect(),
        cid: None,
    };
    let out_entity = Entity {
        id: "out".to_string(),
        kind: EntityKind::Val,
        entity_type: "i32".to_string(),
        attributes: HashMap::new(),
        cid: None,
    };

    lhs.events.insert(mul_event.id.clone(), mul_event);
    lhs.entities.insert(x_entity.id.clone(), x_entity.clone());
    lhs.entities.insert(c_entity.id.clone(), c_entity);
    lhs.entities.insert(out_entity.id.clone(), out_entity.clone());

        lhs.incidences.push(Incidence {
            edge: "mul_op".to_string(),
            node: "x".to_string(),
            role: RoleKind::DataIn,
            idx: Some(0),
            attrs: HashMap::new(),
            cid: None,
        });
        lhs.incidences.push(Incidence {
            edge: "mul_op".to_string(),
            node: "c".to_string(),
            role: RoleKind::DataIn,
            idx: Some(1),
            attrs: HashMap::new(),
            cid: None,
        });
        lhs.incidences.push(Incidence {
            edge: "mul_op".to_string(),
            node: "out".to_string(),
            role: RoleKind::DataOut,
            idx: Some(0),
            attrs: HashMap::new(),
            cid: None,
        });

    // RHS: equivalent shift operation
    let mut rhs = ProgramInteractionHypergraph::new();
    let shift_amount = Node {
        id: "shift_amt".to_string(),
        kind: NodeKind::Val,
        node_type: "i32".to_string(),
        attributes: [
            ("is_const".to_string(), json!(true)),
            ("value".to_string(), json!(3)), // log2(8)
        ].iter().cloned().collect(),
        cid: None,
    };
    let shl_edge = Edge {
        id: "shl_op".to_string(),
        kind: EdgeKind::Event,
        label: Some("shl".to_string()),
        attributes: [
            ("opcode".to_string(), json!("shl")),
            ("dtype".to_string(), json!("i32")),
            ("can_throw".to_string(), json!(false)),
        ].iter().cloned().collect(),
        cid: None,
    };

    rhs.edges.push(shl_edge);
    rhs.nodes.push(x_node);
    rhs.nodes.push(shift_amount);
    rhs.nodes.push(out_node);

    rhs.incidences.push(Incidence {
        edge: "shl_op".to_string(),
        node: "x".to_string(),
        role: RoleKind::DataIn,
        idx: Some(0),
        attrs: HashMap::new(),
        cid: None,
    });
    rhs.incidences.push(Incidence {
        edge: "shl_op".to_string(),
        node: "shift_amt".to_string(),
        role: RoleKind::DataIn,
        idx: Some(1),
        attrs: HashMap::new(),
        cid: None,
    });
    rhs.incidences.push(Incidence {
        edge: "shl_op".to_string(),
        node: "out".to_string(),
        role: RoleKind::DataOut,
        idx: Some(0),
        attrs: HashMap::new(),
        cid: None,
    });

    // NAC: Don't apply if dtype is floating point (due to rounding differences)
    let floating_point_nac = NegativeApplicationCondition {
        name: "no_floating_point".to_string(),
        description: "Don't apply strength reduction to floating point types".to_string(),
        forbidden_incidences: vec![Incidence {
            edge: "mul_op".to_string(),
            node: "float_type".to_string(),
            role: RoleKind::DataIn,
            idx: Some(0),
            attrs: [
                ("dtype".to_string(), json!("float")),
            ].iter().cloned().collect(),
            cid: None,
        }],
        forbidden_state_edges: vec![],
    };

    DpoRule {
        name: "StrengthReduction".to_string(),
        description: "Convert multiplication by power of 2 to shift operation".to_string(),
        lhs,
        rhs,
        nacs: vec![floating_point_nac],
    }
}

#[cfg(test)]
mod tests {
    use super::*;
    use serde_json::json;

    #[test]
    fn test_pih_serialization_deserialization() {
        let mut pih = ProgramInteractionHypergraph::new();

        // Edges
        let edge1 = Edge {
            id: "e1".to_string(),
            kind: EdgeKind::Event,
            label: Some("mul".to_string()),
            attributes: [
                ("opcode".to_string(), json!("mul")),
                ("dtype".to_string(), json!("i32")),
                ("can_throw".to_string(), json!(false)),
            ].iter().cloned().collect(),
            cid: None,
        };
        let node_x = Node {
            id: "v_x".to_string(),
            kind: NodeKind::Val,
            node_type: "i32".to_string(),
            attributes: HashMap::new(),
            cid: None,
        };
        let mut const_attr = HashMap::new();
        const_attr.insert("is_const".to_string(), json!(true));
        const_attr.insert("value".to_string(), json!(8));
        let node_c = Node {
            id: "v_c".to_string(),
            kind: NodeKind::Val,
            node_type: "i32".to_string(),
            attributes: const_attr,
            cid: None,
        };
        let node_out = Node {
            id: "v_out".to_string(),
            kind: NodeKind::Val,
            node_type: "i32".to_string(),
            attributes: HashMap::new(),
            cid: None,
        };
        let state3 = Node {
            id: "s3".to_string(),
            kind: NodeKind::State,
            node_type: "heap".to_string(),
            attributes: HashMap::new(),
            cid: None,
        };
        let state4 = Node {
            id: "s4".to_string(),
            kind: NodeKind::State,
            node_type: "heap".to_string(),
            attributes: HashMap::new(),
            cid: None,
        };

        pih.edges.push(edge1);
        pih.nodes.push(node_x);
        pih.nodes.push(node_c);
        pih.nodes.push(node_out);
        pih.nodes.push(state3);
        pih.nodes.push(state4);

        // Incidences
        pih.incidences.push(Incidence {
            edge: "e1".to_string(),
            node: "v_x".to_string(),
            role: RoleKind::DataIn,
            idx: Some(0),
            attrs: HashMap::new(),
            cid: None,
        });
        pih.incidences.push(Incidence {
            edge: "e1".to_string(),
            node: "v_c".to_string(),
            role: RoleKind::DataIn,
            idx: Some(1),
            attrs: HashMap::new(),
            cid: None,
        });
        pih.incidences.push(Incidence {
            edge: "e1".to_string(),
            node: "v_out".to_string(),
            role: RoleKind::DataOut,
            idx: Some(0),
            attrs: HashMap::new(),
            cid: None,
        });
        pih.incidences.push(Incidence {
            edge: "e1".to_string(),
            node: "s3".to_string(),
            role: RoleKind::StateIn,
            idx: Some(0),
            attrs: HashMap::new(),
            cid: None,
        });
        pih.incidences.push(Incidence {
            edge: "e1".to_string(),
            node: "s4".to_string(),
            role: RoleKind::StateOut,
            idx: Some(0),
            attrs: HashMap::new(),
            cid: None,
        });
        pih.incidences.push(Incidence {
            edge: "e1".to_string(),
            node: "c1".to_string(),
            role: RoleKind::CtrlIn,
            idx: Some(0),
            attrs: HashMap::new(),
            cid: None,
        });
        pih.incidences.push(Incidence {
            edge: "e1".to_string(),
            node: "c1".to_string(),
            role: RoleKind::CtrlOut,
            idx: Some(0),
            attrs: HashMap::new(),
            cid: None,
        });

        // State flow edge
        let flow_edge = Edge {
            id: "flow_s3_s4".to_string(),
            kind: EdgeKind::Flow,
            label: Some("heap_flow".to_string()),
            attributes: [
                ("flow_type".to_string(), json!("EFFECTS")),
            ].iter().cloned().collect(),
            cid: None,
        };

        pih.edges.push(flow_edge);
        pih.incidences.push(Incidence {
            edge: "flow_s3_s4".to_string(),
            node: "s3".to_string(),
            role: RoleKind::Src,
            idx: Some(0),
            attrs: HashMap::new(),
            cid: None,
        });
        pih.incidences.push(Incidence {
            edge: "flow_s3_s4".to_string(),
            node: "s4".to_string(),
            role: RoleKind::Dst,
            idx: Some(0),
            attrs: HashMap::new(),
            cid: None,
        });

        let serialized = serde_json::to_string_pretty(&pih).unwrap();
        
        // This is a simplified check. A more robust test would compare field by field.
        assert!(serialized.contains("\"opcode\": \"mul\""));
        assert!(serialized.contains("\"kind\": \"State\""));
        assert!(serialized.contains("\"role\": \"data_in\""));
        assert!(serialized.contains("\"flow_type\": \"EFFECTS\""));

        let deserialized: ProgramInteractionHypergraph = serde_json::from_str(&serialized).unwrap();
        assert_eq!(deserialized.edges.len(), 2); // e1, flow_s3_s4
        assert_eq!(deserialized.nodes.len(), 5); // v_x, v_c, v_out, s3, s4
        assert_eq!(deserialized.incidences.len(), 8); // 6 for e1, 2 for flow_s3_s4
        assert_eq!(deserialized.nodes.iter().find(|n| n.id == "v_c").unwrap().attributes.get("value").unwrap(), &json!(8));
    }

    #[test]
    fn test_strength_reduction_rule() {
        let rule = create_strength_reduction_rule();

        // Check LHS structure
        assert_eq!(rule.lhs.edges.len(), 1);
        assert_eq!(rule.lhs.nodes.len(), 3); // x, c, out
        assert_eq!(rule.lhs.incidences.len(), 3);
        assert_eq!(rule.lhs.edges.iter().find(|e| e.id == "mul_op").unwrap().attributes.get("opcode").unwrap(), &json!("mul"));

        // Check RHS structure
        assert_eq!(rule.rhs.edges.len(), 1);
        assert_eq!(rule.rhs.nodes.len(), 3); // x, shift_amt, out
        assert_eq!(rule.rhs.incidences.len(), 3);
        assert_eq!(rule.rhs.edges.iter().find(|e| e.id == "shl_op").unwrap().attributes.get("opcode").unwrap(), &json!("shl"));

        // Check NAC
        assert_eq!(rule.nacs.len(), 1);
        assert_eq!(rule.nacs[0].name, "no_floating_point");
    }

    #[test]
    fn test_convert_computation_to_pih() {
        let inputs = vec![
            ("x".to_string(), EntityKind::Val, "i32".to_string()),
        ];
        let outputs = vec![
            ("result".to_string(), EntityKind::Val, "i32".to_string()),
        ];
        let constants = vec![
            ("eight".to_string(), json!(8)),
        ];

        let pih = convert_computation_to_pih("mul", inputs, outputs, constants);

        assert_eq!(pih.events.len(), 1);
        assert_eq!(pih.entities.len(), 3); // x, eight, result
        assert_eq!(pih.incidence.len(), 3); // 1 input + 1 constant + 1 output
        assert_eq!(pih.events.get("event_mul").unwrap().opcode, "mul");

        // Check constant entity
        let const_entity = pih.entities.get("eight").unwrap();
        assert_eq!(const_entity.attributes.get("is_const").unwrap(), &json!(true));
        assert_eq!(const_entity.attributes.get("value").unwrap(), &json!(8));
    }

    #[test]
    fn test_constant_folding_rule() {
        let rule = create_constant_folding_rule();

        // Check LHS structure
        assert_eq!(rule.lhs.events.len(), 1);
        assert_eq!(rule.lhs.entities.len(), 3); // x, identity, out
        assert_eq!(rule.lhs.incidence.len(), 3);
        assert_eq!(rule.lhs.events.get("op").unwrap().opcode, "add");

        // Check RHS structure (simplified - just entities, no operations)
        assert_eq!(rule.rhs.events.len(), 0);
        assert_eq!(rule.rhs.entities.len(), 2); // x, out
        assert_eq!(rule.rhs.incidence.len(), 0); // No operations

        // Check identity constant
        let identity_entity = rule.lhs.entities.get("identity").unwrap();
        assert_eq!(identity_entity.attributes.get("value").unwrap(), &json!(0));

        // Check NACs
        assert_eq!(rule.nacs.len(), 0); // No negative conditions
    }

    #[test]
    fn test_dead_code_elimination_rule() {
        let rule = create_dead_code_elimination_rule();

        // Check LHS structure
        assert_eq!(rule.lhs.events.len(), 1);
        assert_eq!(rule.lhs.entities.len(), 3); // x, y, unused
        assert_eq!(rule.lhs.incidence.len(), 3);

        // Check RHS structure (unused entities removed)
        assert_eq!(rule.rhs.events.len(), 0);
        assert_eq!(rule.rhs.entities.len(), 2); // x, y (unused removed)
        assert_eq!(rule.rhs.incidence.len(), 0);

        // Check NACs
        assert_eq!(rule.nacs.len(), 1);
        assert_eq!(rule.nacs[0].name, "result_is_used");
    }

    #[test]
    fn test_loop_fusion_rule() {
        let rule = create_loop_fusion_rule();

        // Check LHS structure (2 loops)
        assert_eq!(rule.lhs.events.len(), 2); // loop1, loop2
        assert_eq!(rule.lhs.entities.len(), 7); // i, a, b, c, d, e, f
        assert_eq!(rule.lhs.incidence.len(), 4); // 2 loops * 2 incidence each

        // Check RHS structure (1 fused loop)
        assert_eq!(rule.rhs.events.len(), 1); // fused_loop
        assert_eq!(rule.rhs.entities.len(), 7); // All entities preserved
        assert_eq!(rule.rhs.incidence.len(), 2); // 1 loop * 2 incidence

        // Check NACs
        assert_eq!(rule.nacs.len(), 1);
        assert_eq!(rule.nacs[0].name, "no_loop_dependencies");
    }

    #[test]
    fn test_vectorization_rule() {
        let rule = create_vectorization_rule();

        // Check LHS structure (scalar loop)
        assert_eq!(rule.lhs.events.len(), 1);
        assert_eq!(rule.lhs.entities.len(), 3); // i, a, b
        assert_eq!(rule.lhs.incidence.len(), 2);

        // Check RHS structure (vectorized loop)
        assert_eq!(rule.rhs.events.len(), 1);
        assert_eq!(rule.rhs.entities.len(), 4); // i, a, b, vector
        assert_eq!(rule.rhs.incidence.len(), 2);

        // Check SIMD vector type
        assert!(rule.rhs.entities.get("vector").unwrap().entity_type == "__m128i");

        // Check NACs
        assert_eq!(rule.nacs.len(), 1);
        assert_eq!(rule.nacs[0].name, "aligned_data");
    }

    #[test]
    fn test_parallelization_rule() {
        let rule = create_parallelization_rule();

        // Check LHS structure (sequential loop)
        assert_eq!(rule.lhs.events.len(), 1);
        assert_eq!(rule.lhs.entities.len(), 2); // i, array
        assert_eq!(rule.lhs.incidence.len(), 2);

        // Check RHS structure (parallel loop)
        assert_eq!(rule.rhs.events.len(), 1);
        assert_eq!(rule.rhs.entities.len(), 3); // i, array, thread_id
        assert_eq!(rule.rhs.incidence.len(), 3); // Added thread_id

        // Check parallel loop attributes
        let parallel_loop = rule.rhs.events.get("parallel_loop").unwrap();
        assert!(parallel_loop.attributes.get("num_threads") == Some(&json!(4)));

        // Check NACs
        assert_eq!(rule.nacs.len(), 1);
        assert_eq!(rule.nacs[0].name, "no_loop_dependencies");
    }

    #[test]
    fn test_gnn_training_feature_extraction() {
        use crate::gnn_training::{FeatureExtractor, GnnTrainer, TrainingConfig, OptimizationLabels};

        // Create a simple PIH for testing
        let mut pih = ProgramInteractionHypergraph::new();

        let loop_event_id = "test_loop".to_string();
        let i_entity_id = "i".to_string();
        let array_entity_id = "array".to_string();

        let loop_event = Event {
            id: loop_event_id.clone(),
            opcode: "for".to_string(),
            dtype: "i32".to_string(),
            can_throw: false,
            cid: None,
            attributes: [("start".to_string(), json!(0)), ("end".to_string(), json!("N"))].iter().cloned().collect(),
        };

        let i_entity = Entity {
            id: i_entity_id.clone(),
            kind: EntityKind::Val,
            entity_type: "i32".to_string(),
            attributes: HashMap::new(),
            cid: None,
        };

        let array_entity = Entity {
            id: array_entity_id.clone(),
            kind: EntityKind::Val,
            entity_type: "i32*".to_string(),
            attributes: HashMap::new(),
        };

        pih.events.insert(loop_event_id, loop_event);
        pih.entities.insert(i_entity_id, i_entity);
        pih.entities.insert(array_entity_id, array_entity);

        pih.incidence.push(Incidence {
            event: "test_loop".to_string(),
            port: "index".to_string(),
            entity: "i".to_string(),
        });
        pih.incidence.push(Incidence {
            event: "test_loop".to_string(),
            port: "body".to_string(),
            entity: "array".to_string(),
        });

        // Extract features
        let features = FeatureExtractor::extract_features(&pih);

        // Verify feature dimensions
        assert!(!features.node_features.is_empty());
        assert!(!features.edge_features.is_empty());
        assert!(!features.global_features.is_empty());

        // Check global features (should have graph statistics)
        assert_eq!(features.global_features.len(), 8);

        // Check bipartite features
        assert_eq!(features.bipartite_features.event_node_count, 1);
        assert_eq!(features.bipartite_features.entity_node_count, 2);
        assert_eq!(features.bipartite_features.event_to_entity_edges, 2);
        assert_eq!(features.bipartite_features.node_type_distribution.len(), 2);

        // Check hypergraph features
        assert_eq!(features.hypergraph_features.hyperedge_sizes.len(), 1);
        assert_eq!(features.hypergraph_features.avg_hyperedge_size, 2.0);
        assert_eq!(features.hypergraph_features.max_hyperedge_size, 2);
        assert!(!features.hypergraph_features.node_hyperedge_membership.is_empty());
    }

    #[test]
    fn test_gnn_model_creation() {
        use crate::gnn_training::{GnnTrainer, TrainingConfig, GnnModelType};

        let config = TrainingConfig {
            learning_rate: 0.001,
            batch_size: 32,
            num_epochs: 100,
            hidden_dim: 64,
            num_layers: 3,
            dropout: 0.1,
        };

        let model = GnnTrainer::create_model(&config);

        assert_eq!(model.hidden_dim, 64);
        assert_eq!(model.num_layers, 3);
        assert_eq!(model.dropout, 0.1);
        assert_eq!(model.model_type, GnnModelType::BipartiteGnn);
        assert_eq!(model.attention_heads, 4);
        assert_eq!(model.weights.len(), 3);
        assert_eq!(model.weights[0].len(), 64);
        assert_eq!(model.weights[0][0].len(), 64);
    }

    #[test]
    fn test_gat_model_creation() {
        use crate::gnn_training::{GnnTrainer, TrainingConfig, GnnModelType};

        let config = TrainingConfig {
            learning_rate: 0.001,
            batch_size: 32,
            num_epochs: 100,
            hidden_dim: 64,
            num_layers: 2,
            dropout: 0.1,
        };

        let model = GnnTrainer::create_gat_model(&config, 8);

        assert_eq!(model.hidden_dim, 64);
        assert_eq!(model.num_layers, 2);
        assert_eq!(model.dropout, 0.1);
        assert_eq!(model.model_type, GnnModelType::Gat);
        assert_eq!(model.attention_heads, 8);
        assert_eq!(model.weights.len(), 2);
        assert_eq!(model.weights[0].len(), 64); // 64 output dimensions
        assert_eq!(model.weights[0][0].len(), 64); // 64 input dimensions
    }

    #[test]
    fn test_gnn_model_types() {
        use crate::gnn_training::{GnnModelType, OptimizationGnn};

        let mut model = OptimizationGnn::default();
        assert_eq!(model.model_type, GnnModelType::BipartiteGnn);

        model.model_type = GnnModelType::Gat;
        assert_eq!(model.model_type, GnnModelType::Gat);

        model.model_type = GnnModelType::Gcn;
        assert_eq!(model.model_type, GnnModelType::Gcn);

        model.model_type = GnnModelType::GraphSage;
        assert_eq!(model.model_type, GnnModelType::GraphSage);

        model.model_type = GnnModelType::HetGnn;
        assert_eq!(model.model_type, GnnModelType::HetGnn);
    }

    #[test]
    fn test_synthetic_dataset_generation() {
        use crate::gnn_training::GnnTrainer;

        let dataset = GnnTrainer::generate_synthetic_dataset(10);

        assert_eq!(dataset.len(), 10);

        // Check first sample
        let sample = &dataset[0];
        assert!(sample.sample_id.starts_with("sample_"));
        assert!(!sample.features.node_features.is_empty());
        assert!(!sample.labels.rule_applications.is_empty(), "Sample 0 should have optimization rules. Rules: {:?}", sample.labels.rule_applications);
        assert!(sample.labels.performance_gain >= 0.0 && sample.labels.performance_gain <= 1.0);
    }

    #[test]
    fn test_training_loss_computation() {
        use crate::gnn_training::{GnnTrainer, OptimizationLabels};

        let predicted = OptimizationLabels {
            rule_applications: vec!["LoopFusion".to_string()],
            performance_gain: 0.3,
            memory_reduction: 0.2,
            energy_savings: 0.25,
        };

        let actual = OptimizationLabels {
            rule_applications: vec!["LoopFusion".to_string(), "Vectorization".to_string()],
            performance_gain: 0.5,
            memory_reduction: 0.1,
            energy_savings: 0.3,
        };

        let loss = GnnTrainer::compute_loss(&predicted, &actual);
        assert!(loss >= 0.0);
        assert!(loss < 2.0); // Should be reasonable loss value
    }

    #[test]
    fn test_hardware_feature_extraction() {
        use crate::gnn_training::{FeatureExtractor, GnnFeatures, SpatialPatternType, DataflowType};

        // Create a simple PIH for testing
        let mut pih = ProgramInteractionHypergraph::new();

        let event = Event {
            id: "test_event".to_string(),
            opcode: "cgra_compute".to_string(),
            dtype: "f32*".to_string(),
            can_throw: false,
            cid: None,
            attributes: [
                ("pattern".to_string(), json!("systolic_array")),
                ("grid_size".to_string(), json!("2x2")),
            ].iter().cloned().collect(),
        };

        let entity = Entity {
            id: "test_entity".to_string(),
            kind: EntityKind::Obj,
            entity_type: "f32*".to_string(),
            attributes: [("size".to_string(), json!(1024))].iter().cloned().collect(),
        };

        pih.events.insert("test_event".to_string(), event);
        pih.entities.insert("test_entity".to_string(), entity);

        let features = FeatureExtractor::extract_features(&pih);

        // Verify hardware features are extracted
        assert!(features.hardware_features.cgra_features.spatial_patterns.len() > 0);
        assert!(features.hardware_features.fpga_features.rtl_patterns.len() >= 0);

        // Check CGRA pattern detection
        let spatial_pattern = &features.hardware_features.cgra_features.spatial_patterns[0];
        assert_eq!(spatial_pattern.pattern_type, SpatialPatternType::SystolicArray);

        // Check hardware constraints
        assert!(features.hardware_features.hardware_constraints.max_memory_usage > 0);
        assert!(features.hardware_features.hardware_constraints.max_compute_units > 0);
        assert!(features.hardware_features.hardware_constraints.target_frequency > 0.0);
    }

    #[test]
    fn test_cgra_optimization_patterns() {
        use crate::gnn_training::{FeatureExtractor, SpatialPatternType, DataflowType, RtlPatternType};

        // Create CGRA matrix multiplication pattern
        let mut pih = ProgramInteractionHypergraph::new();

        let cgra_kernel = Event {
            id: "cgra_kernel".to_string(),
            opcode: "cgra_compute".to_string(),
            dtype: "f32*".to_string(),
            can_throw: false,
            cid: None,
            attributes: [
                ("pattern".to_string(), json!("systolic_array")),
                ("dataflow".to_string(), json!("stationary")),
            ].iter().cloned().collect(),
        };

        // Add matrix entities
        for i in 0..3 {
            let entity = Entity {
                id: format!("matrix_{}", i),
                kind: EntityKind::Obj,
                entity_type: "f32*".to_string(),
                attributes: [("size".to_string(), json!(1024))].iter().cloned().collect(),
            };
            pih.entities.insert(format!("matrix_{}", i), entity);
        }

        pih.events.insert("cgra_kernel".to_string(), cgra_kernel);

        let features = FeatureExtractor::extract_features(&pih);

        // Verify CGRA-specific features
        assert!(features.hardware_features.cgra_features.spatial_patterns.len() > 0);
        assert_eq!(features.hardware_features.cgra_features.dataflow_type, DataflowType::DataParallel);

        // Check for systolic array pattern
        let pattern = &features.hardware_features.cgra_features.spatial_patterns[0];
        assert_eq!(pattern.pattern_type, SpatialPatternType::SystolicArray);
        assert_eq!(pattern.grid_size, (2, 2));

        // Verify resource estimation
        assert!(features.hardware_features.fpga_features.resource_utilization.dsp_usage > 0.0);
        assert!(features.hardware_features.hardware_constraints.max_compute_units >= 1);
    }

    #[test]
    fn test_fpga_optimization_patterns() {
        use crate::gnn_training::{FeatureExtractor, RtlPatternType, SynthesisDirectiveType};

        // Create FPGA pipelining pattern
        let mut pih = ProgramInteractionHypergraph::new();

        let fpga_pipeline = Event {
            id: "fpga_pipeline".to_string(),
            opcode: "fpga_compute".to_string(),
            dtype: "f32*".to_string(),
            can_throw: false,
            cid: None,
            attributes: [
                ("pipeline_depth".to_string(), json!(5)),
                ("target_frequency".to_string(), json!(250.0)),
                ("resource_type".to_string(), json!("dsp_chain")),
            ].iter().cloned().collect(),
        };

        // Add array entities
        for i in 0..2 {
            let entity = Entity {
                id: format!("array_{}", i),
                kind: EntityKind::Obj,
                entity_type: "f32*".to_string(),
                attributes: [("size".to_string(), json!(2048))].iter().cloned().collect(),
            };
            pih.entities.insert(format!("array_{}", i), entity);
        }

        pih.events.insert("fpga_pipeline".to_string(), fpga_pipeline);

        let features = FeatureExtractor::extract_features(&pih);

        // Verify FPGA-specific features
        assert!(features.hardware_features.fpga_features.rtl_patterns.len() > 0);
        assert!(features.hardware_features.fpga_features.synthesis_directives.len() > 0);

        // Check RTL pattern detection
        let rtl_pattern = &features.hardware_features.fpga_features.rtl_patterns[0];
        assert_eq!(rtl_pattern.pattern_type, RtlPatternType::PipelinedMultiplier);

        // Check synthesis directives
        let directive = &features.hardware_features.fpga_features.synthesis_directives[0];
        assert_eq!(directive.directive_type, SynthesisDirectiveType::Retiming);

        // Verify timing constraints
        assert!(features.hardware_features.fpga_features.timing_constraints.clock_frequency > 0.0);
        assert!(features.hardware_features.fpga_features.timing_constraints.setup_time > 0.0);
    }

    #[test]
    fn test_hardware_aware_training_labels() {
        use crate::gnn_training::GnnTrainer;

        // Create PIH with hardware patterns
        let mut pih = ProgramInteractionHypergraph::new();

        // Add CGRA pattern
        let cgra_event = Event {
            id: "cgra_event".to_string(),
            opcode: "cgra_compute".to_string(),
            dtype: "f32*".to_string(),
            can_throw: false,
            cid: None,
            attributes: [("pattern".to_string(), json!("systolic_array"))].iter().cloned().collect(),
        };

        // Add multiple loop events
        for i in 0..3 {
            let loop_event = Event {
                id: format!("loop_{}", i),
                opcode: "for".to_string(),
                dtype: "i32".to_string(),
                can_throw: false,
            cid: None,
                attributes: [("iterations".to_string(), json!(100))].iter().cloned().collect(),
            };
            pih.events.insert(format!("loop_{}", i), loop_event);
        }

        // Add CGRA pattern
        let cgra_event = Event {
            id: "cgra_event".to_string(),
            opcode: "cgra_compute".to_string(),
            dtype: "f32*".to_string(),
            can_throw: false,
            cid: None,
            attributes: [("pattern".to_string(), json!("systolic_array"))].iter().cloned().collect(),
        };

        pih.events.insert("cgra_event".to_string(), cgra_event);

        let labels = GnnTrainer::generate_hardware_aware_labels(&pih, 0);

        // Verify hardware-aware optimization predictions
        assert!(labels.rule_applications.iter().any(|rule| rule.contains("Cgra")));
        assert!(labels.performance_gain > 0.0);
        assert!(labels.energy_savings > 0.0);

        // Hardware-aware training should provide optimization benefits
        assert!(!labels.rule_applications.is_empty(),
               "Expected at least some optimization rules. Found: {:?}", labels.rule_applications);
        assert!(labels.performance_gain >= 0.2); // Hardware-aware optimization benefits
        assert!(labels.energy_savings >= 0.05); // System-level optimization benefits

        // Print what we actually found for debugging
        println!("Rules found: {:?}", labels.rule_applications);
        println!("Performance gain: {}", labels.performance_gain);
        println!("Energy savings: {}", labels.energy_savings);
    }

    #[test]
    fn test_advanced_loop_transformations() {
        use crate::gnn_training::{FeatureExtractor, LoopTransformType};

        // Create nested loop structure for tiling analysis
        let mut pih = ProgramInteractionHypergraph::new();

        let outer_loop = Event {
            id: "outer_loop".to_string(),
            opcode: "for".to_string(),
            dtype: "i32".to_string(),
            can_throw: false,
            cid: None,
            attributes: [
                ("start".to_string(), json!(0)),
                ("end".to_string(), json!(100)),
            ].iter().cloned().collect(),
        };

        let inner_loop = Event {
            id: "inner_loop".to_string(),
            opcode: "for".to_string(),
            dtype: "i32".to_string(),
            can_throw: false,
            cid: None,
            attributes: [
                ("start".to_string(), json!(0)),
                ("end".to_string(), json!(100)),
                ("parent_loop".to_string(), json!("outer_loop")),
            ].iter().cloned().collect(),
        };

        let array_entity = Entity {
            id: "matrix".to_string(),
            kind: EntityKind::Obj,
            entity_type: "f32**".to_string(),
            attributes: [("dimensions".to_string(), json!([100, 100]))].iter().cloned().collect(),
        };

        pih.events.insert("outer_loop".to_string(), outer_loop);
        pih.events.insert("inner_loop".to_string(), inner_loop);
        pih.entities.insert("matrix".to_string(), array_entity);

        let features = FeatureExtractor::extract_features(&pih);

        // Verify loop transformations are detected
        assert!(features.loop_transformations.len() > 0);

        let tiling_transform = features.loop_transformations.iter()
            .find(|t| t.transform_type == LoopTransformType::Tiling);

        assert!(tiling_transform.is_some());
        assert_eq!(tiling_transform.unwrap().target_loops, vec!["outer_loop".to_string()]);
        assert_eq!(tiling_transform.unwrap().tile_sizes, vec![32, 32]);
    }

    #[test]
    fn test_inter_procedural_optimization() {
        use crate::gnn_training::{FeatureExtractor, GlobalVarOptimizationType};

        // Create function call structure
        let mut pih = ProgramInteractionHypergraph::new();

        // Add main function
        let main_function = Event {
            id: "main".to_string(),
            opcode: "function_def".to_string(),
            dtype: "int".to_string(),
            can_throw: false,
            cid: None,
            attributes: [("function_name".to_string(), json!("main"))].iter().cloned().collect(),
        };

        let function_def = Event {
            id: "helper_function".to_string(),
            opcode: "function_def".to_string(),
            dtype: "void".to_string(),
            can_throw: false,
            cid: None,
            attributes: [("function_name".to_string(), json!("helper_function"))].iter().cloned().collect(),
        };

        let function_call = Event {
            id: "call_helper".to_string(),
            opcode: "call".to_string(),
            dtype: "void".to_string(),
            can_throw: false,
            cid: None,
            attributes: [("callee".to_string(), json!("other_function"))].iter().cloned().collect(),
        };

        let global_var = Entity {
            id: "global_counter".to_string(),
            kind: EntityKind::Obj,
            entity_type: "global".to_string(),
            attributes: [("constant".to_string(), json!(true))].iter().cloned().collect(),
        };

        pih.events.insert("main".to_string(), main_function);
        pih.events.insert("helper_function".to_string(), function_def);
        pih.events.insert("call_helper".to_string(), function_call);
        pih.entities.insert("global_counter".to_string(), global_var);

        let features = FeatureExtractor::extract_features(&pih);

        // Debug: print what we actually found
        println!("Dead functions found: {:?}", features.inter_procedural_optimizations.dead_functions);
        println!("Function definitions: {:?}", pih.events.values()
            .filter(|e| e.opcode == "function_def")
            .map(|e| (e.id.clone(), e.attributes.get("function_name")))
            .collect::<Vec<_>>());
        println!("Function calls: {:?}", pih.events.values()
            .filter(|e| e.opcode == "call")
            .filter_map(|e| e.attributes.get("callee").and_then(|c| c.as_str()))
            .collect::<Vec<_>>());

        // Verify inter-procedural optimizations are detected
        assert!(features.inter_procedural_optimizations.dead_functions.contains(&"helper_function".to_string()),
            "Expected helper_function to be detected as dead. Found: {:?}", features.inter_procedural_optimizations.dead_functions);
        assert!(features.inter_procedural_optimizations.global_variables.len() > 0);

        let global_opt = &features.inter_procedural_optimizations.global_variables[0];
        assert_eq!(global_opt.optimization_type, GlobalVarOptimizationType::LoadStoreOptimization);
        assert!(global_opt.elimination_benefit > 0.0);
    }

    #[test]
    fn test_data_structure_transformations() {
        use crate::gnn_training::{FeatureExtractor, LayoutType, MemoryPoolType, CacheStructureType};

        // Create array structure for layout optimization
        let mut pih = ProgramInteractionHypergraph::new();

        let array_entity = Entity {
            id: "large_array".to_string(),
            kind: EntityKind::Obj,
            entity_type: "f32*".to_string(),
            attributes: [("size".to_string(), json!(1024))].iter().cloned().collect(),
        };

        pih.entities.insert("large_array".to_string(), array_entity);

        let features = FeatureExtractor::extract_features(&pih);

        // Verify data structure transformations are detected
        assert!(features.data_structure_transformations.array_layouts.len() > 0);
        assert!(features.data_structure_transformations.memory_pools.len() > 0);
        assert!(features.data_structure_transformations.cache_structures.len() > 0);

        let layout_opt = &features.data_structure_transformations.array_layouts[0];
        assert_eq!(layout_opt.proposed_layout, LayoutType::Blocked);
        assert!(layout_opt.cache_miss_reduction > 0.0);

        let memory_pool = &features.data_structure_transformations.memory_pools[0];
        assert_eq!(memory_pool.pool_type, MemoryPoolType::ArenaBased);
        assert!(memory_pool.fragmentation_reduction > 0.0);

        let cache_struct = &features.data_structure_transformations.cache_structures[0];
        assert_eq!(cache_struct.structure_type, CacheStructureType::PaddedStruct);
        assert!(cache_struct.cache_line_utilization > 0.0);
    }

    #[test]
    fn test_system_level_optimizations() {
        use crate::gnn_training::{FeatureExtractor, ScheduleType, EnergyOptimizationType, FaultToleranceType};

        // Create system-level optimization structure
        let mut pih = ProgramInteractionHypergraph::new();

        let task_entity = Entity {
            id: "compute_task".to_string(),
            kind: EntityKind::Obj,
            entity_type: "task".to_string(),
            attributes: [("hardware_affinity".to_string(), json!("cgra"))].iter().cloned().collect(),
        };

        pih.entities.insert("compute_task".to_string(), task_entity);

        let features = FeatureExtractor::extract_features(&pih);

        // Verify system-level optimizations are detected
        assert!(features.system_level_optimizations.task_scheduling.len() > 0);
        assert!(features.system_level_optimizations.communication_optimization.len() > 0);
        assert!(features.system_level_optimizations.energy_management.len() > 0);
        assert!(features.system_level_optimizations.fault_tolerance.len() > 0);

        let task_sched = &features.system_level_optimizations.task_scheduling[0];
        assert_eq!(task_sched.schedule_type, ScheduleType::HardwareAware);
        assert!(task_sched.throughput_improvement > 0.0);

        let energy_mgmt = &features.system_level_optimizations.energy_management[0];
        assert_eq!(energy_mgmt.optimization_type, EnergyOptimizationType::DynamicVoltageFrequencyScaling);
        assert!(energy_mgmt.energy_efficiency > 0.0);

        let fault_tol = &features.system_level_optimizations.fault_tolerance[0];
        assert_eq!(fault_tol.optimization_type, FaultToleranceType::CheckpointRestart);
        assert!(fault_tol.reliability_improvement > 0.0);
    }

    #[test]
    fn test_production_training_dataset_pipeline() {
        use crate::gnn_training::{FeatureExtractor, BenchmarkType, HardwareType};

        // Create PIH with benchmark and hardware profile entities
        let mut pih = ProgramInteractionHypergraph::new();

        let benchmark_entity = Entity {
            id: "spec_benchmark".to_string(),
            kind: EntityKind::Obj,
            entity_type: "benchmark_data".to_string(),
            attributes: [("path".to_string(), json!("/benchmarks/spec"))].iter().cloned().collect(),
        };

        let hardware_entity = Entity {
            id: "cpu_profile".to_string(),
            kind: EntityKind::Obj,
            entity_type: "hardware_profile".to_string(),
            attributes: [("arch".to_string(), json!("x86_64"))].iter().cloned().collect(),
        };

        pih.entities.insert("spec_benchmark".to_string(), benchmark_entity);
        pih.entities.insert("cpu_profile".to_string(), hardware_entity);

        let features = FeatureExtractor::extract_features(&pih);

        // Verify production training features are detected
        assert!(features.production_training.dataset_pipeline.benchmark_datasets.len() > 0);
        assert!(features.production_training.dataset_pipeline.hardware_profiles.len() > 0);
        assert!(features.production_training.dataset_pipeline.performance_metrics.len() > 0);

        let benchmark = &features.production_training.dataset_pipeline.benchmark_datasets[0];
        assert_eq!(benchmark.dataset_type, BenchmarkType::Custom);
        assert_eq!(benchmark.name, "spec_benchmark");

        let hardware_profile = &features.production_training.dataset_pipeline.hardware_profiles[0];
        assert_eq!(hardware_profile.hardware_specs.architecture, "x86_64");
        assert!(hardware_profile.optimization_opportunities.len() > 0);
    }

    #[test]
    fn test_production_training_model_quantization() {
        use crate::gnn_training::{FeatureExtractor, QuantizationType, HardwareBackend, TargetType};

        // Create PIH with quantization requirements
        let mut pih = ProgramInteractionHypergraph::new();

        let quantized_entity = Entity {
            id: "quantized_model".to_string(),
            kind: EntityKind::Obj,
            entity_type: "model".to_string(),
            attributes: [("quantized".to_string(), json!(true))].iter().cloned().collect(),
        };

        pih.entities.insert("quantized_model".to_string(), quantized_entity);

        let features = FeatureExtractor::extract_features(&pih);

        // Verify model quantization features are detected
        assert!(features.production_training.model_quantization.compressed_models.len() > 0);
        assert!(features.production_training.model_quantization.deployment_targets.len() > 0);

        let quant_config = &features.production_training.model_quantization.quantization_config;
        assert_eq!(quant_config.quantization_type, QuantizationType::PostTrainingQuantization);
        assert_eq!(quant_config.hardware_backend, HardwareBackend::Cpu);

        let compressed_model = &features.production_training.model_quantization.compressed_models[0];
        assert!(compressed_model.compression_ratio > 0.0);
        assert!(compressed_model.accuracy_retention > 0.0);

        let deployment_target = &features.production_training.model_quantization.deployment_targets[0];
        assert_eq!(deployment_target.deployment_format, "shared_library");
        assert!(deployment_target.hardware_constraints.max_memory_usage > 0);
    }

    #[test]
    fn test_production_training_incremental_learning() {
        use crate::gnn_training::{FeatureExtractor, UpdateType, StrategyType};

        // Create PIH with learning feedback structure
        let mut pih = ProgramInteractionHypergraph::new();

        let feedback_entity = Entity {
            id: "learning_feedback".to_string(),
            kind: EntityKind::Obj,
            entity_type: "feedback".to_string(),
            attributes: [("continuous".to_string(), json!(true))].iter().cloned().collect(),
        };

        pih.entities.insert("learning_feedback".to_string(), feedback_entity);

        let features = FeatureExtractor::extract_features(&pih);

        // Verify incremental learning features are detected
        assert!(features.production_training.incremental_learning.model_updates.len() > 0);
        assert!(features.production_training.incremental_learning.adaptation_strategies.len() > 0);

        let feedback_config = &features.production_training.incremental_learning.feedback_loop;
        assert!(feedback_config.feedback_sources.len() > 0);
        assert!(feedback_config.performance_thresholds.accuracy_threshold > 0.0);

        let model_update = &features.production_training.incremental_learning.model_updates[0];
        assert_eq!(model_update.update_type, UpdateType::ParameterUpdate);
        assert!(model_update.accuracy_change >= 0.0);

        let adaptation_strategy = &features.production_training.incremental_learning.adaptation_strategies[0];
        assert_eq!(adaptation_strategy.strategy_type, StrategyType::HyperparameterTuning);
        assert!(!adaptation_strategy.parameters.is_empty());
    }

    #[test]
    fn test_production_training_build_integration() {
        use crate::gnn_training::{FeatureExtractor, TargetType, ScriptType};

        // Create PIH with build system entities
        let mut pih = ProgramInteractionHypergraph::new();

        let cmake_entity = Entity {
            id: "cmake_config".to_string(),
            kind: EntityKind::Obj,
            entity_type: "build_system".to_string(),
            attributes: [("type".to_string(), json!("cmake"))].iter().cloned().collect(),
        };

        pih.entities.insert("cmake_config".to_string(), cmake_entity);

        let features = FeatureExtractor::extract_features(&pih);

        // Verify build system integration features are detected
        assert!(features.production_training.build_integration.cmake_integration.build_targets.len() > 0);
        assert!(features.production_training.build_integration.deployment_scripts.len() > 0);

        let cmake_integration = &features.production_training.build_integration.cmake_integration;
        assert_eq!(cmake_integration.cmake_version, "3.20");
        assert!(cmake_integration.cmake_files.contains(&"CMakeLists.txt".to_string()));

        let build_target = &cmake_integration.build_targets[0];
        assert_eq!(build_target.target_type, TargetType::SharedLibrary);
        assert_eq!(build_target.target_name, "vm_gnn");
        assert!(build_target.sources.contains(&"src/*.rs".to_string()));

        let deployment_script = &features.production_training.build_integration.deployment_scripts[0];
        assert_eq!(deployment_script.script_type, ScriptType::Bash);
        assert_eq!(deployment_script.script_name, "deploy.sh");
    }

    /// Creates a constant folding rule: add(x, 0)  x, mul(x, 1)  x
    pub fn create_constant_folding_rule() -> DpoRule {
        // LHS: operation with identity constant
        let mut lhs = ProgramInteractionHypergraph::new();
        let op_event = Event {
            id: "op".to_string(),
            opcode: "add".to_string(), // Could be add, mul, etc.
            dtype: "i32".to_string(),
            can_throw: false,
            cid: None,
            attributes: HashMap::new(),
        };
        let x_entity = Entity {
            id: "x".to_string(),
            kind: EntityKind::Val,
            entity_type: "i32".to_string(),
            attributes: HashMap::new(),
            cid: None,
        };
        let identity_entity = Entity {
            id: "identity".to_string(),
            kind: EntityKind::Val,
            entity_type: "i32".to_string(),
            attributes: [
                ("is_const".to_string(), json!(true)),
                ("value".to_string(), json!(0)), // 0 for add, 1 for mul
            ].iter().cloned().collect(),
        };
        let out_entity = Entity {
            id: "out".to_string(),
            kind: EntityKind::Val,
            entity_type: "i32".to_string(),
            attributes: HashMap::new(),
            cid: None,
        };

        lhs.events.insert(op_event.id.clone(), op_event);
        lhs.entities.insert(x_entity.id.clone(), x_entity.clone());
        lhs.entities.insert(identity_entity.id.clone(), identity_entity);
        lhs.entities.insert(out_entity.id.clone(), out_entity.clone());

        lhs.incidence.push(Incidence {
            event: "op".to_string(),
            port: "data_in[0]".to_string(),
            entity: "x".to_string(),
            cid: None,
        });
        lhs.incidence.push(Incidence {
            event: "op".to_string(),
            port: "data_in[1]".to_string(),
            entity: "identity".to_string(),
        });
        lhs.incidence.push(Incidence {
            event: "op".to_string(),
            port: "data_out[0]".to_string(),
            entity: "out".to_string(),
        });

        // RHS: just pass through x
        let mut rhs = ProgramInteractionHypergraph::new();
        rhs.entities.insert(x_entity.id.clone(), x_entity.clone());
        rhs.entities.insert(out_entity.id.clone(), out_entity.clone());
        // Direct connection: x  out (no operation needed)

        DpoRule {
            name: "ConstantFolding".to_string(),
            description: "Eliminate operations with identity constants".to_string(),
            lhs,
            rhs,
            nacs: vec![], // No negative conditions for this simple rule
        }
    }

    /// Creates a dead code elimination rule
    pub fn create_dead_code_elimination_rule() -> DpoRule {
        // LHS: computation result that is never used
        let mut lhs = ProgramInteractionHypergraph::new();
        let compute_event = Event {
            id: "compute".to_string(),
            opcode: "mul".to_string(),
            dtype: "i32".to_string(),
            can_throw: false,
            cid: None,
            attributes: HashMap::new(),
        };
        let x_entity = Entity {
            id: "x".to_string(),
            kind: EntityKind::Val,
            entity_type: "i32".to_string(),
            attributes: HashMap::new(),
            cid: None,
        };
        let y_entity = Entity {
            id: "y".to_string(),
            kind: EntityKind::Val,
            entity_type: "i32".to_string(),
            attributes: HashMap::new(),
            cid: None,
        };
        let unused_entity = Entity {
            id: "unused".to_string(),
            kind: EntityKind::Val,
            entity_type: "i32".to_string(),
            attributes: HashMap::new(),
            cid: None,
        };

        lhs.events.insert(compute_event.id.clone(), compute_event);
        lhs.entities.insert(x_entity.id.clone(), x_entity.clone());
        lhs.entities.insert(y_entity.id.clone(), y_entity.clone());
        lhs.entities.insert(unused_entity.id.clone(), unused_entity.clone());

        lhs.incidence.push(Incidence {
            event: "compute".to_string(),
            port: "data_in[0]".to_string(),
            entity: "x".to_string(),
            cid: None,
        });
        lhs.incidence.push(Incidence {
            event: "compute".to_string(),
            port: "data_in[1]".to_string(),
            entity: "y".to_string(),
        });
        lhs.incidence.push(Incidence {
            event: "compute".to_string(),
            port: "data_out[0]".to_string(),
            entity: "unused".to_string(),
        });

        // RHS: remove the unused computation entirely
        let mut rhs = ProgramInteractionHypergraph::new();
        rhs.entities.insert(x_entity.id.clone(), x_entity);
        rhs.entities.insert(y_entity.id.clone(), y_entity);
        // No events, no unused entity

        // NAC: Don't eliminate if result is actually used somewhere
        let used_result_nac = NegativeApplicationCondition {
            name: "result_is_used".to_string(),
            description: "Don't eliminate if the result is used by another operation".to_string(),
            forbidden_incidence: vec![Incidence {
                event: "other_op".to_string(),
                port: "data_in[0]".to_string(),
                entity: "unused".to_string(),
            }],
            forbidden_state_edges: vec![],
        };

        DpoRule {
            name: "DeadCodeElimination".to_string(),
            description: "Remove computations whose results are never used".to_string(),
            lhs,
            rhs,
            nacs: vec![used_result_nac],
        }
    }

    /// Creates a strength reduction rule: mul(x, 2^k)  shl(x, k)
    pub fn create_strength_reduction_rule() -> DpoRule {
        // LHS: mul operation with constant power of 2
        let mut lhs = ProgramInteractionHypergraph::new();
        let mul_edge = Edge {
            id: "mul_op".to_string(),
            kind: EdgeKind::Event,
            label: Some("mul".to_string()),
            attributes: [
                ("opcode".to_string(), json!("mul")),
                ("dtype".to_string(), json!("i32")),
                ("can_throw".to_string(), json!(false)),
            ].iter().cloned().collect(),
            cid: None,
        };
        let x_node = Node {
            id: "x".to_string(),
            kind: NodeKind::Val,
            node_type: "i32".to_string(),
            attributes: HashMap::new(),
            cid: None,
        };
        let c_node = Node {
            id: "c".to_string(),
            kind: NodeKind::Val,
            node_type: "i32".to_string(),
            attributes: [
                ("is_const".to_string(), json!(true)),
                ("value".to_string(), json!(8)), // 2^3
            ].iter().cloned().collect(),
            cid: None,
        };
        let out_node = Node {
            id: "out".to_string(),
            kind: NodeKind::Val,
            node_type: "i32".to_string(),
            attributes: HashMap::new(),
            cid: None,
        };

        lhs.edges.push(mul_edge);
        lhs.nodes.push(x_node.clone());
        lhs.nodes.push(c_node);
        lhs.nodes.push(out_node.clone());

        lhs.incidence.push(Incidence {
            event: "mul_op".to_string(),
            port: "data_in[0]".to_string(),
            entity: "x".to_string(),
            cid: None,
        });
        lhs.incidence.push(Incidence {
            event: "mul_op".to_string(),
            port: "data_in[1]".to_string(),
            entity: "c".to_string(),
        });
        lhs.incidence.push(Incidence {
            event: "mul_op".to_string(),
            port: "data_out[0]".to_string(),
            entity: "out".to_string(),
        });

        // RHS: equivalent shift operation
        let mut rhs = ProgramInteractionHypergraph::new();
        let shift_amount = Entity {
            id: "shift_amt".to_string(),
            kind: EntityKind::Val,
            entity_type: "i32".to_string(),
            attributes: [
                ("is_const".to_string(), json!(true)),
                ("value".to_string(), json!(3)), // log2(8)
            ].iter().cloned().collect(),
        };
        let shl_event = Event {
            id: "shl_op".to_string(),
            opcode: "shl".to_string(),
            dtype: "i32".to_string(),
            can_throw: false,
            cid: None,
            attributes: HashMap::new(),
        };

        rhs.events.insert(shl_event.id.clone(), shl_event);
        rhs.entities.insert(x_entity.id.clone(), x_entity.clone());
        rhs.entities.insert(shift_amount.id.clone(), shift_amount);
        rhs.entities.insert(out_entity.id.clone(), out_entity.clone());

        rhs.incidence.push(Incidence {
            event: "shl_op".to_string(),
            port: "data_in[0]".to_string(),
            entity: "x".to_string(),
            cid: None,
        });
        rhs.incidence.push(Incidence {
            event: "shl_op".to_string(),
            port: "data_in[1]".to_string(),
            entity: "shift_amt".to_string(),
        });
        rhs.incidence.push(Incidence {
            event: "shl_op".to_string(),
            port: "data_out[0]".to_string(),
            entity: "out".to_string(),
        });

        // NAC: Don't apply if dtype is floating point (due to rounding differences)
        let floating_point_nac = NegativeApplicationCondition {
            name: "no_floating_point".to_string(),
            description: "Don't apply strength reduction to floating point types".to_string(),
            forbidden_incidence: vec![Incidence {
                event: "mul_op".to_string(),
                port: "dtype".to_string(),
                entity: "float_type".to_string(),
            }],
            forbidden_state_edges: vec![],
        };

        DpoRule {
            name: "StrengthReduction".to_string(),
            description: "Convert multiplication by power of 2 to shift operation".to_string(),
            lhs,
            rhs,
            nacs: vec![floating_point_nac],
        }
    }
}
